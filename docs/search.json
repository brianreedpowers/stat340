[
  {
    "objectID": "rv.html",
    "href": "rv.html",
    "title": "Random Variables",
    "section": "",
    "text": "These notes will discuss the most fundamental object in statistics: random variables.\nWe use random variables, within the framework of probability theory, to model how our data came to be.\nWe will first introduce the idea of a random variable (and its associated distribution) and review probability theory.\nThen, we will walk through a number of different basic distributions and discuss the kinds of data for which these different models are appropriate."
  },
  {
    "objectID": "rv.html#learning-objectives",
    "href": "rv.html#learning-objectives",
    "title": "3  Random Variables",
    "section": "3.1 Learning objectives",
    "text": "3.1 Learning objectives\nAfter this lesson, you will be able to\n\nExplain what a random variable is\nIdentify appropriate random variables for modeling different real-world events and explain why one choice might be better or worse than another\nCombine random variables to build simple models of real-world phenomena\nCompute the probabilities of simple events under different probability distributions using R."
  },
  {
    "objectID": "rv.html#what-is-a-random-variable",
    "href": "rv.html#what-is-a-random-variable",
    "title": "3  Random Variables",
    "section": "3.2 What is a random variable?",
    "text": "3.2 What is a random variable?\nConsider the following quantities/events:\n\nWhether or not a coin flip comes up heads or tails.\nHow many people in the treatment group of a vaccine trial are hospitalized.\nThe water level measured in Lake Mendota on a given day.\nHow many customers arrive at a store between 2pm and 3pm today.\nHow many days between installing a lightbulb and when it burns out.\n\nAll of these are examples of events that we might reasonably model according to different random variables.\nLater in your studies you will learn a more formal definition of what a random variable is. For now, let’s be content with saying that a random variable is a (random) number \\(X\\) about which we can compute quantities of the form \\(\\Pr[ X \\in S ]\\), where \\(S\\) is a set."
  },
  {
    "objectID": "rv.html#aside-probability-refresher",
    "href": "rv.html#aside-probability-refresher",
    "title": "3  Random Variables",
    "section": "3.3 Aside: probability refresher",
    "text": "3.3 Aside: probability refresher\nBefore moving on, let’s briefly review some basic ideas from probability theory.\nWe have a set of possible outcomes, usually denoted \\(\\Omega\\).\n\nwhen we flip a coin, it can land either heads (\\(H\\)) or tails (\\(T\\)), so the outcomes are \\(\\Omega = \\{H, T\\}\\).\nWhen we roll a six-sided die, there are six possible outcomes, \\(\\Omega = \\{1,2,3,4,5,6\\}\\).\nIn other settings, the outcomes might be an infinite set.\n\nEx: if we measure the depth of Lake Mendota, the outcome may be any positive real number (at least theoretically, anyway!)\n\n\nIn the vast majority of situations, \\(\\Omega\\) will be either discrete (e.g., \\(\\{1,2,\\dots\\}\\)) or continuous (e.g., \\([0,1]\\)) and we call the associated random variable discrete or continuous, respectively.\nA subset \\(E \\subseteq \\Omega\\) of the outcome space is called an event.\nA probability is a function that maps events to numbers, with the properties that\n\n\\(\\Pr[ E ] \\in [0,1]\\) for all events \\(E\\)\n\\(\\Pr[ \\Omega ] = 1\\)\nFor \\(E_1,E_2 \\subseteq \\Omega\\) with \\(E_1 \\cap E_2 = \\emptyset\\), \\(\\Pr[ E_1 \\cup E_2 ] = \\Pr[ E_1 ] + \\Pr[ E_2 ]\\)\n\nTwo events \\(E_1\\) and \\(E_2\\) are independent if \\(\\Pr[ E_1 \\cap E_2 ] = \\Pr[ E_1 ] \\Pr[ E_2 ]\\).\nTwo random variables \\(X\\) and \\(Y\\) are independent if for all sets \\(S_1,S_2\\), we have \\(\\Pr[ X \\in S_1 ~\\&~ Y \\in S_2 ] = \\Pr[ X \\in S_1 ] \\Pr[ Y \\in S_2 ]\\).\nRoughly speaking, two random variables are independent if learning information about one of them doesn’t tell you anything about the other.\n\nFor example, if each of us flips a coin, it is reasonable to model them as being independent.\nLearning whether my coin landed heads or tails doesn’t tell us anything about your coin.\n\nExample: Coin flipping\nConsider a coin toss, in which the possible outcomes are \\(\\Omega = \\{ H, T \\}\\).\nThis is a discrete random experiment, but beause the outcomes are not numeric it is not a random variable. If, however we define \\(X\\) to be 1 when we flip an \\(H\\) and 0 when we flip \\(T\\), then we have defined a discrete random variable, because the outcome set \\(\\{0,1\\}\\) is discrete.\nIf we have a fair coin, then it is sensible that \\(\\Pr[ X=1 ] = \\Pr[ X=0 ] = 1/2\\).\nExercise (optional): verify that this probability satisfies the above properties!\nWe will see in a moment that this is a special case of a Bernoulli random variable, which you are probably already familiar with.\nExample: Six-sided die\nIf we roll a die, the outcome space is \\(\\Omega = \\{1,2,3,4,5,6\\}\\), and the events are all the subsets of this six-element set.\nSo, for example, we can talk about the event that we roll an odd number \\(E_{\\text{odd}} = \\{1,3,5\\}\\) or the event that we roll a number larger than \\(4\\), \\(E_{&gt;4} = \\{5,6\\}\\).\nExample: Human heights\nConsider our human height example from our previous lecture.\nWe pick a random person and measure their height in, say, centimeters. What is the outcome space?\n\nOne option: the outcome space is the set of positive reals, in which case this is a continuous random variable.\nAlternatively, we could assume that the outcome space is the set of all real numbers.\n\nThis highlights the importance of specifying our assumptions and the outcome space we are working with in a particular problem. We will see these kinds of issues again and again this semester.\n\n3.3.1 A note on models, assumptions and approximations\nNote that we are already making an approximation– our outcome sets aren’t really exhaustive, here.\nWhen you toss a coin, there are possible outcomes other than heads and tails.\n\nPerhaps the coin lands on its side (I have personally seen this happen with a nickel flipped onto an old wooden floor).\nSimilarly, perhaps the die lands on its side.\n\nWe can see a kind of idealization in our human height example.\n\nWe can only measure a height to some finite precision (say, two decimal places), so it is a bit silly to take the outcome space to be the real numbers.\nAfter all, if we can only measure a height to two decimal places, then there is no way to ever obtain the event, “height is 160.3333333… centimeters”.\n\nThese kinds of approximations and idealizations are good to be aware of, but they usually don’t bother us much\nWe will see below and in future lectures the kinds of approximation errors that are more concerning and warrant our attention."
  },
  {
    "objectID": "rv.html#random-variables",
    "href": "rv.html#random-variables",
    "title": "3  Random Variables",
    "section": "3.4 Random variables",
    "text": "3.4 Random variables\nA random variable is specified by a probability.\nThat is, a random variable \\(X\\) is specified by an outcome set \\(\\Omega\\) and a function that specifies probabilities of the form \\(\\Pr[ X \\in E ]\\) where \\(E \\subseteq \\Omega\\) is an event.\nLet’s look at some commonly-used random variables. In the process, we will discuss some of the real-world phenomena to which these random variables are best-suited.\n\n3.4.1 Bernoulli\nA Bernoulli random variable has outcome set \\(\\Omega = \\{0,1\\}\\).\nAs discussed above, to specify a probability on this set, it is enough for us to specify \\(\\Pr[ \\{0 \\} ]\\) and \\(\\Pr[ \\{1\\} ]\\).\nTypically, we do this by specifying the success probability \\(p = \\Pr[ \\{1\\} ] \\in [0,1]\\). Once we have done this, it is immediate that (check!) \\(\\Pr[ \\{0\\} ] = 1-p\\).\nNote that we can check that this gives us a probability by verifying that it sums to 1: \\[\n\\Pr[ \\Omega ] = \\Pr[ \\{0\\} \\cup \\{1\\} ] = \\Pr[ \\{0\\} ] + \\Pr[ \\{1\\} ] = 1-p + p = 1.\n\\] Bernoulli random variables are commonly used to model “yes or no” events. That is, events of the form “whether or not event \\(A\\) happens”. Common examples:\n\nCoin flips\nwhether or not a person gets sick with a disease\nwhether or not a team wins a game.\n\nIf \\(Z\\) is a Bernoulli random variable with probability of success \\(p\\), then we write \\(Z \\sim \\operatorname{Bernoulli}(p)\\).\nWe read this as something like “\\(Z\\) is distributed as Bernoulli \\(p\\)”.\n\n\n3.4.2 Binomial\nA Bernoulli random variable is like a single coin flip.\nWhat if we flip many coins, all with the same probability of coming up heads?\nThen the total number of heads is distributed as a binomial random variable.\nIn particular, we describe a binomial distribution by specifying two parameters:\n\nthe number of trials (i.e., coins flipped) \\(n\\), often called the size parameter and\nthe success probability \\(p\\) (i.e., the probability that an individual coin lands heads).\n\nOften we will write \\(\\operatorname{Binomial}(n,p)\\) to denote this distribution.\nSo if \\(X\\) is a Binomial random variable with \\(n\\) trials and success probability \\(p\\), we write \\(X \\sim \\operatorname{Binomial}(n,p)\\).\nExample: modeling COVID-19\nIn a population of 250,000 people (approximately the population of Madison), we may imagine that each person has some probability \\(p\\) of becoming seriously ill with COVID-19.\nThen, in a sense, the total number of people in Madison who become seriously ill with COVID-19 is like the total number of probability-\\(p\\) coin flips that land heads when we flip \\(250,000\\) coins.\nWe might then model the number of COVID-19 patients by a binomial random variable with \\(n=250,000\\) and \\(p=0.01\\) (just to be clear, we are completely making up this choice of \\(p\\) here, just for the sake of example!).\n\n3.4.2.1 Generating random binomial RVs\nWe can generate binomial random variables using the rbinom function. Think “r for random”.\n\n# rbinom takes three arguments.\n# The first is the number of random variables we want to generate (confusingly, this is called n in the R docs).\n# The size argument specifies the number of coins to flip, i.e., n in our notation above (I know! Confusing!)\n# The prob argument specifies the probability that one coin lands heads, i.e., p in our notation above.\nrbinom(1, size = 10, prob = 0.3) # produces a random number from {0,1,2,...,10}, with 2,3,4 being most common (because np = 3 is the expected value we'll come back to this!)\n\n[1] 3\n\n\n\n# If we repeat the experiment a few times, we get different random values.\nrbinom(1, size = 10, prob = 0.3)\n\n[1] 3\n\nrbinom(1, size = 10, prob = 0.3)\n\n[1] 3\n\nrbinom(1, size = 10, prob = 0.3)\n\n[1] 3\n\nrbinom(1, size = 10, prob = 0.3)\n\n[1] 4\n\nrbinom(1, size = 10, prob = 0.3)\n\n[1] 4\n\n\nWe can also use the binomial to generate Bernoulli random variables, by setting the size argument to 1 (i.e., flip 1 coin):\n\nrbinom(1, size = 1, prob = 0.5) # 1 is \"heads\", 0 is \"tails\"\n\n[1] 1\n\n\nImportant note: if you read the R documentation, there is a possible notational confusion waiting for you, alluded to in the comments of the code above. The signature of the rbinom function is given as rbinom(n, size, prob). Based on the \\(\\operatorname{Binomial}(n,p)\\) notation we used above, you might expect that n in the rbinom function is the number of coins and prob is the success probability. Unfortunately, that isn’t quite right. n is the number of Binomial random variables to generate. size specifies the size parameter (\\(n\\) in our math notation above).\nCompare the following:\n\nrbinom(n = 3, size = 10, prob = 0.5) # 3 draws from a Binomial(10,0.5)\n\n[1] 5 4 8\n\n\n\nrbinom(n = 10, size = 3, prob = 0.5) # 10 draws from a Binomial(3,0.5)\n\n [1] 3 1 2 1 0 1 1 3 3 0\n\n\nAll of the R functions for generating random variables take n as the number of draws from the distribution. This is in keeping with the convention in most of probability and statistics that \\(n\\) is a sample size. Unfortunately, this is just one of those places where two different notational conventions collide. It’s unfortunate that it arises in such a common and early-stage part of R!\n\n\n\n3.4.3 Aside: expectation review\nBefore we continue with more random variables, let’s take a pause to discuss one more important probability concept: expectation. You will hopefully recall from previous courses in probability and/or statistics the notion of expectation of a random variable.\nExpectation: long-run averages\nThe expectation of a random variable \\(X\\), which we write \\(\\mathbb{E} X\\), is the “long-run average” of the random variable.\nRoughly speaking, the expectation is what we would see on average if we observed many copies of \\(X\\).\nThat is, we observe \\(X_1,X_2,\\dots,X_n\\), and consider their average, \\(\\bar{X} = n^{-1} \\sum_{i=1}^n X_i\\).\nThe law of large numbers (LLN) states that in a certain sense, as \\(n\\) gets large, \\(\\bar{X}\\) gets very close to \\(\\mathbb{E} X\\). (actually, there are two LLNs, the weak law and strong law, but that’s a matter for a later course!).\nBy analogy with our calculus class, we would like to say something like \\[\n\\lim_{n \\rightarrow \\infty} \\frac{1}{n} \\sum_{i=1}^n X_i = \\mathbb{E} X.\n\\] But \\(n^{-1} \\sum_i X_i\\) is a random sum, so how can we take a limit?\nWell, again, the details are a matter for your probability theory class, but roughly speaking, for \\(n\\) large, with high probability, \\(\\bar{X}\\) is close to \\(\\mathbb{E}\\).\nExpectation: formal definition\nMore formally, if \\(X\\) is a discrete random variable, we define its expectation \\(\\mu\\) to be \\[\n\\mathbb{E} X = \\sum_k k \\Pr[ X = k]\n\\] where the sum is over all \\(k\\) such that \\(\\Pr[ X=k ] &gt; 0\\).\n\nNote that this set could be finite or infinite.\nIf the set is infinite, the sum might not converge, in which case we say that the expectation is either infinite or doesn’t exist. But that won’t be an issue this semester.\n\nQuestion: can you see how this definition is indeed like the “average behavior” of \\(X\\)?\nExercise: compute the expectation of a Bernoulli random variable with success probability \\(p\\). What about a \\(\\operatorname{Binomial}(n,p)\\) random variable? Hint: the expectation of a sum of RVs is the sum of their expectations. Write the Binomial RV as a sum of Bernoullis.\nImportant take-away: the law of large numbers says that if we take the average of a bunch of independent RVs, the average will be close to the expected value.\n\nSometimes it’s hard to compute the expected value exactly (e.g., because the math is hard– not all sums are nice!)\nThis is where Monte Carlo methods come in– instead of trying to compute the expectation exactly, we just generate lots of RVs and take their average!\nIf we generate enough RVs, the LLN says we can get as close as we want.\nWe’ll have lots to say about this in our lectures on Monte Carlo methods next week.\n\nVariance: formal definition\nAlso recall the variance is the expectation of the squared deviation from the mean, i.e: \\[\n\\operatorname{Var}(X)=\\mathbb{E}[(X-\\mathbb{E}X)^2]=\\sum_k (k-\\mu)^2 \\Pr[ X = k]\n\\] Similar to how the sample mean \\(\\bar{X}\\) converges to \\(\\mathbb{E}X\\), the sample variance \\(s^2\\) will converge to the true variance \\(\\sigma^2\\), i.e: \\[\n\\lim_{n\\to\\infty}\\frac1{n-1}\\sum_{i=1}^n(X_i-\\bar{X})^2=\\operatorname{Var}(X)\n\\]\n\n\n3.4.4 Geometric\nLet’s consider a different coin-flipping experiment. We flip a coin repeatedly and we count how many flips it takes before it lands heads.\nSo perhaps we flip the coin and it comes up heads immediately, in which case we would count zero (because there were no flips before the one where the coin landed heads). If we flipped the coin and it came up heads for the first time on the fourth toss, then we would count three, and so on.\nThis game describes the geometric distribution.\nIts behavior is controlled by a single parameter, the probability \\(p\\) of landing heads.\nThe geometric distribution is a natural model for “time to failure” experiments.\nFor example, suppose we install a light bulb, and measure how many days until the lightbulb burns out (one such experiment has been ongoing for a very long time!.\nWe can generate random geometric random variables using the rgeom function:\n\nrgeom(1, prob = 0.5) # Generate one geometric random variable with p=0.5. Most likely outcomes: 0,1,2\n\n[1] 0\n\n\nThe probability that a \\(\\operatorname{Geom}(p)\\) random variable \\(X\\) takes a particular value \\(k\\) (\\(k=0,1,2,\\dots\\)) is given by \\(\\Pr[ X = k ] = (1-p)^k p.\\)\nThis is the probability mass function of the geometric distribution. It assigns, to each singleton in the outcome space, a nonnegative number (i.e., its probability), and it does so in such a way that these nonnegative numbers sum to 1 (this ensures that these numbers do indeed specify a probability distribution!). Some texts will refer to this function as a distribution function, but I will avoid it in our notes and lectures, because there is possibility of confusion with other related terms (e.g., the cumulative distribution function, which we’ll see soon).\nLet’s plot this as a function of \\(k\\):\n\nlibrary(ggplot2)\nk &lt;- seq(0, 15)\np &lt;- 0.3\ndf &lt;- data.frame(\"k\" = k, \"Probk\" = p * (1 - p)^k)\npp &lt;- ggplot(df, aes(x = k, y = Probk)) +\n  geom_col()\npp\n\n\n\n\nLooking at the plot, we see that the geometric distribution puts most of its probability close to zero– the most likely outcomes are 0, then 1, then 2, and so on.\nWe plotted the distribution only up to \\(k=15\\), but a geometric random variable can, technically, take any non-negative integer as a value.\nFor any value of \\(k\\), \\(\\\\Pr[ X = k ] = p(1-p)^k\\) is non-zero (as long as \\(0 &lt; p &lt; 1\\)).\nSo for any non-negative integer, there is a small but non-zero probability that a geometric random variable takes that integer as a value.\nWe say that the geometric random variable has infinite support.\nThe support of a discrete random variable is the set of values that have non-zero probability mass. A random variable has infinite support if this set is infinite.\nExercise: verify that this is a bona fide probability by checking that \\(\\sum_{k=0}^\\infty p(1-p)^k = 1\\).\nNote: some resources follow a slightly different convention, whereby a geometric random variable counts the total number of attempts (i.e., coinflips) before success, so the support is \\(\\{1,2,\\dots\\}\\). Our discussion above follows the convention of most textbooks and research papers (and the convention followed by R– see ?rgeom), but this is an important thing to be aware of!\n\n\n3.4.5 Poisson\nLet’s look at one more discrete distribution.\nSuppose we are going fishing on lake Mendota, and we want to model how many fish we catch in an hour.\nA common choice for this situation is the Poisson distribution (named after a French mathematician named Poisson, but “poisson” is also French for “fish”).\nThe Poisson distribution is a common choice for modeling “arrivals” or other events that happen per unit time. Common examples include\n\ncustomers arriving to a store on a given day\ncalls to a phone line between 2pm and 3pm\nphotons or other particles hitting a detector during an experiment\ncars arriving at an intersection\n\nThe Poisson distribution has probability mass function \\[\n\\Pr[ X=k ] = \\frac{ \\lambda^k e^{-\\lambda} }{ k! }, ~ ~ ~ ~ ~ ~ k=0,1,2,\\dots\n\\] The parameter \\(\\lambda &gt; 0\\), often called the “rate parameter”, controls the average behavior of the random variable– larger choices of \\(\\lambda\\) mean that the resulting random variable is larger, on average (we will make this statement more precise in a few lectures). That is, the larger \\(\\lambda\\) is, the more arrivals happen per unit time– the larger \\(\\lambda\\) is, the higher the rate!\nWe can generate Poisson random variables using rpois:\n\nrpois(1, lambda = 10.5) # Generate Poisson RV with lambda=10.5 most likely value is 10.\n\n[1] 15\n\n\nWhat if I want several random Poissons, instead of just one?\nThe n argument to rpois (and all the other random variable generation functions) specifies a number of variables to generate.\nSo, for example, to get ten random Poissons, we can write\n\nrpois(10, lambda = 10.5) # Generate 10 Poisson RVs with the same parameter lambda=10.5\n\n [1]  8 17  9  9 13 12 10 13 11  7\n\n\nWhat does the probability mass function of the Poisson look like? Once again, the Poisson distribution has infinite support, since \\(\\Pr[X=k] &gt; 0\\) for all \\(k=0,1,2,\\dots\\) (check this!), but let’s plot its first few values.\n\nk &lt;- seq(0, 30)\nlambda &lt;- 10.5 # On average, we should get back the value 10.5,\ndf &lt;- data.frame(\"k\" = k, \"Probk\" = dpois(k, lambda))\npp &lt;- ggplot(df, aes(x = k, y = Probk)) +\n  geom_col()\npp\n\n\n\n\nThe function dpois above evaluates the Poisson probability mass function.\nThe R documentation calls this a density, which is correct, but… well, we will return to this.\nFor now, just remember “r for random”, “d for density”. rpois generates random Poisson variables, dpois evaluates its probability mass function.\n\n\n3.4.6 The Discrete uniform\nThe roll of a fair 6 sided die (or any \\(n\\)-sided die) can be modeled using a discrete uniform random variable. We will more often refer to the continuous uniform random variable, (which we’ll talk about shortly), but it’s worth mentioning that the roll of a die can be modeled easily.\nIn R, however, the discrete uniform is not a named distribution. Instead we would use the sample function. For example, suppose we wanted to simulate rolling a 6-sided die 100 times.\n\n# The sample function takes 3 important parameters.\n# x :      this can either be a vector of values to sample from\n#         or in this case simply the upper limit R will automatically\n#         create a vector from 1 to this value to sample from\n# size :   how many samples to generate\n# replace: this indicates whether we are able to re-sample the same value\n#         more than once. Careful, the default value is FALSE\nrolls &lt;- sample(x = 6, size = 100, replace = TRUE)\nrolls\n\n  [1] 6 5 1 2 4 1 2 2 4 3 3 3 1 4 4 1 3 6 6 4 6 1 3 6 5 5 3 4 1 1 5 3 5 6 6 1 5\n [38] 2 1 1 6 6 5 2 1 4 4 1 5 2 2 4 6 6 5 4 2 6 4 4 1 4 1 2 5 1 3 4 4 3 6 4 6 3\n [75] 5 1 5 5 5 5 5 5 3 6 3 1 4 2 4 6 6 1 5 1 2 4 6 3 6 5\n\n\n\n\n3.4.7 Aside: approximating one random variable with another\nInterestingly, we can obtain the Poisson distribution from the binomial distribution.\nLet’s make two assumptions about our fish population:\n\nThere are many fish in the lake. Let’s call the number of fish \\(N\\), which is a large number.\nFor each fish, there is a small probability \\(p\\) that we catch it (the same probability for each fish, for the sake of simplicity)\n\nIf we let \\(N\\) get arbitrarily large (“infinite” a limit like you remember from calculus) while \\(p\\) stays “small”, the Binomial distribution comes to be equal to the Poisson distribution with rate \\(Np\\).\nFor this reason, the Poisson is often a good approximation to the Bernoulli when \\(N\\) is large and \\(p\\) is small.\nJust to illustrate, let’s plot the density of the binomial with \\(N\\) really large and \\(p\\) really small, but chosen so that \\(Np = 10.5\\) to match \\(\\lambda = 10.5\\) above.\n\nk &lt;- seq(0, 30)\nlambda &lt;- 10.5\nN &lt;- 1e6\np &lt;- lambda / N # On average, we should get back the value lambda\npoisprob &lt;- dpois(k, lambda) # Vector of Poisson probabilities\nbinomprob &lt;- dbinom(k, size = N, prob = p) # Binomial probs.\n# We need a column in our data frame encoding which of the two distributions a number comes from.\n# This isn't the only way to do this, but it is the easiest way to get things to play nice with the ggplot2 facet_wrap, which displays separate plots for different values in a particular column.\ndist &lt;- c(rep(\"Poisson\", length(k)), rep(\"Binom\", length(k)))\n\n# Construct our data frame. Note that we have to repeat the k column, because our data frame is going to look like\n# Distribution  k  Probk\n# Poisson       0  dpois( 0, lambda )\n# Poisson       1  dpois( 1, lambda )\n# ...           ...\n# Poisson       30 dpois( 30, lambda )\n# Binomial      0  dbinom( 0, N, p )\n# ...\n# Binomial      30  dbinom( 30, N, p )\ndf &lt;- data.frame(\"dist\" = dist, \"k\" = rep(k, 2), \"Probk\" = c(poisprob, binomprob))\n\npp &lt;- ggplot(df, aes(x = k, y = Probk)) +\n  geom_col() +\n  facet_wrap(~dist)\n# facet_wrap tells ggplot to create a separate plot for each group (i.e., value) in the dist column.\npp\n\n\n\n\nWe will see several examples like this during the semester, in which two distributions become (approximately) equivalent if we fiddle with the parameters in the right way."
  },
  {
    "objectID": "rv.html#continuous-random-variables",
    "href": "rv.html#continuous-random-variables",
    "title": "3  Random Variables",
    "section": "3.5 Continuous random variables",
    "text": "3.5 Continuous random variables\nSo far we’ve seen a few different discrete random variables. Their set of possible values are discrete sets like \\(\\{0,1\\}\\) or \\(\\{0,1,2,\\dots\\}\\).\nThis is in contrast to continuous random variables, which take values in “continuous” sets like the interval \\([0,1]\\) or the real like \\(\\mathbb{R}\\).\nDiscrete random variables have probability mass functions, like \\(\\Pr[ X=k ] = p(1-p)^k\\), \\(k=0,1,2,\\dots\\).\nIn contrast, continuous random variables have probability density functions, which we will usually write as \\(f(x)\\) or \\(f(t)\\).\nThese random variables are a little trickier to think about at first, because it doesn’t make sense to ask about the probability that a continuous random variable takes a specific value. That is, \\(\\Pr[ X = k ]\\) doesn’t really make sense when \\(X\\) is continuous (actually– in a precise sense this does make sense, but the probability is always zero you’ll see why below).\nLet’s see some examples.\n\n3.5.1 Normal\nThe normal or Gaussian (after Carl Friedrich Gauss) random variable is undoubtedly the most fundamental in all of statistics.\nYou have likely heard of it before both in your previous courses and just… well, everywhere, in the form of the famous bell curve.\nThe normal distribution really is everywhere, and there are good reasons for this, which we will return to in a few lectures (see here for a preview).\nThe normal distribution is controlled by two parameters: a mean \\(\\mu \\in \\mathbb{R}\\) and a variance \\(\\sigma^2 &gt; 0\\).\nThe standard normal has \\(\\mu = 0\\) and \\(\\sigma^2 = 1\\), and it “looks like” this:\n\nx &lt;- seq(-4, 4, 0.1)\nf &lt;- dnorm(x, 0, 1) # eval density at x values, mean mu=0, standard deviation sigma=1.\ndf &lt;- data.frame(\"x\" = x, \"density\" = f)\npp &lt;- ggplot(df, aes(x = x, y = density)) +\n  geom_line(size = 1)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\npp\n\n\n\n\nThis is the probability density function of the standard normal. Of course, the curve extends out to infinity on the right and negative infinity on the left we just haven’t plotted it.\nHopefully this is a familiar shape to you. If not, no worries– you’ll see it plenty as you continue your studies.\nThis is a probability density, not a mass function, because to evaluate something like the probability that a normal random variable \\(X\\) falls between, say, \\(-1\\) and \\(1\\), we have to integrate the area under this curve between these two endpoints.\nThis is why we refer to this as a density– recall from physics that integrating a density over a region (i.e., a volume) gives us a mass (compare to the discrete case, where we did call it a probability mass function).\nSaid another way, integrating the density over a region gives us the probability of that region. So if \\(X\\) is a normal random variable with mean \\(\\mu\\) and variance \\(\\sigma^2\\), \\[\n\\Pr[ -1 \\le X \\le 1 ] = \\int_{-1}^1 f(t; \\mu, \\sigma^2) dt,\n\\] where \\(f(t; \\mu, \\sigma^2)\\) is the density function of the normal distribution, \\[\nf(t;  \\mu, \\sigma^2) = \\frac{1}{\\sqrt{ 2\\pi \\sigma^2 } } \\exp\\left\\{ \\frac{ -(t-\\mu)^2 }{ 2\\sigma^2 } \\right \\}.\n\\] The weird semicolon notation is to emphasize that the density is a function of \\(t\\), but its shape depends on \\(\\mu\\) and \\(\\sigma^2\\).\nThink of \\(\\mu\\) and \\(\\sigma\\) as two knobs we can twiddle to change the shape of the curve.\nChanging \\(\\mu\\) while keeping \\(\\sigma^2\\) fixed just shifts the distribution:\n\nx &lt;- seq(-6, 6, 0.1) # Some x values to evaluate at\nf1 &lt;- dnorm(x, -2, 1) # mean mu=-1, standard deviation sigma=1.\nf2 &lt;- dnorm(x, 0.5, 1) # mean mu=1.5, standard deviation sigma=1.\nf3 &lt;- dnorm(x, 1.5, 1) # mean mu=1.5, standard deviation sigma=1.\nmu &lt;- c(rep(-1, length(x)), rep(1.5, length(x)), rep(2.0, length(x)))\ndf &lt;- data.frame(\"x\" = rep(x, 3), \"density\" = c(f1, f2, f3), \"mean\" = as.factor(mu))\npp &lt;- ggplot(df, aes(x = x, y = density, color = mean)) +\n  geom_line(size = 1)\npp\n\n\n\n\nChanging \\(\\sigma\\) changes the standard deviation (and hence also the variance, \\(\\sigma^2\\)). Larger \\(\\sigma\\) means higher variance, which means a “wider” distribution:\n\nx &lt;- seq(-6, 6, 0.1) # Some x values to evaluate at\nf1 &lt;- dnorm(x, 0, 0.5) # mean 0, standard deviation sigma=1.\nf2 &lt;- dnorm(x, 0, 1) # mean 0, standard deviation sigma=2.\nf3 &lt;- dnorm(x, 0, 2) # mean 0, standard deviation sigma=3.\nsigma2 &lt;- c(rep(0.5, length(x)), rep(1, length(x)), rep(2, length(x)))\ndf &lt;- data.frame(\"x\" = rep(x, 3), \"density\" = c(f1, f2, f3), \"variance\" = as.factor(sigma2))\npp &lt;- ggplot(df, aes(x = x, y = density, color = variance)) +\n  geom_line(size = 1)\npp\n\n\n\n\nWe’ll have plenty more to say about this later in the semester when we talk about fitting models to data. For now, think back to our human heights example from our introductory lecture– we played with the \\(\\mu\\) and \\(\\sigma^2\\) parameters to find a normal distribution that “looked” a lot like our observed data.\nWe can generate normal random variables in R using the rnorm function:\n\nrnorm(1, mean = 1, sd = 2) # Note that we pass the standard deviation (sd), not the variance sigma^2.\n\n[1] 0.7080544\n\nrnorm(1) # If we don't specify a mean and sd, they default to 0 and 1, respectively\n\n[1] -1.023645\n\n\nLet’s generate a bunch of normal RVs and plot their (normalized) histogram:\n\n# Reminder: if mu, sigma unspecified, they default to mu=0, sigma=1\ndata &lt;- rnorm(1e6) # 1e6 = 1.0x10^6 = one million standard normal RVs\npp &lt;- ggplot(data.frame(\"x\" = data), aes(x = data))\npp &lt;- pp + geom_histogram(aes(y = ..density..), binwidth = 0.25, color = \"black\", fill = \"white\")\npp\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n\n\n\nNote that this is a normalized histogram– it is scaled so that the areas of the rectangles sums to 1, like a probability distribution.\nNow, let’s overlay the normal density function on this.\n\nx &lt;- seq(-5, 5, 0.1)\nf &lt;- dnorm(x, mean = 0, sd = 1) # Evaluating the density at points x\ndf_dnorm &lt;- data.frame(\"x\" = x, \"f\" = f)\npp &lt;- pp + geom_line(data = df_dnorm, aes(x = x, y = f), size = 1, color = \"red\")\npp\n\n\n\n\nLook at how closely the histogram matches the density! This is no accident. The density describes the average-case behavior of the random variable.\nBecause we plotted a standard normal, one unit on the x-axis of the plot above is one standard deviation.\nYou will hopefully recall from any previous statistics courses that a normal random variable falls\n\nwithin one standard deviation of the mean (i.e., between -1 and 1 in the plot above) with probability about 0.68,\nwithin two standard deviations of the mean (i.e., between -2 and 2 in the plot above) with probability about 0.9545\nwithin three standard deviations of the mean (i.e., between -3 and 3 in the plot above) with probability about 0.997.\n\nWe can approximately check this by counting how many of our simulated normals fall in these ranges. What fraction of these data points fell within one standard deviation of the mean?\n\nsum(data &gt; -1 & data &lt; 1) / length(data) # Should be about 0.68\n\n[1] 0.682746\n\n\n\nsum(data &gt; -2 & data &lt; 2) / length(data) # should be about 0.9545\n\n[1] 0.954521\n\n\n\nsum(data &gt; -3 & data &lt; 3) / length(data) # should be about 0.997\n\n[1] 0.99727\n\n\nOf course, because the data is random, the proportions are not exactly equal to their predicted values, but they are quite close.\nThis is a nice illustration of the law of large numbers!\n\n3.5.1.1 Computing probabilities\nNow, let’s check this fact by using R to compute probabilities of the form \\(\\Pr[ a \\le X \\le b ]\\) for a normal RV \\(X\\), where \\(a \\ge b\\). How can we compute this probability?\nLet’s start by writing something slightly different: \\[\n\\Pr[ X \\le b ] = \\Pr[ X \\le a ] + \\Pr[ a \\le X \\le b].\n\\]\nQuestion: why is this true? What “rule” of probability are we using?\nNow, let’s rearrange that expression: \\[\n\\Pr[ a \\le X \\le b] = \\Pr[ X \\le b ] - \\Pr[ X \\le a ].\n\\]\nHow exactly does this help us? We replaced one probability with a sum of two… that seems worse!\n…at least until I tell you (or you remember from previous courses) that for all the “nice” distributions, R makes it very easy to compute probabilities of the form \\(\\Pr[ X \\le a]\\). The function \\[\nF_X(t) = \\Pr[ X \\le t]\n\\] is called the cumulative distribution function (CDF) of \\(X\\).\nWe compute the CDF of the normal in R with pnorm. So, for example, to compute the probability that a standard normal random variable is \\(\\le 0\\), we can write\n\npnorm(0) # Once again, mu, sigma default to 0,1.\n\n[1] 0.5\n\n\nAside/exercise: You might enjoy spending some time thinking on why it is “obvious” that a normal random variable is less than or equal to its mean with probability one half. Remember (look at the density function above, or just look at our plots) that the normal density is symmetric about the mean \\(\\mu\\). If you’re feeling up to it (warning: calculus ahead!), you can try computing the appropriate integrals to show that under the normal, \\(\\Pr[ X \\le \\mu ] = \\Pr[ X &gt; \\mu ] = 1/2\\).\nSo suppose that we want to compute the probability that a standard normal random variable is less or equal to 1. This would be\n\npnorm(1) # again, recall the default behavior.\n\n[1] 0.8413447\n\n\nAnd to compute the probability that we are within one standard deviation of the mean, we need to compute \\[\n\\Pr[ -1 \\le X \\le 1] = \\Pr[ X \\le 1 ] - \\Pr[ X \\le -1 ] = \\texttt{ pnorm(1) - pnorm(-1) }\n\\]\nThat is,\n\npnorm(1) - pnorm(-1)\n\n[1] 0.6826895\n\n\nwhich matches our 0.68-.9545-0.997 rule so far. Let’s check the other two.\n\npnorm(2) - pnorm(-2)\n\n[1] 0.9544997\n\n\n\npnorm(3) - pnorm(-3)\n\n[1] 0.9973002\n\n\nBy the way, if you’ve seen this bell-shaped curve before in your classes, you probably associate it with Z-scores and the magic number 1.96.\nWe’ll see a bit of that this semester, but for the most part, we will use Monte Carlo simulation to do testing.\nThis is a different approach to statistics that lets us avoid worrying so much about Z-tables and 1.96 and all that, but in the interest of full disclosure: really most of the basic parts of R are just fancy Z-tables. So R does the annoying work for us!\n\n\n\n3.5.2 Recap: RVs in R (so far)\nSo far, we have seen three functions for working with different distributions.\nFor the normal, we have rnorm, dnorm and pnorm, corresponding to random variable generation, the density function and cumulative distribution function (CDF), respectively.\nOther RVs have similar patterns. For example, with the geometric random variable, we have rgeom, dgeom and pgeom, which work analogously to the normal case.\nThere is one more of these functions yet to come, but we aren’t quite ready to introduce it.\n\n\n3.5.3 Aside: Expectation for continuous random variables\nPreviously, we defined the expectation of a discrete random variable \\(X\\) to be \\[\n\\mathbb{E} X = \\sum_k k \\Pr[ X = k ],\n\\] with the summand \\(k\\) ranging over all allowable values of \\(X\\).\nWhen \\(X\\) is continuous, the sum doesn’t make sense, so how should we define the expectation?\nWell, just change the sum to an integral! After all, the integral sign is just a fancy S for “sum” (okay, it’s for the Latin word “summa” or something along those lines, but close enough!).\n\\[\n\\mathbb{E} X = \\int_\\Omega t f(t) dt,\n\\]\nwhere \\(f(t)\\) is the density of \\(X\\) and \\(\\Omega\\) is the support.\nExercise: Let’s flex those calculus muscles! Check that the mean of a normal with mean \\(\\mu\\) and standard deviation \\(\\sigma\\) is indeed \\(\\mu\\). That is, check that \\[\n\\int_{-\\infty}^\\infty \\frac{ t }{ \\sqrt{ 2\\pi \\sigma^2}} \\exp\\left\\{ \\frac{ -(t-\\mu)^2 }{ 2\\sigma^2 } \\right\\} dt = \\mu.\n\\]\nHint: Make the substitution \\(u=t-\\mu\\) and use the facts that\n\n\\(f(t) = e^{-(t-\\mu)^2/2\\sigma^2}/\\sqrt{2\\pi \\sigma^2}\\) integrates to \\(1\\) (because it is a probability density), and\n\\(g(u) = u \\exp\\{ -u^2/2\\sigma^2 \\}\\) is symmetric about zero (and thus integrates to zero).\n\n\n\n3.5.4 Uniform\nThe uniform distribution is a continuous random variable whose density is constant on its outcome space.\nThat is, for continuous set \\(\\Omega \\subseteq \\mathbb{R}\\), the density is identically \\(f(t) = c\\).\nRemember that our probability has to sum to 1, but since we have a continuous support, this sum becomes an integral:\n\\[\n\\int_{\\Omega} f(t) dt = \\int_{\\Omega} c dt = c \\int_{\\Omega} 1 dt.\n\\]\nSo to make the probability integrate to \\(1\\), we need \\(c = \\int_{\\Omega} 1 dt\\).\nMost commonly, we take \\(\\Omega = [0,1]\\), and call the resulting random variable “uniform 0-1”, written \\(\\operatorname{Unif(0,1)}\\).\nThe density function of \\(\\operatorname{Unif(0,1)}\\) is then given by \\[\nf(t) = \\begin{cases}\n  1 &\\mbox{ if } 0 \\le t \\le 1 \\\\\n  0 &\\mbox{ otherwise. } \\end{cases}\n\\]\nExercise: check that this indeed integrates to \\(1\\), i.e., that it is a valid probability density. The support is \\([0,1]\\), so we need to check that \\(\\int_0^1 1 dt = 1\\).\nThe most common application of uniform random variables is in simulations when we need to make a random decision.\nFor example, suppose we didn’t have the Bernoulli distribution available to us for some reason, but we still wanted to generate random coin flips.\nTo generate a \\(\\operatorname{Bernoulli}(p)\\) random variable, we could first draw a uniform random variable \\(U \\sim \\operatorname{Unif}(0,1)\\) and then output \\(1\\) (or “heads” or “true”) if \\(U \\le p\\) and out put \\(0\\) (or “tails” or “false”) otherwise.\n\n\n3.5.5 Exponential\nLet’s look at one more continuous random variable.\nThe exponential distribution is most commonly used to model “waiting times”, like how long until the bus arrives.\nIn many ways, the exponential distribution is like the continuous version of the geometric distribution.\nLike geometric random variables, the exponential distribution is non-negative and is controlled by a single parameter \\(\\lambda &gt; 0\\), called the rate (because larger \\(\\lambda\\) means less time before the event, hence more events per unit time, i.e., a higher rate of events).\nThe density is given by \\[\nf(t  \\lambda ) = \\begin{cases}\n  \\lambda \\exp\\{ - \\lambda t \\} &\\mbox{ if } t \\ge 0 \\\\\n  0 &\\mbox{ otherwise. }\n  \\end{cases}\n\\]\nExercise: check that this defines a probability distribution by checking that for any \\(\\lambda &gt; 0\\), (1) \\(f(t \\lambda) \\ge 0\\) and (2) \\(\\int_0^\\infty f(t \\lambda) dt = 1\\).\nLet’s plot this density as a function of \\(t\\) for \\(\\lambda = 1\\).\n\nx &lt;- seq(0, 10, 0.1)\nf &lt;- dexp(x, rate = 1)\ndf_exp &lt;- data.frame(\"x\" = x, \"density\" = f)\npp &lt;- ggplot(df_exp, aes(x = x, y = density)) +\n  geom_line(size = 2)\npp\n\n\n\n\nLooking at the density, we see that most of the probability is near zero.\nRoughly, it looks like the vast majority of the time, \\(X \\sim \\operatorname{Exp}(1)\\) should be less than 5. Let’s check!\n\ndata &lt;- rexp(n = 1e6, rate = 1) # rexp to generate random exponentials.\nsum(data &lt; 5) / length(data) # something like 99% of the generated points should be below 5.\n\n[1] 0.993268\n\n\n\n\n\n3.5.6 Bonus: Building Bigger Models\nThere are plenty more named distributions out there. See here.\nIndeed, we can make all sorts of distributions– ultimately we just need to specify a support and a density or mass function, depending on whether we want a discrete or continuous variable.\nMore often, though, the processes out in the world that we want to model require that we build more complicated models from simple ones.\n\n\n3.5.7 Social network models\nSeveral professors in the statistics department study networks. A common example of these are social networks (e.g., Facebook and twitter).\nThese data usually take the form of a list specifying who is friends with whom.\nIn most models for social networks, each pair of people \\(i\\) and \\(j\\) become friends, independently, with some probability \\(p_{ij}\\).\nOften, these probabilities depend on other random variables.\n\nFor example, we might have a (random) number for every person that describes how much that person likes sports, and pairs of people who both have a high “sports score” are more likely to be friends (i.e., \\(p_{ij}\\) is higher).\n\nIn this way, we combine different elementary random variables (e.g., Bernoullis and normals) to yield more complicated distributions (say, a probability distribution over “possible social networks”).\nHaving obtained a network from Twitter or Facebook data, we apply all sorts of different functions to it that describe the network’s structure (e.g., compute shortest paths or eigenvectors, if you know what those are).\nIt is really difficult to do the math out exactly to determine analytically how these different functions behave.\nInstead, we often appeal to Monte Carlo methods, which we will discuss in the next lecture.\n\n\n3.5.8 Binomial asset pricing model\nAnother way to create new random variables is to take a function of another random variable. This is what happens in the pricing of “options” in finance.\nSuppose that \\(X\\) is the price of stock XYZ one month from today.\nAn “option” pays you \\(f(X)\\) on that day for some function \\(f\\).\nFor example, suppose stock XYZ costs $120 today and the function is\n\\[\nf(X)= \\begin{cases} 120−X &\\mbox{ if } X&lt;120 \\\\\n    0 &\\mbox{ otherwise. } \\end{cases}\n\\]\nThis is often referred to as a put option. It is essentially giving you the option to purchase the stock in one month and sell it at today’s price.\n\nIf the price goes up, you would not use that option and you would make zero (but not lose any additional money, such as the cost of buying the option in the first place).\nOtherwise, you would make \\(120−X\\).\nIn effect, you are betting that the price will go down.\n\nSuppose you are a bank and someone wants to purchase this put option. You need to determine the price.\nWhat would be the fair price to charge them?\nTo make a good guess, we need a model for the asset price \\(X\\).\nOnce we have such a model, we can derive analytical expressions for \\(f(X)\\) or use Monte Carlo methods, which we will discuss soon.\nOne of the simplest models for \\(X\\) is the Binomial Asset Pricing Model, which says that at every time step (e.g., every minute), the price goes up by one penny with probability \\(p\\), or down by one penny with probability \\(1−p\\).\nIn this example, both \\(X\\) and \\(f(X)\\) are random variables.\nQuestion: The Binomial Asset Pricing Model is a very simple model, especially given how complicated the stock market is. Can you think of any possible problems with the model?\n\n\n3.5.9 Election models\nWill the Democratic (D) or Republican (R) presidential candidate win Wisconsin in 20xx?\nWhat is the distribution of this random variable \\(W\\), where \\(W=−1\\) if D and \\(W=1\\) if R?\nWhat about neighboring Michigan \\(M \\in \\{-1,1\\}\\)?\nWisconsin and Michigan are not so different, so if we find out that the Republican candidate won Michigan (i.e., we learn about \\(M\\)), then that certainly tells us something about \\(W\\).\nThat is to say, \\(W\\) and \\(M\\) are not independent.\nWhat if we wanted to model both Wisconsin and Michigan together?\nWe usually write this as a pair \\((W,M)\\).\nOne thing you could do is model the proportion of votes for D vs R in Wisconsin (ignoring third parties) as normally distributed.\n\nPerhaps you consider this to be \\(W_p \\sim \\operatorname{Normal}(1/2,.05)\\).\nThen, \\(W\\) is 1 if \\(W_p&gt;.5\\) and \\(W=−1\\) if \\(W_p&lt;.5\\).\n\nThis helps because we can do the same thing for \\(M\\), based on and \\(M_p\\).\nWe can model \\((W_p,M_p)\\) as being correlated via the multivariate normal.\nTo simulate these, you need to specify both the mean, which is now a two-dimensional “vector” and a covariance matrix \\(\\Sigma \\in \\mathbb{R}^{2 \\times 2}\\).\nThe diagonal of the matrix \\(\\Sigma\\) specifies the variances of \\(W_p\\) and \\(M_p\\) respectively, and the off-diagonal \\(\\Sigma_{1,2}\\) specifies the covariance between \\(W_p\\) and \\(M_p\\).\nIf you haven’t heard of covariance before, think of it like a measure of how closely two variables track one another, similar to correlation.\n\nWhen the covariance is large and positive, the two variables tend to track one another.\nIf the covariance is large and negative, the two variables are inversely related to one another.\n\nLet’s try simulating some election results.\n\nmu &lt;- c(.5, .5) # Vector of means both W_p and M_p are mean 1/2.\nCovMx &lt;- matrix(c(.05^2, .04^2, .04^2, .05^2), nrow = 2) # Make a two-by-two symmetric matrix.\nCovMx\n\n       [,1]   [,2]\n[1,] 0.0025 0.0016\n[2,] 0.0016 0.0025\n\n\n\nlibrary(MASS) # This library includes a multivariate normal\n\nWarning: package 'MASS' was built under R version 4.2.3\n\nWpMp &lt;- mvrnorm(n = 2000, mu = mu, Sigma = CovMx) # mvrnorm is the multivariate version of rnorm.\nplot(WpMp, xlab = \"Wisconsin proportion\", ylab = \"Michigan proportion\")\nlines(c(.5, .5), c(-10, 10), col = \"red\")\nlines(c(-10, 10), c(.5, .5), col = \"red\")\n\n\n\n\nEach point in this plot corresponds to one simulated election.\nQuestions:\n\nWhat region of this plot corresponds to \\(W=−1\\) and \\(M=+1\\)?\nDoes it make sense that there are fewer points in the top left compared to the top right?\nAre Michigan and Wisconsin positively or negatively correlated (based on this plot, anyway)?\n\n\n\n3.5.10 Review:\nIn these notes we covered:\n\nThe basic rules of probability: outcome spaces, events\nthe concept of a random variable\nFamilies of discrete random variables: Bernoulli, binomial, geometric, Poisson and uniform\nFamilies of continuous random variables: Gaussian (normal), exponential and uniform\nThe concept of expected value\nPMF, PDF and CDF\ncomputing probabilities\nsome applications of random variables"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "References"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT 340: Data Science II",
    "section": "",
    "text": "Here are the course notes, practice problems and other course materials for STAT 340 at UW Madison.\nAuthor credits to Bi Cheng Wu, Brian Powers, Keith Levin\nExample shiny live app\nNormal PDF CDF Inverse CDF"
  },
  {
    "objectID": "intro.html#what-is-data-science",
    "href": "intro.html#what-is-data-science",
    "title": "2  Introduction",
    "section": "2.3 What is data science?",
    "text": "2.3 What is data science?\nIs “data science” just a rebranding of applied statistics?\nWell, perhaps, to an extent. But the emergence of “data science” has coincided with huge changes in how science and statistics gets done.\nComputers and the internet have made it easy to collect, share and analyze data in ways that were unimaginable only a decade or two ago.\nSeveral times this semester, we will talk about fundamental parts of the data science toolkit that are usable only because computers are fast and cheap.\nThis change in technology has changed how we do science. In this sense, “data science” is a culture or a way of thinking, more than it is a field."
  },
  {
    "objectID": "intro.html#wearing-different-hats",
    "href": "intro.html#wearing-different-hats",
    "title": "2  Introduction",
    "section": "2.4 Wearing different hats",
    "text": "2.4 Wearing different hats\nBeing a good data scientist requires that we be able to draw on many different fields and ways of thinking.\nA “well rounded” data scientist should move fluidly among multiple ways of thinking and approaching a problem.\nHere are a few of the different kinds of hats I (Keith) find myself wearing in my day-to-day work:\n\nscientist: understanding data domain, developing questions, “story telling”\nsoftware dev: data processing and wrangling / reproducibility\nmathematician: linear algebra, probability theory, optimization\nmethodologist: regression, unsupervised learning, visualizations\nscience communicator: summarizing results, explaining broader impacts\n\nThis hints at why it is so hard to become a truly good data scientist– you need to be pretty good at a lot of different things.\nIf nothing else, going into this line of work requires that you be ready and willing to be a life-long student There are always new techniques, methods, frameworks and application domains to be learned!"
  },
  {
    "objectID": "intro.html#topics-covered",
    "href": "intro.html#topics-covered",
    "title": "2  Introduction",
    "section": "2.5 Topics covered",
    "text": "2.5 Topics covered\nWe will cover five basic topics this semester:\n\nSampling\nEstimation\nTesting\nPrediction\nObservational/exploratory data analysis\n\nLet’s briefly discuss each of these.\n\n2.5.1 Sampling\nElection polls and other survey data often get reported with response rates and other details about how survey respondents were selected.\nExample: At the end of October 2020, pollsters were trying to predict the outcome of the 2020 presidential election. A common technique for this is “random digit dialing”, which is exactly what it sounds like.\nThis poll reached 806 registered voters in Wisconsin. After a significant amount of statistical work, the pollsters reported that\n\n48% of likely voters would choose Biden\n43% would vote for Trump\n2% for Jorgensen, and\n7% remained undecided.\n\nIn order to reach those 806 participants, many more numbers need to be dialed. In this poll, the response rate was 4.3%. If you read the methodology report, you’ll see that in fact over 100,000 numbers had to be dialed to get these 806 respondents. The vast majority of those 100,000 calls were never picked up. Among those who did pick up, 806 were registered voters and agreed to participate in the survey, but another were 1113 refused to participate (or hung up).\nIn the actual election,\n\nBiden received 49.45% of votes cast in Wisconsin and\nTrump received 48.82%.\n\nQuestions:\n\nHow does this compare with the predicted vote shares of 48% for Biden and 43% for Trump?\nHow might we explain the discrepancies?”\n\n\n\n2.5.2 Testing\nYou have no doubt heard that “correlation does not imply causation”. Well, this is true.\n\nIce cream consumption is correlated with drowning, but we don’t think that ice cream causes drowning.\nHospitals are full of sick people, but we don’t think that hospitals cause sickness.\n\nNonetheless, to paraphrase a relevant comic, causality often does give awfully strong hints.\n\n\n\nCredit: Randall Munroe, XKCD (https://xkcd.com/552)\n\n\nExample: On November 16, 2020 Moderna released results from their phase 3 clinical trial for their COVID-19 vaccine.\nThere were approximately 30,000 people in the trial, split (approximately) evenly between treatment (got the vaccine) and control (got a placebo).\n\nIn total, there were 95 cases of COVID-19 among the participants; 90 among the placebo group and 5 among the treated group.\nOf the 95 cases, 11 were severe cases, all in the placebo group.\n\nIn this study, vaccination is correlated with reduced risk of infection.\n\nDoes this mean that the vaccination causally reduced COVID-19 infection? Why or why not?\nHow do we know that we aren’t fooling ourselves when we say that the Moderna vaccine is effective?\n\n\n\n2.5.3 Estimation\nThe news is perpetually full of stories about different economic indicators and how they are changing over time.\n\nThe Consumer Price Index (CPI) is meant to measure the change over time in prices of consumer goods and services.\nMost surveys (e.g., public opinion or election surveys) are reported with a +/- 3% “confidence interval” or “sampling error”.\n\nWhat is that all about?\nExample: In the Wisconsin poll discussed above, the margin of error was reported to be +/- 4.3%.\nRecall that the pollsters predicted 48% of likely voters would choose Biden and 43% Trump, while the actual outcome was 49.45% for Biden and 48.82% for Trump.\n\nIs this outcome within the stated margin of error?\nMore generally, what does it mean to give a confidence interval for a quantity of interest?”\n\n\n\n2.5.4 Prediction\nInvesting successfully (in real estate, stocks, etc) requires that we be able to predict the future behavior of an asset based on what we know about it currently.\n\nBased on the size of a house, its proximity to schools or infrastructure, walkability of its neighborhood, etc., we might hope to predict its “true” price.\nMany psychology and sociology studies aim to predict future student outcomes based on performance on a standardized test\n\nIn these kinds of problems, our goal is to predict an outcome or response (e.g., house price) based on one or more predictors (e.g., square footage of the house).\nMost of machine learning is concerned with prediction problems. For example, labeling an image according to whether or not it contains a cat can be stated as a prediction problem.\nExample: this plot shows different people’s incomes (in tens of thousands of dollars per year) as a function of their years of education.\n\n\n\nEducation by income\n\n\nIt certainly looks like more years of education correlate with higher income.\nQuestion: Suppose I tell you that someone has 18 years of education. What would you predict their income to be?\n\n\n2.5.5 Observational/exploratory data analysis\nSuppose that a colleague or client gives you a data set that looks like this:\n\nWhat would you do? There is clearly some kind of a cluster structure present here.\nThe goal of exploratory data analysis is to identify interesting structures in our data that might warrant further study.\nExample: In my own research, I (Keith) collaborate a lot with neuroscientists, who are interested in identifying functional subnetworks of the brain. These are groups of neurons that work together, typically because they are associated with the same activity (e.g., attention, motion, speech).\nThis is an example of clustering, in which our goal is to group data points in a sensible way, without necessarily saying ahead of time what those groups mean\nOftentimes, we obtain observational data. That is, data that does not come from a carefully-designed experiment.\nExample: Much data in the modern age of “big data” is collected by scraping the web or collected in other “messy” ways.\n\nScraping data from a social media site such as Twitter.\nMeasuring the socioeconomic status of people in different zip codes\n\nThere are lots of interesting scientific questions we might like to ask about such a data set, but because this data isn’t the result of a carefully-controlled experiment, we are often much more limited in what we can say."
  },
  {
    "objectID": "intro.html#world-data-model-hat-tip-to-karl-rohe",
    "href": "intro.html#world-data-model-hat-tip-to-karl-rohe",
    "title": "2  Introduction",
    "section": "2.6 World, Data, Model (hat tip to Karl Rohe)",
    "text": "2.6 World, Data, Model (hat tip to Karl Rohe)\nUnless you subscribe to some rather outlandish philosophical beliefs (see, e.g., here), there is a world out there, which we would like to learn about.\nTo figure things out about the world, we take measurements. That is to say, we collect data. These data describe the world, but it remains to build a model that explains how these data came to be.\nThe process of inference is how we use a specific set of data to guide our beliefs about the world.\nAs a simple example, consider human height. What is the average adult human height?\nThis is a question about the world. In fact, we could compute the average adult human height exactly if we could go out and measure the height of every adult human.\n\nOf course this would be a complicated and expensive process.\nInstead, we could just measure the heights of a few adult humans (say, a few thousand).\n\nOf course, this small collection of humans would need to be chosen randomly and in such a way that they would be representative of the population as a whole, but let’s ignore that concern until later in the course.\nThe few thousand heights that we measure would constitute our data– measurements that were taken out there in the world.\nHere is a simulation of what that data might look like with a sample of size 2000.\n\n# heights.R contains code for generating our synthetic data set.\nsource('r_scripts/heights.R');\n\nLoading required package: ggplot2\n\npp &lt;- ggplot( df_heights, aes(x=heights ) );\npp &lt;- pp + geom_histogram(aes(y=..density..), fill=\"grey\", color=\"black\", binwidth=2, );\npp &lt;- pp + geom_vline(xintercept=mean(heights), color=\"black\", linetype='f8', linewidth=1);\npp\n\n\n\n\nThe vertical dashed line indicates the mean of these 2000 sampled heights.\nBecause this is a random sample (and because heights vary due to factors like nutrition and genetics), this sample mean need not be equal to the population mean (i.e., the true average adult human height).\nInstead, the heights in our sample (and their mean) will vary randomly about the population average height. We use a statistical model (i.e., probability theory) to describe this variation.\nA common choice for modeling random variation like this is the normal distribution (in the coming lectures we will see plenty of other distributions).\nWe assume that our data are generated by a normal distribution with some mean \\(\\mu\\) (i.e., the average height) and some standard deviation \\(\\sigma\\). We call these parameters of the model.\nEstimating the population average height then reduces to estimating the “true” value of the parameter \\(\\mu\\) based on the data.\nThis step of using our data to determine something about our model is called inference. In this case, our goal is to estimate the value of the model parameter \\(\\mu\\), which will in turn be our estimate of the average adult human height."
  },
  {
    "objectID": "intro.html#all-models-are-wrong-but-some-are-useful",
    "href": "intro.html#all-models-are-wrong-but-some-are-useful",
    "title": "2  Introduction",
    "section": "2.7 All models are wrong, but some are useful",
    "text": "2.7 All models are wrong, but some are useful\nAn important point in our human height example above was our assumption that heights are normally distributed. In practice, modeling assumptions like these are never strictly true.\nOur model is just that– a model of the world; a set of simplifying assumptions that we hope are at least a good approximation to the truth.\nThink of your physics courses, where we assume that things happen in a frictionless void and use Newtonian mechanics instead of quantum mechanics.\nWe make assumptions like these because they often make the math easier while still being a good approximation to reality.\nIn our example above, the normal distribution with mean \\(\\mu\\) and standard deviation \\(\\sigma\\) says that with some (perhaps very small) probability, we might observe a negative number.\nIf we model human heights as being normally distributed, our model predicts that we should, on occasion, meet people who have negative height.\n\nWhy might that be a problem?\nWhy might it be okay to still use this model anyway?\n\nLet’s push ahead and “fit” a normal to our data. We’ll have lots to say about this later. For now, think of this as choosing, out of all the possible normal distributions, the one that “best agrees”” with our data.\n\n# The dataframe df_normal contains a column of x-values in the same range as our synthetic data.\n# df_normal$y contains the normal pdf with mean and standard deviation fit to our synthetic data,\n# evaluated at these x-values.\npp &lt;- pp + geom_line( aes(x=df_normal$x, y=df_normal$y), size=1, color='red' );\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\npp\n\n\n\n\nHuh. Our data seems to be a bit “flatter” than the normal distribution would predict.\nPerhaps this is just due to random fluctuation, but in fact there is a very simple reason for this: We didn’t tell you about it, but this sample includes both males and females.\nLet’s plot the same histogram, but this time, let’s break out the heights according to sex.\n\npp &lt;- ggplot( df_heights, aes(x=heights, color=sex, fill=sex ) );\npp &lt;- pp + geom_histogram( aes(y=..density..), position=\"identity\", alpha=0.5, binwidth=2);\npp\n\n\n\n\nHuman heights are bimodal– female heights are approximately normal about some mean, and male heights are approximately normal about another.\nWe can fit a normal to each of these separately and we see that our model agrees with the data much better.\n\n# df_bimodal$x contains x values that agree with the range of our height data.\n# df_bimodal$density is the density of a normal distribution, fit to the male or female heights,\n#        evaluated at these x-values.\n# df_bimodal$sex encodes male/female\\n\",\npp &lt;- pp + geom_line(data=df_bimodal, aes(x=x, y=density, color=sex), size=2, alpha=0.5);\npp\n\n\n\n\nThis is a good (albeit simple) illustration of the kind of iterative workflow that we typically use in data science.\n\nWe obtain our data, fit a model to it, and then we examine the shortcomings of that model.\nAfter some thought, it becomes clear how to improve our model.\nWe implement those changes (in this case, we incorporated the variable sex into our model), and examine our findings again.\n\nTypically, we repeat this cycle several times before reaching a conclusion that we are confident in."
  },
  {
    "objectID": "intro.html#overview",
    "href": "intro.html#overview",
    "title": "2  Introduction",
    "section": "2.1 Overview",
    "text": "2.1 Overview\nIn this introductory set of notes, we will:\n\nget a flavor for what data science is\ndiscuss why you might want to take a course like this one and\nhighlight the topics that we will cover this semester."
  },
  {
    "objectID": "intro.html#motivating-questions",
    "href": "intro.html#motivating-questions",
    "title": "2  Introduction",
    "section": "2.2 Motivating Questions",
    "text": "2.2 Motivating Questions\nConsider the following questions:\n\nHow effective is the Pfizer vaccine against the delta variant of COVID-19?\nDo early intervention programs (e.g., Head Start) improve educational outcomes for low-income children?\nAre record-high temperatures in recent years explainable by chance?\n\nThese questions are a little too complicated for an introductory course like this, but they are the kinds of questions that data science is equipped to answer.\nOur job as data scientists is to draw on tools from statistics, computer science and mathematics, in collaboration with domain experts, to answer questions like these.\nThat being said, collecting, cleaning and analyzing data is only part of the job.\nThe most important skill you will learn in this course is not a statistical or computational tool (though those are important!). It is the abilitity to clearly organize and explain your findings in a way that is appropriate for your intended audience."
  },
  {
    "objectID": "cov.html#learning-objectives",
    "href": "cov.html#learning-objectives",
    "title": "4  Independence, Conditional Probability and Bayes’ Rule",
    "section": "4.1 Learning objectives",
    "text": "4.1 Learning objectives\nAfter this lesson, you will be able to\n\nExplain what it means for variables to be dependent or independent and assess how reasonable independence assumptions are in simple statistical models.\nExplain expectations and variances of sums of variables are influenced by the dependence or independence of those random variables.\nExplain correlation, compute the correlation of two random variables, and explain the difference between correlation and dependence.\nDefine the conditional probability of an event \\(A\\) given an event \\(B\\) and calculate this probability given the appropriate joint distribution.\nUse Bayes’ rule to compute \\(\\Pr[B \\mid A]\\) in terms of \\(\\Pr[A \\mid B]\\), \\(\\Pr[A]\\) and \\(\\Pr[B]\\)."
  },
  {
    "objectID": "cov.html#recap-rvs-events-and-independence.",
    "href": "cov.html#recap-rvs-events-and-independence.",
    "title": "4  Independence, Conditional Probability and Bayes’ Rule",
    "section": "4.2 Recap: RVs events and independence.",
    "text": "4.2 Recap: RVs events and independence.\nWhen working with random variables, we start with a set of possible outcomes, usually denoted \\(\\Omega\\).\nA subset \\(E \\subseteq \\Omega\\) of the outcome space is called an event.\nA probability is a function that maps events to numbers, with the properties that\n\n\\(\\Pr[ E ] \\in [0,1]\\) for all events \\(E\\)\n\\(\\Pr[ \\Omega ] = 1\\)\nFor \\(E_1,E_2 \\in \\Omega\\) with \\(E_1 \\cap E_2 = \\emptyset\\), \\(\\Pr[ E_1 \\cup E_2 ] = \\Pr[ E_1 ] + \\Pr[ E_2 ]\\)\n\nNote: If \\(\\Pr[E_1 \\cap E_2]=\\emptyset\\), we say that \\(E_1\\) and \\(E_2\\) are mutually exclusive (or disjoint)\nWe say that two events \\(E_1\\) and \\(E_2\\) are independent if \\(\\Pr[ E_1 \\cap E_2 ] = \\Pr[ E_1 ] \\Pr[ E_2 ]\\). Note that it is very common to write \\(\\Pr[ E_1, E_2]\\) to mean \\(\\Pr[ E_1 \\cap E_2 ]\\). We usually read that as “the probability of events \\(E_1\\) and \\(E_2\\)” or “the probability that \\(E_1\\) and \\(E_2\\) occur”.\nTwo random variables \\(X\\) and \\(Y\\) are independent if for all sets \\(S_1,S_2\\), we have \\(\\Pr[ X \\in S_1,~ Y \\in S_2 ] = \\Pr[ X \\in S_1 ] \\Pr[ Y \\in S_2 ]\\).\nRoughly speaking, two random variables are independent if learning information about one of them doesn’t tell you anything about the other.\n\nFor example, if each of us flips a coin, it is reasonable to model them as being independent.\nLearning whether my coin landed heads or tails doesn’t tell us anything about your coin.\n\n\n4.2.1 Example: dice and coins\nSuppose that you roll a die and I flip a coin. Let \\(D\\) denote the (random) outcome of the die roll, and let \\(C\\) denote the (random) outcome of the coin flip. So \\(D \\in \\{1,2,3,4,5,6\\}\\) and \\(C \\in \\{H,T\\}\\). Suppose that for all \\(d \\in \\{1,2,3,4,5,6\\}\\) and all \\(c \\in \\{H,T\\}\\), \\(\\Pr[ D=d, C=c ] = 1/12\\).\nQuestion: Verify that the random variables \\(D\\) and \\(C\\) are independent, or at least check that it’s true for two particular events \\(E_1 \\subseteq \\{1,2,3,4,5,6\\}\\) and \\(E_2 \\subseteq \\{H,T\\}\\).\n\n\n4.2.2 Example: more dice\nSuppose that we roll a six-sided die. Consider the following two events: \\[\n\\begin{aligned}\nE_1 &= \\{ \\text{The die lands on an even number} \\} \\\\\nE_2 &= \\{ \\text{The die lands showing 3} \\}.\n\\end{aligned}\n\\]\nAre these two events independent? Our intuitive definition of independence is that learning about one event shouldn’t change the probability of the other event. These two events surely fail that test: if I tell you that the die landed on an even number, then it’s certainly impossible that it landed showing a 3, since 3 isn’t even.\nLet’s verify this intuition by checking that these two events fail the formal definition of independence. That is, let’s verify that \\[\n\\Pr[ E_1 \\cap E_2 ] \\neq \\Pr[ E_1 ] \\Pr[ E_2 ].\n\\]\nThere are six sides on our die, numbered 1, 2, 3, 4, 5, 6, and three of those sides are even numbers, so \\(\\Pr[ E_1 ] = 1/2\\).\nThe probability that the die lands showing 3 is exactly \\(\\Pr[ E_2 ] = 1/6\\).\nPutting these together, \\(\\Pr[E_1] \\Pr[E_2] = 1/12\\).\nOn the other hand, let’s consider \\(E_1 \\cap E_2\\). This is the event that the die lands showing an even number and it lands showing three. These two events cannot both happen!\nThat means that \\(E_1 \\cap E_2 = \\emptyset\\). That is, the intersection of these two events is the empty set. The laws of probability require that \\(\\Pr[ \\emptyset ] = 0\\) (Aside: why? Hint: \\(\\Pr[ \\Omega ] = 1\\) and \\(\\emptyset \\cap \\Omega = \\emptyset\\); now use the fact that the probability of the union of disjoint events is the sum of their probabilities).\nSo we have \\[\n\\Pr[ E_1 \\cap E_2 ] = 0 \\neq \\frac{1}{12} =\\Pr[ E_1 ] \\Pr[ E_2 ].\n\\]\nOur two events are indeed not independent.\nImportant note: it’s not always so obvious that two events are independent! Any probability textbook will have a collection of good examples of less intuitive independent and dependent events."
  },
  {
    "objectID": "cov.html#independent-random-variables",
    "href": "cov.html#independent-random-variables",
    "title": "4  Independence, Conditional Probability and Bayes’ Rule",
    "section": "4.3 Independent Random Variables",
    "text": "4.3 Independent Random Variables\nWhat do we mean by independent random variables? Well, a strict, formal definition is going to have to wait for a future math class.\nFor this semester, we’ll say that two random variables \\(X\\) and \\(Y\\) are independent if any two events concerning those random variables are independent.\nThat is, for any event \\(E_X\\) concerning \\(X\\) (i.e., \\(E_X = \\{ X \\in S \\}\\) for \\(S \\subseteq \\Omega)\\) and any event \\(E_Y\\) concerning \\(Y\\), the events \\(E_X\\) and \\(E_Y\\) are independent.\nSaid another way, if two random variables \\(X\\) and \\(Y\\) are independent, then for any two sets \\(S_1, S_2 \\subset \\Omega\\), \\[\n\\Pr[ X \\in S_1, Y \\in S_2 ]\n=\n\\Pr[ X \\in S_1] \\Pr[ Y \\in S_2 ].\n\\]\nIn particular, if \\(X\\) and \\(Y\\) are both discrete, then for any \\(k\\) and \\(\\ell\\), \\[\n\\Pr[ X=k, Y=\\ell ]\n=\n\\Pr[ X=k ] \\Pr[ Y=\\ell ].\n\\]\nSimilarly, if \\(X\\) and \\(Y\\) are continuous, then the joint density has the same property: \\[\nf_{X,Y}(s,t) = f_X(s) f_Y(t).\n\\]\nDon’t worry about these mathematical details too much at this stage– We just want to make sure that you’ve seen a little bit of this so that it isn’t completely new to you when you go off and do your readings and, more importantly, when you see these ideas in your later classes."
  },
  {
    "objectID": "cov.html#independence-expectation-and-variance",
    "href": "cov.html#independence-expectation-and-variance",
    "title": "4  Independence, Conditional Probability and Bayes’ Rule",
    "section": "4.4 (in)dependence, expectation and variance",
    "text": "4.4 (in)dependence, expectation and variance\nRecall the definition of the expectation of a random variable \\(X\\) with outcome set \\(\\Omega\\), \\[\n\\mathbb{E} X = \\int_\\Omega t f_X(t) dt,\n\\]\nif \\(X\\) is continuous with density \\(f_X\\), and \\[\n\\mathbb{E} X = \\sum_{k \\in \\Omega} k \\Pr[X=k]\n\\]\nif \\(X\\) is discrete with probability mass function \\(\\Pr[ X=k]\\).\nWith the expectation defined, we can also define the variance, \\[\n\\operatorname{Var} X = \\mathbb{E} (X - \\mathbb{E} X)^2\n= \\mathbb{E} X^2 - \\mathbb{E}^2 X.\n\\]\nThat second equality isn’t necessarily obvious– we’ll see why it’s true in a moment.\nNote: we often write \\(\\mathbb{E}^2 X\\) as short for \\((\\mathbb{E} X)^2\\). This is standard notation, but it’s sometimes a source of confusion to beginner students, so be careful!\nA basic property of expectation is that it is linear. For any constants (i.e., non-random) \\(a,b \\in \\mathbb{R}\\), \\[\n\\mathbb{E} (a X + b) = a \\mathbb{E} X + b.\n\\] If \\(X,Y\\) are random variables, then \\[\n\\mathbb{E}( X + Y) = \\mathbb{E} X + \\mathbb{E} Y.\n\\]\nThis linearity of expectation property may look/sound a bit weird, but this isn’t the first time you’ve seen it– derivatives and integrals are linear, too! For example, \\[\n(a ~f(t) + b ~g(t))' = a ~ f'(t) + b ~g'(t)\n\\]\nand \\[\n\\int(a f(t) + b g(t)) dt = a \\int f(t) dt + b \\int g(t) dt\n\\]\nBecause expected value is simply an integral (or summation), the linearity of expectation follows directly from the definition.\nExercise: prove that \\(\\mathbb{E} (a X + b) = a \\mathbb{E} X + b\\) for discrete r.v. \\(X\\).\nExercise: prove that \\(\\mathbb{E}( X + Y) = \\mathbb{E} X + \\mathbb{E} Y\\) for discrete \\(X\\) and \\(Y\\).\nExercise: Use the linearity of expectation to prove that \\(\\mathbb{E} (X - \\mathbb{E} X)^2 = \\mathbb{E} X^2 - \\mathbb{E}^2 X\\). Hint: \\(\\mathbb{E}( X \\mathbb{E} X) = \\mathbb{E}^2 X\\) because \\(\\mathbb{E} X\\) is NOT random– it pops right out of the expectation just like \\(a\\) does in the equation above.\nThe definition of variance and the linearity of expectation are enough to give us a property of variance:\nFor any constants (i.e., non-random) \\(a,b \\in \\mathbb{R}\\), \\[\n\\operatorname{Var} (a X + b) = a^2 \\operatorname{Var} (X).\n\\]\nExercise: Use the definition \\(\\operatorname{Var}(X)=\\mathbb{E} X^2 - \\mathbb{E}^2 X\\) to prove the above.\nThis linearity property implies that the expectation of a sum is the sum of the expectations: \\[\n\\mathbb{E}[ X_1 + X_2 + \\dots + X_n]\n= \\mathbb{E} X_1 + \\mathbb{E} X_2 + \\dots + \\mathbb{E} X_n.\n\\]\nWhat about variance? Is the variance of the sum the sum of the variances?\nWell, sadly, not always. To see why this isn’t always true, consider RVs \\(X\\) and \\(Y\\). \\[\n\\begin{aligned}\n\\operatorname{Var}(X + Y)\n&= \\mathbb{E}[ X + Y - \\mathbb{E}(X + Y) ]^2 \\\\\n&= \\mathbb{E}[ (X - \\mathbb{E} X) + (Y - \\mathbb{E} Y) ]^2,\n\\end{aligned}\n\\]\nwhere the second equality follows from applying linear of expectation to write \\(\\mathbb{E}(X+Y) = \\mathbb{E}X + \\mathbb{E}Y\\).\nNow, let’s expand the square in the expectation. \\[\n\\begin{aligned}\n\\operatorname{Var}(X + Y)\n&=\n\\mathbb{E}[ (X - \\mathbb{E} X) + (Y - \\mathbb{E} Y) ]^2 \\\\\n&= \\mathbb{E}[(X - \\mathbb{E} X)^2 + 2(X - \\mathbb{E} X)(Y - \\mathbb{E} Y)\n              + (Y - \\mathbb{E} Y)^2 ] \\\\\n&= \\mathbb{E} (X - \\mathbb{E} X)^2 + 2 \\mathbb{E} (X - \\mathbb{E} X)(Y - \\mathbb{E} Y) + \\mathbb{E} (Y - \\mathbb{E} Y)^2,\n\\end{aligned}\n\\] where the last equality is just using the linearity of expectation.\nNow, the first and last terms there are the variances of \\(X\\) and \\(Y\\): \\[\n\\operatorname{Var} X = \\mathbb{E}(X - \\mathbb{E} X)^2,~~~\n\\operatorname{Var} Y = \\mathbb{E}(Y - \\mathbb{E} Y)^2.\n\\] So \\[\n\\operatorname{Var}(X + Y)\n= \\operatorname{Var} X + 2 \\mathbb{E} (X - \\mathbb{E} X)(Y - \\mathbb{E} Y)\n  + \\operatorname{Var} Y.\n\\]\nSo what’s up with that middle term? This term might be familiar to you– it is (two times) the covariance of \\(X\\) and \\(Y\\), often written \\[\n\\operatorname{Cov}(X,Y)\n= \\mathbb{E}( X - \\mathbb{E}X)( Y - \\mathbb{E} Y).\n\\]\nNow, if \\(\\operatorname{Cov}(X,Y) = 0\\), then \\[\n\\operatorname{Var}(X + Y) = \\operatorname{Var} X + \\operatorname{Var} Y.\n\\]\nBut when does \\(\\operatorname{Cov}(X,Y) = 0\\)?\nWell, one sufficient condition is that \\(X\\) and \\(Y\\) be independent. That is, if \\(X\\) and \\(Y\\) are independent random variables, then \\(\\operatorname{Cov}(X,Y) = 0\\).\nNote: We will skip the proof that independence of \\(X\\) and \\(Y\\) implies \\(Cov(X,Y)=0\\), but you can find this proof in many places online."
  },
  {
    "objectID": "cov.html#uncorrelation-and-independence",
    "href": "cov.html#uncorrelation-and-independence",
    "title": "4  Independence, Conditional Probability and Bayes’ Rule",
    "section": "4.5 (Un)correlation and independence",
    "text": "4.5 (Un)correlation and independence\nCovariance might look familiar to you from a quantity that you saw in STAT240 (and a quantity that is very important in statistics!). The (Pearson) correlation between random variables \\(X\\) and \\(Y\\) is defined to be \\[\n\\rho_{X,Y} = \\frac{ \\operatorname{Cov}(X,Y) }{ \\sqrt{ (\\operatorname{Var} X)(\\operatorname{Var} Y)} }.\n\\]\nNote that if \\(X\\) and \\(Y\\) are independent, then \\(\\rho_{X,Y}=0\\) and we say that they are uncorrelated.\nBut the converse isn’t true– it is possible to cook up examples of random variables that are uncorrelated (i.e., \\(\\rho_{X,Y} = 0\\)), but which are not independent.\n\n4.5.1 Example: Uncorrelated but not independent\nSuppose \\(X \\sim Unif(-1, 1)\\) and \\(Y=X^2\\). You can see from the definition that \\(Y\\) is most definitely dependent on \\(X\\). If, for example, you know that \\(x=.5\\), then you know that \\(y=.5^2=.25\\). A proof that the covariance is zero is going to be difficult, but we can simulate some data to help us be confident that the claim is true.\n\nx &lt;- runif(10000, -1, 1)\ny &lt;- x^2\n\ncov(x,y)\n\n[1] 0.0003628265\n\n\nThe covariance of this sample of 10,000 observations of \\(X\\) and \\(Y\\) is very close to 0 (probably a little below or a little above due to randomness). The sample correlation is\n\ncor(x,y)\n\n[1] 0.002149034\n\n\nAgain - this is a number that is very close to zero.\n\n\n4.5.2 Example: sums of independent normals\nLet’s consider two independent normals: \\[\nX_1 \\sim \\operatorname{Normal}(1,1)\n~\\text{ and }~\nX_2 \\sim \\operatorname{Normal}(2,2).\n\\]\nSince \\(X_1\\) and \\(X_2\\) are independent,\n\nthe variance of their sum should be the sum of their variances, and\ntheir correlation should be zero\n\nLet’s check both of those facts in simulation. We’ll generate lots of copies of \\(X_1\\) and \\(X_2\\), and then we’ll compute their\n\n(sample) variances separately,\n(sample) variance of their sum, and\n(sample) correlation\n\nOf course, all three of these quantities will be estimated from samples. The law of large numbers tells us that these quantities computed on our data will be close to the truth, but not necessarily precisely equal to the truth.\nOkay, let’s generate data.\n\nM &lt;- 1e5; # Generate 100K Monte Carlo samples\nX1 &lt;- rnorm( n=M, mean=1, sd=sqrt(1) );\nX2 &lt;- rnorm( n=M, mean=2, sd=sqrt(2) );\n\n# Compute the (sample) variances of the copies of X1 and X2.\nv1 &lt;- var(X1);\nv2 &lt;- var(X2);\n\n# v1 should be close to 1=Var X_1, v2 close to 2=Var X_2.\nc( v1, v2 )\n\n[1] 0.9964867 2.0028233\n\n\nAnd let’s check that these two independent variables have covariance (approximately) zero.\n\n# cor( x, y) computes the (sample) covariance between\n# the entries of vectors x and y.\n# See ?cor for details.\ncor( X1, X2 );\n\n[1] 0.006530369\n\n\nAgain, those sample-based quantities will never be precisely equal to 1, 2, and 0, but they will be very close!\nFinally, let’s check that the variance of the sum \\(X_1 + X_2\\) is the sum of variances, as it should be if the RVs are independent. So we should see \\[\n\\operatorname{Var}(X_1 + X_2)\n= \\operatorname{Var} X_1 + \\operatorname{Var} X_2\n= 1 + 2 = 3.\n\\]\nOkay, let’s check.\n\nvar(X1 + X2)\n\n[1] 3.017761\n\n\nAs we predicted!\n\n\n4.5.3 Example: multivariate normal\nRemember that the multivariate normal is a way of generating multiple normal random variables that are correlated with one another.\nHere’s our code from our example modeling the voter shares in Wisconsin and Michigan.\n\nmu &lt;- c(.5,.5); # Vector of means; both W_p and M_p are mean 1/2.\nCovMx &lt;- matrix( c(.05^2,.04^2,.04^2,.05^2), nrow = 2); # Make a two-by-two symmetric matrix.\nCovMx;\n\n       [,1]   [,2]\n[1,] 0.0025 0.0016\n[2,] 0.0016 0.0025\n\n\nThe code above generates a multivariate normal with two entries. Both will have means \\(0.5\\), encoded in the vector mu.\nThe variances and covariance between the two normals is encoded by CovMx. It encodes a matrix (fancy word for an array of numbers), which looks like \\[\n\\Sigma = \\begin{bmatrix}\n0.05^2 & 0.04^2 \\\\\n0.04^2 & 0.05^2\n\\end{bmatrix}.\n\\] That \\(0.4^2\\) in the off-diagonal entries is the covariance of the two normals.\nSo this will generate two normal random variables, both having mean \\(0.5\\), and variance \\(0.05^2\\), but these two normals will be correlated, with covariance \\(0.04^2\\).\nLet’s have a look:\n\nlibrary(MASS); # This library includes a multivariate normal\nWpMp = mvrnorm(n=2000, mu=mu, Sigma=CovMx); #mvrnorm is the multivariate version of rnorm.\nplot(WpMp, xlab = \"Wisconsin proportion\", ylab = \"Michigan proportion\");\n\n\n\n\nIt’s clear that the Wisconsin and Michigan voter shares are correlated– we can see it in the plot!\nBut just to be sure:\n\n# WpMp is an array with two columns and 500 rows.\n# If we call cov on it directly, we get something shaped\n# like our covariance matrix.\ncov(WpMp )\n\n            [,1]        [,2]\n[1,] 0.002434066 0.001654258\n[2,] 0.001654258 0.002638478\n\n\nThe diagonal entries are the (sample) variances computed along the columns. The off-diagonal entries (note that they are both the same) tell us the (sample) covariance. Unsurprisingly, the off-diagonal is close to the true covariance \\(0.0016\\).\nAlso worth noting is the fact that the on-diagonal entries are (approximately) 0.025. The on-diagonal entries are computing covariances of our two columns of data with themselves. That is, these are computing something like \\(\\operatorname{Cov}(X,X)\\).\nWhat is a random variable’s covariance with itself? Let’s plug in the definition: \\[\n\\operatorname{Cov}(X,X)\n= \\mathbb{E} (X - \\mathbb{E} X)(X - \\mathbb{E} X)\n= \\mathbb{E} (X - \\mathbb{E} X)^2\n\\]\nHey, that’s the variance! So \\(\\operatorname{Cov}(X,X) = \\operatorname{Var} X\\)."
  },
  {
    "objectID": "cov.html#how-reasonable-is-independence",
    "href": "cov.html#how-reasonable-is-independence",
    "title": "4  Independence, Conditional Probability and Bayes’ Rule",
    "section": "4.6 How reasonable is independence?",
    "text": "4.6 How reasonable is independence?\nIn most applications, it is pretty standard that we assume that our data are drawn independently and identically distributed according to some distribution. We say “i.i.d.”. For example, if \\(X_1, X_2, \\ldots, X_n\\) are all continuous uniform random variables between 0 and 1, we would say \\[\nX_i \\overset{\\text{iid}}{\\sim} \\text{Uniform}(0,1), \\text{ for } i=1,\\ldots, n\n\\]\nThis notation is common to denote iid random variables.\nAs another example, when we perform regression (as you did in STAT240, and which we’ll revisit in more detail later this semester), we imagine that the observations (i.e., predictor-response pairs) \\((X_1,Y_1),(X_2,Y_2),\\dots,(X_n,Y_n)\\) are independent.\nMost standard testing procedures (e.g., the t-test) assume that data are drawn i.i.d.\nHow reasonable are these assumptions?\nWell, of course, in the end, it depends on where the data comes from! We have to draw on what we know about the data, either from our own knowledge or from that of our clients, to assess what assumptions are and aren’t reasonable.\nLike most modeling assumptions, we usually acknowledge that independence may not be exactly true, but it’s often a good approximation to the truth!\nOf course, we have to be careful.\nExample: suppose we are modeling the value of a stock over time. We model the stock’s price on days 1, 2, 3, etc as \\(X_1, X_2, X_3, \\dots\\). What is wrong with modeling these prices as being independent of one another? Why might it still be a reasonable modeling assumption?\nWhat if instead we look at the change in stock price from day to day? For example, let \\(Y_i = X_{i+1}-X_{i}\\). In other words, \\(X_{i+1}=X_i+Y_i\\). Would it be more reasonable to assume that the \\(Y_i\\)’s are independent?\nWhat if instead of considering a stock’s returns on one day after another, we look at a change in stock price on one day, then at the change 10 days from that, and 10 days from that, and so on? Surely there is still dependence, but a longer time lag between observations might make us more willing to accept that our observations are close to independent (or at least have much smaller covariance!).\nNote: Tobler’s first law of geography states ‘Everything is related to everything else, but near things are more related than distant things.’ Does that ring true in this context?\nExample: suppose we randomly sample 1000 UW-Madison students to participate in a survey, and record their responses as \\(X_1,X_2,\\dots,X_{1000}\\). What might be the problem with modeling these responses as being independent? Why might be still be a reasonable modeling assumption?"
  },
  {
    "objectID": "cov.html#conditional-probability",
    "href": "cov.html#conditional-probability",
    "title": "4  Independence, Conditional Probability and Bayes’ Rule",
    "section": "4.7 Conditional probability",
    "text": "4.7 Conditional probability\nWe can’t talk about events and independence without discussing conditional probability.\nTo motivate this, consider the following: suppose I roll a six-sided die. What is the probability that the die lands showing 2?\nNow, suppose that I don’t tell you the number on the die, but I do tell you that the die landed on an even number (i.e., one of 2, 4 or 6). Now what is the probability that the die is showing 2?\nWe can work out the probabilities by simply counting possible outcomes. Are the probabilities the same?\nExample: disease screening\nHere’s a more real-world (and more consequential example): suppose we are screening for a rare disease. A patient takes the screening test, and tests positive. What is the probability that the patient has the disease, given that they have tested positive for it?\nWe will need to establish the rules of conditional probability before we can tackle a problem such as this.\n\n4.7.1 Introducing conditional probability\nThese kinds of questions, in which we want to ask about the probability of an event given that something else has happened, require that we be able to define a “new kind” of probability, called conditional probability.\nLet \\(A\\) and \\(B\\) be two events.\n\nExample: \\(A\\) could be the event that a die lands showing 2 and \\(B\\) is the event that the die landed on an even number.\nExample: \\(A\\) could be the event that our patient has a disease and \\(B\\) is the event that the patient tests positive on a screening test.\n\nProvided that \\(\\Pr[ B ] &gt; 0\\), we define the conditional probability of \\(A\\) given \\(B\\), written \\(\\Pr[ A \\mid B]\\), according to \\[\n\\Pr[ A \\mid B ] = \\frac{ \\Pr[ A \\cap B ] }{ \\Pr[ B ] }.\n\\] Note that if \\(\\Pr[B] = 0\\), then the ratio on the right-hand side is not defined, hence why we demanded that \\(\\Pr[B] &gt; 0\\). Later in your career, you’ll see that we can actually define conditional probability in a sensible way even if \\(\\Pr[B] = 0\\), but that’s a matter for a later class.\n\n\n\nVenn diagram illustrating conditional probability\n\n\nLet’s try computing one of these conditional probabilities: what is the probability that the die is showing 2 conditional on the fact that it landed on an even number?\nWell,\n\n\\(\\Pr[ \\text{ even } ] = 1/2\\), because there are three even numbers on the die, and all six numbers are equally likely: \\(3/6 = 1/2\\).\n\\(\\Pr[ \\text{ die lands 2 } \\cap \\text{even} ] = \\Pr[ \\text{ die lands 2 }]\\), since \\(2\\) is an even number.\n\nSo the conditional probability is \\[\n\\begin{aligned}\n\\Pr[ \\text{ die lands 2 } \\mid \\text{ even }]\n&= \\frac{ \\Pr[ \\text{ die lands 2 } \\cap \\text{even} ] }{ \\Pr[ \\text{ even } ] } \\\\\n&= \\frac{ \\Pr[ \\text{ die lands 2 }]}\n    { \\Pr[ \\text{ even } ] } \\\\\n&= \\frac{ 1/6 }{ 1/2 } = 1/3.\n\\end{aligned}\n\\] This makes sense– given that the die lands on an even number, we are choosing from among three outcomes: \\(\\{2,4,6\\}\\). The probability that we choose \\(2\\) from among these three possible equally-likely outcomes is \\(1/3\\).\n\n\n4.7.2 Disease screening\nWhat about our disease testing example? What is the probability that our patient has the disease given that they tested positive?\nWell, applying the definition of conditional probability, \\[\n\\Pr[ \\text{ disease} \\mid \\text{ positive test }]\n= \\frac{ \\Pr[ \\text{ disease} \\cap \\text{ positive test }] }{ \\Pr[ \\text{positive test} ] }\n\\]\nOkay, but what is \\(\\Pr[ \\text{ positive test} ]\\)? I guess it’s just the probability that a random person (with the disease or not) tests positive? For that matter, what is \\(\\Pr[ \\text{ disease} \\cap \\text{ positive test }]\\)? These can be hard events to assign probabilities to! Luckily, there is a famous equation that often gives us a way forward."
  },
  {
    "objectID": "cov.html#bayes-rule",
    "href": "cov.html#bayes-rule",
    "title": "4  Independence, Conditional Probability and Bayes’ Rule",
    "section": "4.8 Bayes’ rule",
    "text": "4.8 Bayes’ rule\nThe Reverend Thomas Bayes was the first to suggest an answer to this issue. Bayes’ rule, as it is now called, tells us how to relate \\(\\Pr[ A \\mid B]\\) to \\(\\Pr[ B \\mid A]\\): \\[\n\\Pr[ A \\mid B ] = \\frac{ \\Pr[ B \\mid A ] \\Pr[ A ]}{ \\Pr[ B ]}.\n\\]\nThis is useful, because it is often easier to write one or the other of these two probabilities.\nApplying this to our disease screening example, \\[\n\\Pr[ \\text{ disease} \\mid \\text{ positive test }]\n=\n\\frac{ \\Pr[\\text{ positive test } \\mid \\text{ disease}]\n        \\Pr[ \\text{ disease}]}\n        { \\Pr[ \\text{ positive test } ]  }\n\\]\nThe advantage of using Bayes’ rule in this context is that the probabilities appearing on the right-hand side are all straight-forward to think about (and estimate!).\n\n\\(\\Pr[ \\text{ disease}]\\) is the just the probability that a randomly-selected person has the disease. This is known as the prevelance of the diseases in the population. We could estimate this probability by randomly selecting a random group of people and determining if they have the disease (hopefully not using the screening test we are already using…).\n\\(\\Pr[\\text{ positive test } \\mid \\text{ disease}]\\) is the probability that when we give our screening test to a patient who has the disease in question, the test returns positive. This is often called the sensitivity of a test, a term you may recall hearing frequently in the early days of the COVID-19 pandemic.\n\\(\\Pr[ \\text{ positive test } ]\\) is just the probability that a test given to a (presumably randomly selected) person returns a positive result. We just said about that this is the hard thing to estimate. In your homework, you’ll explore one way to get at this quantity, but for now we’ll have to just assume that we can estimate it somehow or other."
  },
  {
    "objectID": "cov.html#example-testing-for-a-rare-disease",
    "href": "cov.html#example-testing-for-a-rare-disease",
    "title": "4  Independence, Conditional Probability and Bayes’ Rule",
    "section": "4.9 Example: testing for a rare disease",
    "text": "4.9 Example: testing for a rare disease\nSuppose that we are testing for a rare disease, say, \\[\n\\Pr[ \\text{ disease}] = \\frac{1}{10^6},\n\\]\nand suppose that a positive test is also rare, in keeping with the fact that our disease is rare and our test presumably has a low false positive rate: \\[\n\\Pr[ \\text{ positive test} ] = 1.999*10^{-6}\n\\] Note that this probability actually depends on the sensitivity \\(\\Pr[\\text{ positive test } \\mid \\text{ disease}]\\) and the specificity \\(1-\\Pr[\\text{ positive test } \\mid \\text{ healthy}]\\) of our test. You’ll explore this part more on your homework, but we’re just going to take this number as given for now.\nFinally, let’s suppose that our test is 99.99% accurate: \\[\n\\Pr[\\text{ positive test } \\mid \\text{ disease}]\n= 0.9999 = 1-10^{-4}\n\\]\nTo recap, \\[\n\\begin{aligned}\n\\Pr[ \\text{ disease}] &= \\frac{1}{10^6} \\\\\n\\Pr[ \\text{ positive test} ] &= 1.999*10^{-6} \\\\\n\\Pr[\\text{ positive test } \\mid \\text{ disease}]\n&= 0.9999.\n\\end{aligned}\n\\]\nNow, suppose that a patient is given the screening test and receives a positive result. Bayes’ rule tells us \\[\n\\begin{aligned}\n\\Pr[ \\text{ disease} \\mid \\text{ positive test }]\n&=\n\\frac{ \\Pr[\\text{ positive test } \\mid \\text{ disease}]\n        \\Pr[ \\text{ disease}]}\n        { \\Pr[ \\text{ positive test } ]  }\n= \\frac{ 0.9999 * 10^{-6} }{ 1.999*10^{-6} } \\\\\n&= 0.5002001.\n\\end{aligned}\n\\]\nSo even in light of our positive screening test result, the probability that our patient has the disease in question is still only about 50%!\nThis is part of why, especially early on in the pandemic when COVID-19 was especially rare, testing for the disease in the absence of symptoms was not considered especially useful.\nMore generally, this is why most screenings for rare diseases are not done routinely– doctors typically screen for rare diseases only if they have a reason to think a patient is more likely to have that disease for other reasons (e.g., family history of a genetic condition or recent exposure to an infectious disease)."
  },
  {
    "objectID": "cov.html#calculating-the-denominator-in-bayes-rule",
    "href": "cov.html#calculating-the-denominator-in-bayes-rule",
    "title": "4  Independence, Conditional Probability and Bayes’ Rule",
    "section": "4.10 Calculating the denominator in Bayes’ Rule",
    "text": "4.10 Calculating the denominator in Bayes’ Rule\nThe denominator can be decomposed into two parts using a property known as the Law of Total Probability.\n\\[\n\\Pr[ \\text{ positive test} ] = \\Pr[ \\text{ positive test} \\cap \\text{disease}]+\\Pr[ \\text{ positive test} \\cap \\text{no disease}]\n\\]\nIn other words, all positive results are either true positives or false positives. Because these are mutually exclusive events, the total probability of a positive result is the probability of a true positive plus the probability of a false positive. We can expand each of these terms using the conditional probability rule.\n\\[\n\\Pr[ \\text{ positive test} \\cap \\text{disease}] = \\Pr[\\text{ positive test } \\mid \\text{ disease}]  \\Pr[ \\text{ disease}]\n\\] \\[\n\\Pr[ \\text{ positive test} \\cap \\text{no disease}] = \\Pr[\\text{ positive test } \\mid \\text{ no disease}]  \\Pr[ \\text{ no disease}]\n\\]\nFor example, suppose that a genetic condition occurs in roughly 1 out of 800 individuals. A simple saliva test is available. If a person has the gene, the test is positive with 97% probability. If a person does not have the gene, a false positive occurs with 4% probability.\nTo simplify notation, let \\(G\\) represent “the individual has the gene” and \\(G'\\) be the complementary event that “the individual does not have the gene.” Furthermore, let \\(Pos\\) and \\(Neg\\) represent the test results.\nIf a random person from the population takes the test and gets a positive result, what is the probability they have the genetic condition?\nBayes’ Rule to the rescue:\n\\[\n\\begin{aligned}\nP[G | Pos] &= \\dfrac{P[Pos | G] P[G]}{P[Pos | G] P[G] + P[Pos | G'] P[G']}\\\\\n&= \\dfrac{(.97)(1/800)}{(.97)(1/800)+(.04)(799/800)}\\\\\n&\\approx 0.0295\n\\end{aligned}\n\\] In other words, a positive test result would raise the likelihood of the gene being present from \\(1/800=0.00125\\) up to \\(.0295\\)."
  },
  {
    "objectID": "cov.html#dependent-free-throw-shots",
    "href": "cov.html#dependent-free-throw-shots",
    "title": "4  Independence, Conditional Probability and Bayes’ Rule",
    "section": "4.11 Dependent free throw shots",
    "text": "4.11 Dependent free throw shots\nSuppose a basketball player’s likelihood of making a basket when making a free throw depends on the previous attempt. On the first throw, they have a probability of \\(0.67\\) of making the basket. On the second throw, following a basket the probability goes up to \\(.75\\). If the first throw is a miss, the probability of a basket on the second throw goes down to \\(0.62\\).\nExercise: If the second throw is a basket, what is the likelihood the first throw is a basket?\nExercise: Given that the player scores at least 1 point, what is the probability that they score 2 points total?\n\n4.11.1 Review:\nIn these notes we covered:\n\nThe concept of independent events\nIndependent random variables\nDefinition of variance\nExpectation of a linear combination of r.v.s\nVariance of a linear combination of r.v.s\nCovariance and correlation\nRelationship between correlation and independence\nWhen the independence assumption is reasonable\nConditional probability & the general multiplication rule\nBayes’ rule"
  },
  {
    "objectID": "rv_practice.html",
    "href": "rv_practice.html",
    "title": "5  Probability and Random Variables Practice",
    "section": "",
    "text": "6 Practice Problems\nThese problems are excellent practice but they are beyond the material we cover in STAT 340."
  },
  {
    "objectID": "rv_practice.html#using-wikipedia-in-college",
    "href": "rv_practice.html#using-wikipedia-in-college",
    "title": "5  Probability and Random Variables Practice",
    "section": "6.1 1. Using Wikipedia in college",
    "text": "6.1 1. Using Wikipedia in college\nA recent national study showed that approximately 44.7% of college students have used Wikipedia as a source in at least one of their term papers. Let \\(X\\) equal the number of students in a random sample of size \\(n = 31\\) who have used Wikipedia as a source.\n\nHow is \\(X\\) distributed?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAssuming independence in sampling, and a representative sample, we can use a Binomial distribution with \\(n=31\\) and \\(p=0.447\\).\n\n\n\n\nSketch the probability mass function (roughly).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nbarplot(dbinom(0:31, 31,.447), names=0:31, ylab=\"probability\", main=\"PMF of Binomial(31,.447)\")\n\n\n\n\n\n\n\n\nSketch the cumulative distribution function (roughly).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nplot(pbinom(0:31, 31, .447), type=\"s\", ylab=\"cumulative prob.\", main=\"CDF of Binomial(31, .447)\")\n\n\n\n\n\n\n\n\nFind the probability that \\(X\\) is equal to 17.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndbinom(17, 31, .447)\n\n[1] 0.07532248\n\n\n\n\n\n\nFind the probability that \\(X\\) is at most 13.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npbinom(13, 31, .447)\n\n[1] 0.451357\n\n\n\n\n\n\nFind the probability that \\(X\\) is bigger than 11.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsum(dbinom(12:31, 31, .447))\n\n[1] 0.8020339\n\n#or\npbinom(11, 31, .447, lower.tail=FALSE)\n\n[1] 0.8020339\n\n#or\n1-pbinom(11, 31, .447)\n\n[1] 0.8020339\n\n\n\n\n\n\nFind the probability that \\(X\\) is at least 15.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#P(X at least 15)\nsum(dbinom(15:31,31,.447))\n\n[1] 0.406024\n\n\n\n\n\n\nFind the probability that \\(X\\) is between 16 and 19, inclusive.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsum(dbinom(16:19, 31, .447))\n\n[1] 0.2544758\n\n\n\n\n\n\nGive the mean of \\(X\\), denoted \\(\\mathbb{E}X\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#E(X)=n*p\n31*.447\n\n[1] 13.857\n\n#or you can also do this (but it's too much work)\nsum( (0:31) * dbinom(0:31, 31, .447))\n\n[1] 13.857\n\n\n\n\n\n\nGive the variance of \\(X\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#Var(X) = n * p * (1-p)\n31 * .447 * (1-.447)\n\n[1] 7.662921\n\n#or - if you want (but why would you want to?)\nsum((0:31 - 31*.447)^2 * dbinom(0:31, 31, .447))\n\n[1] 7.662921\n\n\n\n\n\n\nGive the standard deviation of \\(X\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#SD(X) = sqrt(n*p*(1-p))\nsqrt(31*.447*(1-.447))\n\n[1] 2.768198\n\n\n\n\n\n\nFind \\(\\mathbb{E}(4X+51.324)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#E(4X+51.324) = 4*E(X)+51.324\n4*(31*.447) + 51.324\n\n[1] 106.752"
  },
  {
    "objectID": "rv_practice.html#choose-the-distribution",
    "href": "rv_practice.html#choose-the-distribution",
    "title": "5  Probability and Random Variables Practice",
    "section": "6.2 2. Choose the distribution",
    "text": "6.2 2. Choose the distribution\n\nFor the following situations, decide what the distribution of \\(X\\) should be. In nearly every case, there are additional assumptions that should be made for the distribution to apply; identify those assumptions (which may or may not hold in practice.)\n\n\nWe shoot basketballs at a basketball hoop, and count the number of shots until we make a basket. Let X denote the number of missed shots. On a normal day we would typically make about 37% of the shots.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe number of missed shots before the first basket, assuming independence, can be modeled by a Geometric random variable with parameter \\(p=.37\\).\n\n\n\n\nIn a local lottery in which a three digit number is selected randomly, let X be the number selected.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAssuming that all 3 digit numbers are equally likely (A reasonable assumption) the number selected can be modeled by a discrete uniform distribution with minimum 100 and maximum 999.\n\n\n\n\nWe drop a Styrofoam cup to the floor twenty times, each time recording whether the cup comes to rest perfectly right side up, or not. Let X be the number of times the cup lands perfectly right side up.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf we drop the cup 20 times, and the result each time is independent with a constant probability of landing right side up, the number of times it does can be modeled by a Binomial random variable with parameters \\(n=20\\) and \\(p\\) (unknown).\n\n\n\n\nWe toss a piece of trash at the garbage can from across the room. If we miss the trash can, we retrieve the trash and try again, continuing to toss until we make the shot. Let X denote the number of missed shots.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nGeometric random variable (unknown parameter value for \\(p\\)).\n\n\n\n\nWorking for the border patrol, we inspect shipping cargo as when it enters the harbor looking for contraband. A certain ship comes to port with 557 cargo containers. Standard practice is to select 10 containers randomly and inspect each one very carefully, classifying it as either having contraband or not. Let X count the number of containers that illegally contain contraband.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTechnically we should use a hypergeometric random variable for this situation (since it is a small population size of 557), but since we do not cover the hypergeometric the closest random variable we have is the binomial.\n\n\n\n\nAt the same time every year, some migratory birds land in a bush outside for a short rest. On a certain day, we look outside and let X denote the number of birds in the bush.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis is a discrete random variable, but without other information it’s hard to say. The distribution is likely unimodal and bell-curved. You could probably model this using a normal distribution rounded off to the nearest integer.\n\n\n\n\nWe count the number of rain drops that fall in a circular area on a sidewalk during a ten minute period of a thunder storm.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe observation window is the circular area, and the 10 minutes during observation. Assuming the rate of rainfall is constant, the number of raindrops in the circle can be modeled using a Poisson random variable.\n\n\n\n\nWe count the number of moth eggs on our window screen.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCounting indicates a discrete random variable. A binomial or a rounded normal distribution may be appropriate, but we lack enough details to be sure.\n\n\n\n\nWe count the number of blades of grass in a one square foot patch of land.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe location of the sprouting grass could be modeled well by a Poisson random variable - the \\(\\lambda\\) parameter would likely be very large, in the range of 1000 or 10000, and as such the distribution would look very much like a normal distribution.\n\n\n\n\nWe count the number of pats on a baby’s back until (s)he burps.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAs we define a geometric random variable, we let \\(X\\) be the number of failures before the first success. The last pat (that causes the burp) is the success in this context. So we could use a geometric random variable, but we would have to add 1 to it in order to count all burps (the failures + 1 success)."
  },
  {
    "objectID": "rv_practice.html#variance-formula",
    "href": "rv_practice.html#variance-formula",
    "title": "5  Probability and Random Variables Practice",
    "section": "6.3 3. Variance Formula",
    "text": "6.3 3. Variance Formula\nmove to chapter on covariance\nShow that \\(\\mathbb{E}(X-\\mu)^2 = \\mathbb{E}X^2-\\mu^2\\). Hint: expand the quantity \\((X-\\mu)^2\\) and distribute the expectation over the resulting terms.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe proof goes like this: We first FOIL \\((X-\\mu)^2\\):\n\\(\\mathbb{E}(X-\\mu)^2 = \\mathbb{E}(X^2 - 2\\mu X + \\mu^2)\\)\nWe next split the expected value into 3 expected values using the fact that \\(\\mathbb{E}\\) is a linear operator.\n\\(\\mathbb{E}(X-\\mu)^2 = \\mathbb{E}X^2 -2\\mu \\mathbb{E}X + \\mathbb{E}\\mu^2\\)\nWe next observe that \\(\\mu^2\\) is constant and \\(\\mathbb{X}=\\mu\\)\n\\(\\mathbb{E}(X-\\mu)^2 = \\mathbb{E}X^2 -2\\mu \\mu + \\mu^2\\)\nWe can simplify the expression and we’re done!"
  },
  {
    "objectID": "rv_practice.html#expectation-and-binomial",
    "href": "rv_practice.html#expectation-and-binomial",
    "title": "5  Probability and Random Variables Practice",
    "section": "6.4 4. Expectation and Binomial",
    "text": "6.4 4. Expectation and Binomial\nextra If \\(X \\sim \\text{Binom}(n,p)\\) show that \\(\\mathbb{E}X(X-1)=n(n-1)p^2\\).\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can just expand the product \\(\\mathbb{E}(X^2-X)\\) and we can split this up into two expected values: \\(\\mathbb{E}X^2 - \\mathbb{E}X = \\mathbb{E}X^2-\\mu\\). Recall that \\(Var(X)=\\mathbb{E}X^2-\\mu^2\\) So \\(\\mathbb{E}X^2=Var(X)+\\mu^2\\). For a binomial, \\(Var(X)=np(1-p)\\) and \\(\\mu=np\\). Thus we have\n\\(\\mathbb{E}X^2 - \\mu=[np(1-p) + n^2p^2] - np = np\\left(1-p+np-1\\right)\\)\nTidying up a little bit we get \\(np(np-p)=np^2(n-1)\\), and we’re done."
  },
  {
    "objectID": "rv_practice.html#pmf-practice",
    "href": "rv_practice.html#pmf-practice",
    "title": "5  Probability and Random Variables Practice",
    "section": "6.5 5. PMF practice",
    "text": "6.5 5. PMF practice\nConsider an information source that produces numbers \\(k\\) in the set \\(S_X=\\{1,2,3,4\\}\\). Find and plot the pmf in the following cases:\n\n\\(p_k = p_1/k\\) for \\(k=1,2,3,4\\). Hint: find \\(p_1\\)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUse the fact that \\(p_1+p_2+p_3+p_4=1\\). In other words, \\(p_1/1+p_1/2+p_1/3+p_1/4=p_1(12/12+6/12+4/12+3/12) = p_1(25/12) =1\\), so \\(p_1=12/25\\). Then \\(p_2=6/25\\), \\(p_3=4/25\\) and \\(p_4=3/25\\).\n\nbarplot(height=c(12/25, 6/25, 4/25, 3/25), names=1:4)\n\n\n\n\n\n\n\n\n\\(p_{k+1}=p_k/2\\) for \\(k=1,2,3\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nStarting with \\(k=1\\) we have \\(p_2 = p_1/2\\). Following this pattern, \\(p_3=p_1/4\\) and \\(p_4=p_1/8\\). If we add these together we have \\(p_1(8/8 + 4/8 + 2/8 + 1/8) = 15/8\\). Thus we have \\(p_1=8/15, p_2=4/15, p_3=2/15\\) and \\(p_4=1/15\\)\n\nbarplot(height=c(8/15, 4/15, 2/15, 1/15), names=1:4)\n\n\n\n\n\n\n\n\n\\(p_{k+1}=p_k/2^k\\) for \\(k=1,2,3\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nStarting with \\(k=1\\) we have \\(p_2 = p_1/2\\), \\(p_3=p_2/2^2= p_2/4 = (p_1/2)/4 = p_1/8\\). \\(p_4 = p_3/2^3 = p_3/8 = (p_1/8)/8) = p_1/64\\). The sum is \\(p_1(64/64 + 32/64 + 8/64 + 1/64) = p_1(105/64)\\) so \\(p_1 = 64/105, p_2=32/105, p_3=8/105, p_4=1/105\\)\n\nbarplot(height=c(64/105, 32/105, 8/105, 1/105), names=1:4)\n\n\n\n\n\n\n\n\nCan the random variables in parts a. through c. be extended to take on values in the set \\(\\{1,2,\\ldots,\\}\\)? Why or why not? (Hint: You may use the fact that the series \\(1+\\frac12+\\frac13+\\cdots\\) diverges.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nConsider the pmf for part a. The sum of the probabilities would be \\(\\sum_{k=1}^\\infty p_1/k\\). However \\(\\sum_{k=1}^\\infty \\frac{1}{k}\\) does not converge, so no matter what \\(p_1\\) is, the sum of probabilities will exceed 1.\nFor part b, the sum of the probabilities is \\(\\sum_{k=1}^\\infty 2p_1/{2^{k}}\\). Because \\(\\sum_{k=1}^\\infty \\frac{1}{2^k}=1\\), then it would be possible to define a random variable with support \\(1,2,\\ldots\\) with this pmf.\nFor part c, because \\(p_k/2^k \\leq p_k/2\\), we at least know that \\(\\sum_k p_k\\) is finite, so such a random variable with infinite support is certainly feasible. The exact value of \\(p_1\\) is not as simple to calculate, but we were not asked to do that."
  },
  {
    "objectID": "rv_practice.html#dice-difference",
    "href": "rv_practice.html#dice-difference",
    "title": "5  Probability and Random Variables Practice",
    "section": "6.6 6. Dice Difference",
    "text": "6.6 6. Dice Difference\nTwo dice are tossed. Let \\(X\\) be the absolute difference in the number of dots facing up.\n\n\nFind and plot the pmf of \\(X\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#It may be simplest to calculate all possible values of X. \nx &lt;- vector(\"numeric\")\nfor(i in 1:6){\n  for(j in 1:6){\nx[length(x)+1] = abs(i-j)\n  }\n}\n#now that we have all equally likely values, we can just calculate the pmf in a prop.table\npX &lt;- prop.table(table(x))\n#And create a barplot.\nbarplot(pX)\n\n\n\n\n\n\n\n\nFind the probability that \\(X\\leq 2\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#The probability that X &lt;= 2 is easy to find using the pmf\n#The columns are named with strings, so we can convert 0 1 and 2 to strings to pull out the proper probabilities.\nsum(pX[as.character(0:2)])\n\n[1] 0.6666667\n\n\n\n\n\n\nFind \\(\\mathbb{E}X\\) and \\(\\text{Var}X\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#The expected value and variance can be calculated from the pmf.\n\n(EX &lt;- sum(0:5 * pX))\n\n[1] 1.944444\n\n(VarX &lt;- sum((0:5 - EX)^2 * pX))\n\n[1] 2.052469\n\n#or by taking the mean and population variance of the x values themselves\nmean(x)\n\n[1] 1.944444\n\nmean((x-mean(x))^2)\n\n[1] 2.052469\n\n\n\n\n\n##7. PMF Formula extra, move to next chapter\nLet \\(X\\) be a random variable with pmf \\(p_k = c/2^k\\) for \\(k=1,2,\\ldots\\).\n\n\nDetermine the value of \\(c\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis was done above; because \\(\\sum_{i=1}^\\infty 1/2^k = 1\\), the value of \\(c\\) must be \\(1\\).\n\n\n\n\nFind \\(\\mathbb{P}(X&gt;4)\\) and \\(\\mathbb{P}(6\\leq X \\leq 8)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(P(X&gt;4) = 1-P(X \\leq 3)=1-(\\frac12 + \\frac14 + \\frac18)\\)\n\n1-(1/2+1/4+1/8)\n\n[1] 0.125\n\n\n\n\n\n\nFind \\(\\mathbb{E}X\\) and \\(\\text{Var}X\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe expected value can be calculated by taking the sum \\(\\sum k p_k = \\sum_{k=1}^\\infty \\frac{k}{2^k}\\) which we can show using facts from calculus equals 2. Why? Well, as long as \\(|p|&lt;1, \\sum_{k=1}^{\\infty}p^k=\\frac{p}{1-p}\\) (this is a geometric series). If we take a derivative of both sides we get \\(\\sum_{k=1}^\\infty kp^{k-1}=\\frac{1}{(1-p)^2}\\). Multiply both sides by \\(p\\) to get \\(\\sum_{k=1}^\\infty kp^{k}=\\frac{p}{(1-p)^2}\\). In our case, \\(p=\\frac12\\). Plugging this in we get \\(\\frac{.5}{.5^2}=2\\).\nThe variance is \\(E(X^2)-(EX)^2=E(X^2)-4\\). The expected value of \\(X^2\\) can be derived, though it’s not so fun…\nStart by taking the equation \\(\\sum_k kp^k = \\frac{p}{(1-p)^2}\\) and take a derivative again. We get \\(\\sum_k k^2 p^{k-1} = \\frac{(1-p)^2+2p(1-p)}{(1-p)^4}\\). Multiply through by \\(p\\) to get \\(\\sum_k k^2 p^k = \\frac{p(1-p)^2+2p^2(1-p)}{(1-p)^4}\\). If we let \\(p=\\frac12\\) we have found \\(E(X^2)=\\sum_{k=1}^\\infty k^2(\\frac12)^k=\\dfrac{\\frac18-\\frac{2}{8}}{\\frac{1}{16}}=6\\). Thus \\(Var(X)=E(X^2)-E(X)^2 = 6-4=2\\). It should be noted that this random variable is actually a geometric random variable (well, according to the “number of trials until and including the first success definition). If we define \\(Y\\sim Geom(.5)\\) using our definition of “number of failures before the first success” then We can let \\(X=Y+1\\). \\(E(X)=E(Y+1)=\\frac{1-.5}{.5}+1=2\\) and \\(Var(X)=Var(Y)=\\frac{1-p}{p2}=\\frac{.5}{.25^2}=2\\)."
  },
  {
    "objectID": "rv_practice.html#pmf-formula-ii",
    "href": "rv_practice.html#pmf-formula-ii",
    "title": "5  Probability and Random Variables Practice",
    "section": "6.7 8. PMF Formula II",
    "text": "6.7 8. PMF Formula II\nextra\nLet \\(X\\) be a random variable with pmf \\(p_k = c/2^k\\) for \\(k=-1,0,1,2,3,4,5\\).\n\n\nDetermine the value of \\(c\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe sum of the probabilities are \\(c(2 + 1 + \\frac{1}{2}+\\frac{1}{4}+\\frac{1}8+\\frac{1}{16}+\\frac{1}{32})=c\\frac{127}{32}\\) so \\(c=\\frac{32}{127}\\).\n\n\n\n\nFind \\(\\mathbb{P}(1\\leq X &lt; 3)\\) and \\(\\mathbb{P}(1 &lt; X \\leq 5)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nc=32/127\nk = seq(-1,5)\npk=c/2^k\nnames(pk) &lt;- k\nsum(pk[as.character(2)])\n\n[1] 0.06299213\n\nsum(pk[as.character(2:5)])\n\n[1] 0.1181102\n\n\n\n\n\n\nFind \\(\\mathbb{P}(X^3 &lt; 5)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIf \\(X^3 &lt; 5\\) that means \\(X^3 \\leq 4\\) and thus \\(X \\leq 4^{1/3}\\approx 1.587\\)\n\nsum(pk[k&lt;=4^(1/3)])\n\n[1] 0.8818898\n\nsum(pk[k^3&lt;5])\n\n[1] 0.8818898\n\n\n\n\n\n\nFind the pmf and the cdf of \\(X\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nbarplot(height=pk, names=k, main='pmf of X')\n\n\n\nbarplot(height=cumsum(pk), names=k, main='cdf of X')"
  },
  {
    "objectID": "rv_practice.html#voltage-random-variable",
    "href": "rv_practice.html#voltage-random-variable",
    "title": "5  Probability and Random Variables Practice",
    "section": "6.8 9. Voltage random variable",
    "text": "6.8 9. Voltage random variable\nA modem transmits a +2 voltage signal into a channel. The channel adds to this signal a noise term that is drawn from the set \\(\\{0,-1,-2,-3\\}\\) with respective probabilities \\(\\{4/10, 3/10, 2/10, 1/10\\}\\).\n\n\nFind the pmf of the output \\(Y\\) of the channel.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#Let X be the noise\nk &lt;- seq(0,-3)\npk &lt;- c(4/10, 3/10, 2/10, 1/10)\n\ny &lt;- sort(2+k)\npy &lt;- pk[order(2+k)]\n\nbarplot(height=py, names=y, main=\"pmf of Y\")\n\n\n\n\n\n\n\n\nWhat is the probability that the channel’s output is equal to the input of the channel?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis happens when there’s no noise, with probability 4/10.\n\n\n\n\nWhat is the probability that the channel’s output is positive?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#Interpreting 'positive' to be strictly positive, not zero:\nsum(py[y&gt;0])\n\n[1] 0.7\n\n\n\n\n\n\nFind the expected value and variance of \\(Y\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n(EY &lt;- sum(y*py))\n\n[1] 1\n\n(VarY &lt;- sum((y-EY)^2*py))\n\n[1] 1"
  },
  {
    "objectID": "rv_practice.html#golf-score",
    "href": "rv_practice.html#golf-score",
    "title": "5  Probability and Random Variables Practice",
    "section": "6.9 10. Golf Score",
    "text": "6.9 10. Golf Score\nOn a given day, your golf score takes values from the numbers 1 through 10 with equal probability of getting each one. Assume that you play golf for three days, and assume that your three performances are independent. Let \\(X_1, X_2\\) and \\(X_3\\) be the scores that you get, and let \\(X\\) be the minimum of these three scores.\n\n\nShow that for any discrete random variable \\(X\\) \\(p_X(k)=\\mathbb{P}(X &gt; k-1) - \\mathbb{P}(X&gt;k)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(P(X &gt; k-1) = P(X \\geq k) =P(X = k)+P(X &gt; k)\\), thus \\(P(X=k)=P(X&gt;k-1)-P(X&gt;k)\\).\n\n\n\n\nWhat is the probability that \\(\\mathbb{P}(X_1&gt;k)\\) for \\(k=1,\\ldots,10\\)?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(P(X_1&gt;k)=\\frac{10-k}{10}\\)\n\n\n\n\nUse (a) to determine the pmf \\(p_X(k)\\) for \\(k=1,\\ldots,10\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(P(X &gt; k) = P(X_1,X_2,X_3 &gt; k) = P(X_1 &gt; k)P(X_2&gt;k)P(X_3&gt;k)\\)\nThis means \\(P(X&gt;k) =\\frac{(10-k)^3}{10^3}\\), and \\(P(X&gt;k-1)=\\frac{(11-k)^3}{10^3}\\). From the previous result, \\(P(X=k)=P(X&gt;k-1)-P(X&gt;k)=\\frac{(11-k)^3-(10-k)^3}{10^3}\\)\n\n\n\n\nWhat is the average score improvement if you play just for one day compared with playing for three days and taking the minimum?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis is asking to take the difference of the two expected values. It’s obvious that \\(E(X_1)=5.5\\); We need to find the expected value of \\(X\\).\n\nx &lt;- 1:10\npx &lt;- ((11-x)^3-(10-x)^3)/10^3\n#double check\nsum(px)\n\n[1] 1\n\n(EX &lt;- sum(x*px))\n\n[1] 3.025\n\n5.5-EX\n\n[1] 2.475\n\n\nThe average (expected) point improvement when going from a 1 day point to a minimum of 3 days is 2.475."
  },
  {
    "objectID": "rv_practice.html#functions-of-a-random-variable",
    "href": "rv_practice.html#functions-of-a-random-variable",
    "title": "5  Probability and Random Variables Practice",
    "section": "6.10 11. Functions of a random variable",
    "text": "6.10 11. Functions of a random variable\nLet \\(g(X) = \\begin{cases}1 & \\text{if }X&gt;10\\\\0 & \\text{otherwise}\\end{cases}\\) and \\(h(X) = \\begin{cases}X-10 & \\text{if }X-10&gt;0\\\\0 & \\text{otherwise}\\end{cases}\\)\n\n\nFor \\(X \\in S_X=\\{1,2,\\ldots,15\\}\\) with \\(p_k = p_1/k\\), find \\(\\mathbb{E}\\left[g(X)\\right]\\)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nk &lt;- 1:15\np1 &lt;- 1/(sum(1/k))\npk &lt;- p1/k\n\ng &lt;- function(x){\n  return(as.numeric(x&gt;10))\n}\n\nsum(g(k)*pk)\n\n[1] 0.1173098\n\n\n\n\n\n\nFor \\(X \\in S_X=\\{1,2,\\ldots,15\\}\\) with \\(p_{k+1} = p_k/2\\) (for \\(k&gt;1\\)), find \\(\\mathbb{E}\\left[h(X)\\right]\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nh &lt;- function(x){\n  return(max(0, x-10))\n}\n\np1 &lt;- 1/(sum(1/2^(k-1)))\npk &lt;- p1*(1/2^(k-1))\n\nsum(h(k)*pk)\n\n[1] 5"
  },
  {
    "objectID": "rv_practice.html#voltage-ii",
    "href": "rv_practice.html#voltage-ii",
    "title": "5  Probability and Random Variables Practice",
    "section": "6.11 12. Voltage II",
    "text": "6.11 12. Voltage II\nA voltage \\(X\\) is uniformly distributed on the set \\(\\{-3,\\ldots,3,4\\}\\).\n\n\nFind the mean and variance of \\(X\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nx &lt;- -3:4\npx &lt;- 1/length(x)\n\n(EX &lt;- sum(x*px))\n\n[1] 0.5\n\n(VarX &lt;- sum((x-EX)^2*px))\n\n[1] 5.25\n\n\n\n\n\n\nFind the mean and variance of \\(Y=-2X^2+3\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ny &lt;- -2*x^2+3\n\n(EY &lt;- sum(y*px))\n\n[1] -8\n\n(VarY &lt;- sum((y-EY)^2*px))\n\n[1] 105\n\n\n\n\n\n\nFind the mean and variance of \\(W=\\text{cos}(\\pi X/8)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nw &lt;- cos(pi*x/8)\n(EW &lt;- sum(w*px))\n\n[1] 0.6284174\n\n(VarW &lt;- sum((w-EW)^2*px))\n\n[1] 0.1050915\n\n\n\n\n\n\nFind the mean and variance of \\(Z=\\text{cos}^2(\\pi X/8)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nz &lt;- w^2\n(EZ &lt;- sum(z*px))\n\n[1] 0.5\n\n(VarZ &lt;- sum((z-EZ)^2*px))\n\n[1] 0.125"
  },
  {
    "objectID": "rv_practice.html#discrete-random-variable-problems",
    "href": "rv_practice.html#discrete-random-variable-problems",
    "title": "5  Probability and Random Variables Practice",
    "section": "6.12 13. Discrete Random Variable Problems",
    "text": "6.12 13. Discrete Random Variable Problems\n\n\nIf \\(X\\) is \\(\\text{Poisson}(\\lambda)\\), compute \\(\\mathbb{E}\\left[1/(X+1)\\right]\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis can be handled mathematically. The formula for \\(E(1/(X+1))\\) is\n\\(E(1/(X+1))=\\sum_{x=0}^{\\infty}\\frac{1}{x+1}\\frac{\\lambda^{x}}{x!}e^{-\\lambda}=\\sum_{x=0}^{\\infty}\\frac{\\lambda^{x}}{(x+1)!}e^{-\\lambda}\\)\nThe trick is to get get the summation to equal 1 and simplify. We multiply by \\(\\lambda/\\lambda\\)\n\\(E(1/(X+1))=\\frac{1}{\\lambda}\\sum_{x=0}^{\\infty}\\frac{\\lambda^{x+1}}{(x+1)!}e^{-\\lambda}\\)\nNow we can make a change of variables: \\(y=x+1\\) and thus \\(x=0\\) becomes \\(y=1\\)\n\\(E(1/(X+1)) = \\frac{1}{\\lambda}\\sum_{y=1}^{\\infty}\\frac{\\lambda^{y}}{y!}e^{-\\lambda}\\)\nThe only thing missing is that the summation starts at \\(y=1\\) instead of \\(y=0\\), But for \\(Y \\sim Poisson(\\lambda)\\), \\(P(Y=0)=e^{-\\lambda}\\) so this summation is \\(1-e^{-\\lambda}\\).\n\\(E(1/(X+1)) = \\frac{1}{\\lambda}(1-e^{-\\lambda})\\)\n\n\n\n\nIf \\(X\\) is \\(\\text{Bernoulli}(p)\\) and \\(Y\\) is \\(\\text{Bernoulli}(q)\\), computer \\(\\mathbb{E}\\left[(X+Y)^3\\right]\\) assuming \\(X\\) and \\(Y\\) are independent.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\((X+Y)^3 = X^3+3X^2Y+3XY^2+Y^3\\) so \\(E[(X+Y)^3]=E(X^3)+3E(X^2)E(Y)+3E(X)E(Y^2)+E(Y^2)\\)\nthis is due to independence. Since \\(X\\) an \\(Y\\) are independent, so are \\(X^2\\) and \\(Y\\), and \\(X\\) and \\(Y^2\\). \\(E(X)=E(X^2)=E(X^3)=p\\) and \\(E(Y)=E(Y^2)=E(Y^3)=q\\). Thus \\(E[(X+Y)^3]=p+6pq+q\\)\n\n\n\n\nLet \\(X\\) be a random variable with mean \\(\\mu\\) and variance \\(\\sigma^2\\). Let \\(\\Delta(\\theta)=\\mathbb{E}\\left[(X-\\theta)^2\\right]\\). Find \\(\\theta\\) that minimizes the error \\(\\Delta(\\theta)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can expand the expected value and attempt to find the minimum with respect to \\(\\theta\\). \\(E[(X-\\theta)^2]=E[X^2-2\\theta X+\\theta^2]=E(X^2)-2\\theta\\mu+\\theta^2\\). Recall that \\(Var(X)=E(X^2)-\\mu^2\\) so \\(E(X^2)=\\sigma^2+\\mu^2\\) So we can write \\(\\Delta(\\theta)=\\sigma^2 + \\mu^2-2\\theta\\mu + \\theta^2\\) We want to find what value of \\(\\theta\\) minimizes this function - derivative! \\(\\Delta'(\\theta)=-2\\mu+2\\theta=0\\) thus \\(\\theta=\\mu\\) minimizes this.\n\n\n\n\nSuppose that \\(X_1, \\ldots, X_n\\) are independent uniform random variables in \\(\\{0,1,\\ldots,100\\}\\). Evaluate \\(\\mathbb{P}\\left[\\text{min}(X_1,\\ldots, X_n) &gt; l\\right]\\) for any \\(l \\in \\{0,1,\\ldots,100\\}\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet \\(Y=\\min(X_1, \\ldots, X_n)\\) If \\(P(Y &gt;l)\\), that means the minimum exceeds \\(l\\), so all of the values \\(&gt;l\\). \\(P(X_1 &gt; l)=(100-l)/101\\) - you can check: \\(P(X_1&gt;0)=100/101\\). This is the same calculation for each \\(i\\). So \\(P(Y&gt;l)=\\dfrac{(100-l)^n}{101^n}\\).\n\n\n\n\nConsider a binomial random variable \\(X\\) with parameters \\(n\\) and \\(p\\). \\(p_X(k)={n \\choose k} p^k(1-p)^{n-k}\\). Show that the mean is \\(\\mathbb{E}X= np\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(E(X)=\\sum_{k=0}^n k{n \\choose k} p^k(1-p)^{n-k}\\)\nThe first term is zero so we could write\n\\(\\sum_{k=1}^n k{n \\choose k} p^k(1-p)^{n-k}\\)\nNow the following is a fact that is needed but perhaps not well known. It’s the equivalence of \\(k{n \\choose k}=n{n-1 \\choose k-1}\\). We make this subsitution\n\\(\\sum_{k=1}^n n{n-1 \\choose k-1} p^k(1-p)^{n-k}=np\\sum_{k=1}^n {n-1\\choose k-1}p^{k-1}(1-p)^{n-k}\\)\nWe could write \\(n-k=(n-1)-(k-1)\\) and we’ll be making some substitutions: \\(m=n-1\\) and \\(j=k-1\\). This lets us write\n\\(np\\sum_{j=0}^m {m \\choose j}p^j(1-p)^{m-j}=np\\) because the summation =1, as it is just the sum of the pmf of a binomial.\n\n\n\n\n(not for 340) Consider a geometric random variable \\(X\\) with parameter \\(p\\). \\(p_X(k)=p(1-p)^k\\) for \\(k=0,1,\\ldots\\). Show that its mean is \\(\\mathbb{E}X=(1-p)/p\\).\n(not for 340) Consider a Poisson random variable \\(X\\) with parameter \\(\\lambda\\). \\(p_X(k)=\\dfrac{\\lambda^k}{k!}e^{-\\lambda}\\). Show that \\(\\text{Var}X=\\lambda\\).\n(not for 340) Consider the uniform random variable \\(X\\) over values \\(1,2,\\ldots, L\\). Show that \\(\\text{Var}X=\\dfrac{L^2-1}{12}\\). Hint: \\(\\sum_{i=1}^n i = \\frac{n(n+1)}{2}\\) and \\(\\sum_{i=1}^n i^2=\\frac{n^3}{3}+\\frac{n^2}{2}+\\frac{n}{6}\\)"
  },
  {
    "objectID": "rv_practice.html#hard-drive-failures",
    "href": "rv_practice.html#hard-drive-failures",
    "title": "5  Probability and Random Variables Practice",
    "section": "6.13 14. Hard Drive Failures",
    "text": "6.13 14. Hard Drive Failures\nAn audio player uses a low-quality hard drive. The probability that the hard drive fails after being used for one month is 1/12. If it fails, the manufacturer offers a free-of-charge repair for the customer. For the cost of each repair, however, the manufacturer has to pay $20. The initial cost of building the player is $50, and the manufacturer offers a 1-year warranty. Within one year, the customer can ask for a free repair up to 12 times.\n\n\nLet \\(X\\) be the number of months when the player fails. What is the PMF of \\(X\\)? Hint: \\(\\mathbb{P}(X = 1)\\) may not be very high because if the hard drive fails it will be fixed by the manufacturer. Once fixed, the drive can fail again in the remaining months. So saying \\(X = 1\\) is equivalent to saying that there is only one failure in the entire 12-month period.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe number of failures should follow a binomial distribution with \\(n=12, p=1/12\\). Thus \\(P(X=k)={n \\choose k}(\\frac{1}{12})^k(\\frac{11}{12})^{n-k}\\)\n\n\n\n\nWhat is the average cost per player?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe cost is \\(50+20X\\) So \\(E(50+20X)=50+20E(X)=50+20\\cdot 12(\\frac{1}{12})=70\\)"
  },
  {
    "objectID": "rv_practice.html#bit-errors",
    "href": "rv_practice.html#bit-errors",
    "title": "5  Probability and Random Variables Practice",
    "section": "6.14 15. Bit Errors",
    "text": "6.14 15. Bit Errors\n\nA binary communication channel has a probability of bit error of \\(p = 10^{-6}\\). Suppose that transmission occurs in blocks of 10,000 bits. Let \\(N\\) be the number of errors introduced by the channel in a transmission block.\n\n\n\nWhat is the PMF of \\(N\\)?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(N\\) follows a binomial distribution with \\(n=10000\\) and \\(p=.000001\\)\n\n\n\n\nFind \\(\\mathbb{P}(N = 0)\\) and $(N b $ 3)$.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndbinom(0, 10000, .000001)\n\n[1] 0.9900498\n\npbinom(3, 10000, .000001)\n\n[1] 1\n\n\n\n\n\n\nFor what value of \\(p\\) will the probability of 1 or more errors in a block be 99%?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis can be solved directly. \\(P(N \\geq 1)=1-P(X=0)=1-(1-p)^{10000}\\). If we set this to .99 we can solve for \\(p\\) : \\(.99=1-(1-p)^{10000}\\) so \\(.01 = (1-p)^{10000}\\) so \\(p=1-.01^{1/10000}\\)\n\n1-.01^(1/10000)\n\n[1] 0.000460411"
  },
  {
    "objectID": "rv_practice.html#processing-orders",
    "href": "rv_practice.html#processing-orders",
    "title": "5  Probability and Random Variables Practice",
    "section": "6.15 16. Processing Orders",
    "text": "6.15 16. Processing Orders\nThe number of orders waiting to be processed is given by a Poisson random variable with parameter \\(\\alpha = \\frac{\\lambda}{n\\mu}\\), where \\(\\lambda\\) is the average number of orders that arrive in a day, \\(\\mu\\) is the number of orders that an employee can process per day, and n is the number of employees. Let \\(N; = 5\\) and \\(N&lt; = 1\\). Find the number of employees required so the probability that more than four orders are waiting is less than 10%.\nHint: You need to use trial and error for a few \\(n\\)’s.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlambda=5\nmu=1\nppois(4, lambda/(1:10 * mu), lower.tail=FALSE)\n\n [1] 0.5595067149 0.1088219811 0.0275432568 0.0091242792 0.0036598468\n [6] 0.0016844329 0.0008589296 0.0004739871 0.0002784618 0.0001721156\n\n#With 3 employees P(X&gt;4) is less than 10%."
  },
  {
    "objectID": "rv_practice.html#normal-random-variable",
    "href": "rv_practice.html#normal-random-variable",
    "title": "5  Probability and Random Variables Practice",
    "section": "6.16 17. Normal Random Variable",
    "text": "6.16 17. Normal Random Variable\nIf \\(Z\\sim \\text{Normal}(\\mu=0, \\sigma^2=1^2)\\) find\n\n\n\\(\\mathbb{P}(Z &gt; 2.64)\\)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npnorm(2.64, 0, 1, lower.tail=FALSE)\n\n[1] 0.004145301\n\n\n\n\n\n\n\\(\\mathbb{P}(0 \\leq Z &lt; 0.87)\\)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npnorm(.87)-pnorm(0)\n\n[1] 0.3078498\n\n\n\n\n\n\n\\(\\mathbb{P}(|Z| &gt; 1.39)\\) (Hint: draw a picture)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npnorm(1.39, lower.tail=FALSE)*2\n\n[1] 0.1645289"
  },
  {
    "objectID": "rv_practice.html#identify-the-distribution",
    "href": "rv_practice.html#identify-the-distribution",
    "title": "5  Probability and Random Variables Practice",
    "section": "6.17 18. Identify the Distribution",
    "text": "6.17 18. Identify the Distribution\nFor the following random experiments, decide what the distribution of X should be. In nearly every case, there are additional assumptions that should be made for the distribution to apply; identify those assumptions (which may or may not strictly hold in practice).\n\n\nWe throw a dart at a dart board. Let X denote the squared linear distance from the bullseye to the where the dart landed.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAssume the dart lands somewhere on the board, and any point is equally likely (not a good assumption for a skilled dart thrower). The probability density would be proportional to the distance to the center squared - Suppose the dart board has radius \\(R\\). Let \\(X\\) be the distance to the dart from the bullseye. Then \\(P(X&lt;r)=\\pi r^2 / (\\pi R^2)=(r/R)^2\\) . The question then is what is \\(P(X^2&lt;r)\\)? Well, take a square root of both sides. \\(=P(X &lt; \\sqrt{r})=\\frac{r}{R^2}\\). This is a uniform distribution’s CDF.\n\n\n\n\nWe randomly choose a textbook from the shelf at the bookstore and let P denote the proportion of the total pages of the book devoted to exercises.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nA random proportion you might want to use uniform(0,1) however this is assuming that each proportion is equally likely. This is actually a great example for a beta distribution. Beta distributions are continuous distributions that can be parameterized to model a random proportion and the distribution can can be made to be skewed in different ways.\n\n\n\n\nWe measure the time it takes for the water to completely drain out of the kitchen sink.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet’s assume the sink is filled to the maximum. We drain the sink and start our timer. In this case, it’s reasonable to model the length of time to drain as a normal distribution.\n\n\n\n\nWe randomly sample strangers at the grocery store and ask them how long it will take them to drive home.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe time it takes to go home could be modeled by a gamma distribution since it is a continuous distribution capped below at 0 and it is a useful way to model the length of time a random process takes to complete.\n\n\n\n\nLet \\(X\\) be a Gaussian random variable with \\(\\mu=5\\) and \\(\\sigma^2=16\\).\n\n\n\nFind \\(\\mathbb{P}(X&gt;4)\\) and \\(\\mathbb{P}(2\\leq X \\leq 7)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#P(X&gt;4)\npnorm(4, mean=5, sd=4, lower.tail=FALSE)\n\n[1] 0.5987063\n\n#P(2 &lt;= X &lt;= 7)\npnorm(7, 5, 4)-pnorm(4,5,4)\n\n[1] 0.2901688\n\n\n\n\n\n\nIf \\(\\mathbb{P}(X &lt; a)=0.8869\\), find \\(a\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nqnorm(.88695, 4)\n\n[1] 5.210466\n\n\n\n\n\n\nIf \\(\\mathbb{P}(X&gt;b)=0.1131\\), find \\(b\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nqnorm(.1131, 5, 4, lower.tail=FALSE)\n\n[1] 9.840823\n\n\n\n\n\n\nIf \\(\\mathbb{P}(13 &lt; X \\leq c)=0.0011\\), find \\(c\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#First find the probability less than 13\np13 &lt;- pnorm(13, 5, 4)\n#now we can find the quantile for p13+.0011\nqnorm(p13+.0011, 5, 4)\n\n[1] 13.08321\n\n#double check\npnorm(13.08321,5,4)-pnorm(13,5,4)\n\n[1] 0.001100025\n\n\n\n\n\n\nConsider a cdf\n\n\\(F_X(x)-\\begin{cases}0,&\\text{if }x &lt; -1\\\\ 0.5 & \\text{if }-1 \\leq x &lt; 0\\\\(1+x)/2 & \\text{if }0 \\leq x &lt; 1\\\\1&\\text{otherwise}\\end{cases}\\)\nFind \\(\\mathbb{P}(X &lt; -1)\\), \\(\\mathbb{P}(-0.5 &lt; X &lt; 0.5)\\), and \\(\\mathbb{P}(X&gt;0.5)\\).\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#P(X &lt; -1) = 0 because F(x) only goes up to .5 at x=-1, not when x &lt; -1\n\n#P(-.5 &lt; X &lt; .5) = F(.5) - F(-.5)\n(1+.5)/2 - .5\n\n[1] 0.25\n\n#P(X &gt; 0.5) = 1-P(X&lt;.5) = 1-F(.5) \n1- (1+.5)/2\n\n[1] 0.25"
  },
  {
    "objectID": "cov_practice.html",
    "href": "cov_practice.html",
    "title": "6  Independence and Conditional Probability Practice",
    "section": "",
    "text": "7 Practice Problems\nThese problems are excellent practice but they are beyond the material we cover in STAT 340."
  },
  {
    "objectID": "cov_practice.html#two-fair-coins",
    "href": "cov_practice.html#two-fair-coins",
    "title": "6  Independence and Conditional Probability Practice",
    "section": "7.1 1. Two Fair Coins",
    "text": "7.1 1. Two Fair Coins\nAlex and Bob each flips a fair coin twice. Use “1” to denote heads and “0” to denote tails. Let X be the maximum of the two numbers Alex gets, and let Y be the minimum of the two numbers Bob gets.\n\n\nFind and sketch the joint PMF \\(p_{X,Y} (x, y)\\).\nFind the marginal PMF \\(p_X(x)\\) and \\(p_Y (y)\\).\nFind the conditional PMF \\(P_{X|Y} (x | y)\\). Does \\(P_{X|Y} (x | y) = P_X(x)\\)? Why or why not?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nx &lt;- 0:1\npx &lt;- c(.25, .75) \n\ny&lt;- 0:1\npy &lt;- c(.75, .25)\n\npmf &lt;- px %*% t(py)\nrownames(pmf) &lt;- x\ncolnames(pmf) &lt;- y \naddmargins(pmf)\n\n         0      1  Sum\n0   0.1875 0.0625 0.25\n1   0.5625 0.1875 0.75\nSum 0.7500 0.2500 1.00\n\n\n\nprop.table(pmf, 2)\n\n     0    1\n0 0.25 0.25\n1 0.75 0.75\n\n\nEach column gives P(X=x|Y=y) for the two values of y; you can see that they are the same; the reason is because the value of X and Y are independent."
  },
  {
    "objectID": "cov_practice.html#two-fair-dice",
    "href": "cov_practice.html#two-fair-dice",
    "title": "6  Independence and Conditional Probability Practice",
    "section": "7.2 2. Two Fair Dice",
    "text": "7.2 2. Two Fair Dice\nTwo fair dice are rolled. Find the joint PMF of \\(X\\) and \\(Y\\) when\n\n\n\\(X\\) is the larger value rolled, and \\(Y\\) is the sum of the two values.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndie1 &lt;- rep(1:6, 6)\ndie2 &lt;- rep(1:6, rep(6,6))\noutcomes &lt;- data.frame(die1, die2)\noutcomes$x &lt;- pmax(die1, die2)\noutcomes$y &lt;- die1+die2\npmf &lt;- prop.table(table(outcomes$x, outcomes$y))\npmf\n\n   \n             2          3          4          5          6          7\n  1 0.02777778 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000\n  2 0.00000000 0.05555556 0.02777778 0.00000000 0.00000000 0.00000000\n  3 0.00000000 0.00000000 0.05555556 0.05555556 0.02777778 0.00000000\n  4 0.00000000 0.00000000 0.00000000 0.05555556 0.05555556 0.05555556\n  5 0.00000000 0.00000000 0.00000000 0.00000000 0.05555556 0.05555556\n  6 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.05555556\n   \n             8          9         10         11         12\n  1 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000\n  2 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000\n  3 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000\n  4 0.02777778 0.00000000 0.00000000 0.00000000 0.00000000\n  5 0.05555556 0.05555556 0.02777778 0.00000000 0.00000000\n  6 0.05555556 0.05555556 0.05555556 0.05555556 0.02777778\n\n\n\n\n\n\n\\(X\\) is the smaller, and \\(Y\\) is the larger value rolled.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndie1 &lt;- rep(1:6, 6)\ndie2 &lt;- rep(1:6, rep(6,6))\noutcomes &lt;- data.frame(die1, die2)\noutcomes$x &lt;- pmin(die1, die2)\noutcomes$y &lt;- pmax(die1,die2)\npmf &lt;- prop.table(table(outcomes$x, outcomes$y))\npmf\n\n   \n             1          2          3          4          5          6\n  1 0.02777778 0.05555556 0.05555556 0.05555556 0.05555556 0.05555556\n  2 0.00000000 0.02777778 0.05555556 0.05555556 0.05555556 0.05555556\n  3 0.00000000 0.00000000 0.02777778 0.05555556 0.05555556 0.05555556\n  4 0.00000000 0.00000000 0.00000000 0.02777778 0.05555556 0.05555556\n  5 0.00000000 0.00000000 0.00000000 0.00000000 0.02777778 0.05555556\n  6 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.02777778"
  },
  {
    "objectID": "cov_practice.html#two-normal-rvs",
    "href": "cov_practice.html#two-normal-rvs",
    "title": "6  Independence and Conditional Probability Practice",
    "section": "7.3 3. Two Normal RVs",
    "text": "7.3 3. Two Normal RVs\nLet X and Y be zero-mean, unit-variance independent Gaussian random variables. Find the value of r for which the probability that \\((X, Y )\\) falls inside a circle of radius r is 1/2.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nx &lt;- rnorm(10000)\ny &lt;- rnorm(10000)\n\nr &lt;- seq(1.1, 1.2, .005)\np &lt;- 0\nfor (i in 1:length(r)){\n  p[i] &lt;- mean(sqrt(x^2+y^2) &lt;= r[i])\n}\ndata.frame(r,p)\n\n       r      p\n1  1.100 0.4654\n2  1.105 0.4685\n3  1.110 0.4707\n4  1.115 0.4745\n5  1.120 0.4764\n6  1.125 0.4798\n7  1.130 0.4831\n8  1.135 0.4855\n9  1.140 0.4888\n10 1.145 0.4918\n11 1.150 0.4954\n12 1.155 0.4987\n13 1.160 0.5017\n14 1.165 0.5042\n15 1.170 0.5074\n16 1.175 0.5105\n17 1.180 0.5130\n18 1.185 0.5168\n19 1.190 0.5201\n20 1.195 0.5223\n21 1.200 0.5247\n\n#X^2 + Y^2 ~ Chisq(2)\n#so the square root of the 50th percentile from that distribution should be the answer\nsqrt(qchisq(.5,2))\n\n[1] 1.17741"
  },
  {
    "objectID": "cov_practice.html#uniform-random-angle",
    "href": "cov_practice.html#uniform-random-angle",
    "title": "6  Independence and Conditional Probability Practice",
    "section": "7.4 4. Uniform Random Angle",
    "text": "7.4 4. Uniform Random Angle\nLet \\(\\Theta ∼ Uniform[0, 2\\pi]\\).\n\n\nIf \\(X = cos \\Theta\\), \\(Y = sin \\Theta\\). Are \\(X\\) and \\(Y\\) uncorrelated?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nYes, they are uncorrelated, because (x,y) can be any point on the circumference of a circle of radius 1 with uniform likelihood. However, they are not independent. If we know the value of \\(Y\\) for example, there are only 2 possible values of \\(X\\).\n\nthetas &lt;- runif(10000, 0, 2*pi)\ncor(cos(thetas), sin(thetas))\n\n[1] 0.01024295\n\n\n\n\n\n\nIf \\(X = cos(\\Theta/4)\\), \\(Y = sin(\\Theta/4)\\). Are \\(X\\) and \\(Y\\) uncorrelated?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIn this case (x,y) can only be found in the first quadrant. In this case they are going to be negatively correlated, since that portion of the unit circle in the first quadrant slopes downwards.\n\ncor(cos(thetas/4), sin(thetas/4))\n\n[1] -0.9184621\n\n\n\n\n\n##5. Signal and Noise Let \\(Y = X+N\\), where \\(X\\) is the input, \\(N\\) is the noise, and \\(Y\\) is the output of a system. Assume that \\(X\\) and \\(N\\) are independent random variables. It is given that \\(E[X] = 0\\), \\(Var[X] = \\sigma^2_X\\), \\(E[N] = 0\\), and \\(Var[N] = \\sigma^2_N\\).\n\n\nFind the correlation coefficient \\(\\rho\\) between the input \\(X\\) and the output \\(Y\\) .\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(\\rho(X,Y)= \\dfrac{Cov(X,Y)}{SD(X)SD(Y)}=\\dfrac{E(XY)-E(X)E(Y)}{\\sigma_X \\cdot \\sqrt{\\sigma^2_X+\\sigma^2_N}}\\)\n\\(E(XY)=E(X^2+XN)=E(X^2)+E(X)E(N)\\). Because \\(E(X)=E(N)=0\\) this simplifies to\n\\(\\rho(X,y)=\\dfrac{E(X^2)}{\\sigma_x\\sqrt{\\sigma^2_X+\\sigma^2_N}}\\)\n\\(Var(X)=E(X^2)-E(X)^2 = E(X^2)\\) so we can replace the numerator with \\(\\sigma^2_X\\). So\n\\(\\rho(X,Y) = \\sqrt{\\dfrac{\\sigma^2_X}{\\sigma^2_X+\\sigma^2_N}}\\)\n\n#example: sigma_X = 5, sigma_N=2\nX &lt;- rnorm(10000, 0, 5)\nN &lt;- rnorm(10000, 0, 2)\ncor(X, X+N)\n\n[1] 0.9298284\n\nsqrt(5^2/(5^2+2^2))\n\n[1] 0.9284767\n\n\n\n\n\n\nSuppose we estimate the input \\(X\\) by a linear function \\(g(Y ) = aY\\) . Find the value of a that minimizes the mean squared error \\(E[(X − aY )^2]\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(E[(X-aY)^2]=E[X^2-2aXY+a^2Y^2]=E[X^2]-2aE[XY]+a^2E[Y^2]\\)\nBecause \\(E(Y)=0\\), \\(E[Y^2]=Var(Y)=\\sigma_X^2+\\sigma_N^2\\). We already have that \\(E(X^2)=\\sigma_X^2\\) and \\(E(XY)=\\sigma_X^2\\). Thus\n$E[(X-aY)^2]=(_X^2+_N2)a2- 2_X^2a+_X^2 $\nThis is a quadratic function in \\(a\\), and the vertex can be found at \\(-\\frac{B}{2A}\\) or in this case \\(a^*=\\dfrac{\\sigma_X^2}{\\sigma_X^2+\\sigma_N^2}\\)\n\n\n\n\nExpress the resulting mean squared error in terms of \\(\\eta = \\sigma^2_X/\\sigma^2_N\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nPlugging this in for \\(a\\) we get\n\\(E[(X-aY)^2]=(\\sigma_X^2+\\sigma_N^2)\\dfrac{\\sigma_X^4}{(\\sigma_X^2+\\sigma_N^2)^2}-2\\dfrac{\\sigma_X^4}{\\sigma_X^2+\\sigma_N^2}+\\sigma_X^2=\\sigma_X^2\\left(1-\\dfrac{\\sigma_X^2}{\\sigma_X^2+\\sigma_N^2}\\right)\\)\n\\(=\\sigma_X^2\\left(\\dfrac{\\sigma_N^2}{\\sigma_X^2+\\sigma_N^2}\\right)=\\dfrac{\\sigma_X^2}{\\eta+1}\\)"
  },
  {
    "objectID": "cov_practice.html#cat-genetics",
    "href": "cov_practice.html#cat-genetics",
    "title": "6  Independence and Conditional Probability Practice",
    "section": "7.5 6. Cat Genetics",
    "text": "7.5 6. Cat Genetics\nThe gene that controls white coat color in cats, KIT , is known to be responsible for multiple phenotypes such as deafness and blue eye color. A dominant allele W at one location in the gene has complete penetrance for white coat color; all cats with the W allele have white coats. There is incomplete penetrance for blue eyes and deafness; not all white cats will have blue eyes and not all white cats will be deaf. However, deafness and blue eye color are strongly linked, such that white cats with blue eyes are much more likely to be deaf. The variation in penetrance for eye color and deafness may be due to other genes as well as environmental factors.\n\nSuppose that 30% of white cats have one blue eye, while 10% of white cats have two blue eyes.\nAbout 73% of white cats with two blue eyes are deaf\n40% of white cats with one blue eye are deaf.\nOnly 19% of white cats with other eye colors are deaf.\n\n\nCalculate the prevalence of deafness among white cats.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nn.blue &lt;- c(0,1,2)\np.n.blue &lt;- c(.60, .30, .10)\n\np.deaf.given.b &lt;- c(.19, .40, .73) #for 0, 1 ,2 blue eyes\n\n#P(Deafness) = P(0b)*P(deaf|0b) + P(1b)*P(deaf|1b) + P(2b)*P(deaf|2b)\n(p.deaf &lt;- sum(p.n.blue * p.deaf.given.b))\n\n[1] 0.307\n\n#Check\nnCats &lt;- 10000\nnblue &lt;- sample(n.blue, size=nCats, replace=TRUE, prob=p.n.blue)\nisdeaf &lt;- FALSE\nfor(i in 1:nCats){\n  isdeaf[i] &lt;- runif(1) &lt; p.deaf.given.b[nblue[i]+1]\n}\nmean(isdeaf)\n\n[1] 0.3057\n\n\n\n\n\n\nGiven that a white cat is deaf, what is the probability that it has two blue eyes?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#P(2b | deaf) = P(2b)*P(deaf|2b) / p(deaf)\np.n.blue[3] * p.deaf.given.b[3] / p.deaf\n\n[1] 0.237785\n\n#check\nmean(nblue[isdeaf]==2)\n\n[1] 0.2342166\n\n\n\n\n\n\nSuppose that deaf, white cats have an increased chance of being blind, but that the prevalence of blindness differs according to eye color. While deaf, white cats with two blue eyes or two non-blue eyes have probability 0.20 of developing blindness, deaf and white cats with one blue eye have probability 0.40 of developing blindness. White cats that are not deaf have probability 0.10 of developing blindness, regardless of their eye color.\nWhat is the prevalence of blindness among deaf, white cats?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\np.blind.given.nodeaf &lt;- 0.10\np.blind.given.deaf.and.nblue &lt;- c(0.20, 0.4, 0.2) #for 0, 1, 2 blue eyes\n\n#P(blind & deaf) = P(0b)*P(deaf|0b)*P(blind|deaf&0b)+\n#  P(1b)*P(deaf|1b)*P(blind|deaf&1b)+\n#  P(2b)*P(deaf|2b)*P(blind|deaf&2b)+\np.blind.and.deaf &lt;- sum(p.n.blue * p.deaf.given.b * p.blind.given.deaf.and.nblue)\n\n#P(blind | deaf ) = P(blind & deaf) / P(deaf)\n(p.blind.given.deaf = p.blind.and.deaf / p.deaf)\n\n[1] 0.2781759\n\n#check\nisBlind &lt;- FALSE\nfor(i in 1:nCats){\n  if(!isdeaf[i]){\nisBlind[i] &lt;- runif(1) &lt; p.blind.given.nodeaf\n  } else {\nisBlind[i] &lt;- runif(1) &lt; p.blind.given.deaf.and.nblue[nblue[i]+1]\n  }\n}\n#check\nmean(isBlind[isdeaf])\n\n[1] 0.2744521\n\n\n\n\n\n\nWhat is the prevalence of blindness among white cats?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#P(blind) = P(deaf & blind) + P(nondeaf & blind)\n\n#P(nondeaf & blind ) = P(nondeaf) * P(blind | nondeaf)\np.blind.and.nondeaf &lt;- (1-p.deaf)*p.blind.given.nodeaf\n\n(p.blind &lt;- p.blind.and.deaf + p.blind.and.nondeaf)\n\n[1] 0.1547\n\n#check\nmean(isBlind)\n\n[1] 0.1531\n\n\n\n\n\n\nGiven that a cat is white and blind, what is the probability that it has two blue eyes?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#P(2b | blind) = P(2b & blind) / p(blind)\n#numerator: P(2b & blind) = P(2b) * [P(deaf|2b) * p(blind|deaf & 2b) + P(nondeaf|2b) * p(blind|nondeaf & 2b)]\np.blind.and.2b &lt;- p.n.blue[3] * (p.deaf.given.b[3]*p.blind.given.deaf.and.nblue[3] + \n (1-p.deaf.given.b[3]) * p.blind.given.nodeaf)\n\n(p.2b.given.blind = p.blind.and.2b / p.blind)\n\n[1] 0.1118293\n\n#check\nmean(nblue[isBlind]==2)\n\n[1] 0.1071195"
  },
  {
    "objectID": "cov_practice.html#gss-survey-i",
    "href": "cov_practice.html#gss-survey-i",
    "title": "6  Independence and Conditional Probability Practice",
    "section": "7.6 7. GSS Survey I",
    "text": "7.6 7. GSS Survey I\nLinda is 31 years old, single, outspoken, and very bright. She majored in philosophy. As a student, she was deeply concerned with issues of discrimination and social justice, and also participated in anti-nuclear demonstrations. Which is more probable?\n\n\nLinda is a banker.\nLinda is a banker and considers herself a liberal Democrat.\n\nTo answer this question we will use data from the GSS survey found at https://github.com/AllenDowney/ThinkBayes2/raw/master/data/gss_bayes.csv.\nThe code for “Banking and related activities” in the indus10 variable is 6870. The values of the column sex are encoded like this:\n1: Male, 2: Female\nThe values of polviews are on a seven-point scale:\n1 Extremely liberal\n2 Liberal\n3 Slightly liberal\n4 Moderate\n5 Slightly conservative\n6 Conservative\n7 Extremely conservative\nDefine “liberal” as anyone whose political views are 3 or below. The values of partyid are encoded:\n0 Strong democrat\n1 Not strong democrat\n2 Independent, near democrat\n3 Independent\n4 Independent, near republican\n5 Not strong republican\n6 Strong republican\n7 Other party\nYou need to compute:\n\nThe probability that Linda is a female banker,\nThe probability that Linda is a liberal female banker, and\nThe probability that Linda is a liberal female banker and a Democrat.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ngss &lt;- read.csv(\"https://github.com/AllenDowney/ThinkBayes2/raw/master/data/gss_bayes.csv\")\n#banker : indus10==6870\n#female : sex == 2\n#liberal: polviews &lt;= 3\n#democrat: partyid &lt;= 2\n\n#In my reading, I am interpreteing that 'Linda is female' is given from the context;\n\n#P(banker | female) \nmean(gss[gss$sex==2,]$indus10==6870)\n\n[1] 0.02116103\n\n#P(liberal banker | female)\nmean(gss[gss$sex==2 & gss$polviews &lt;=3,]$indus10==6870)\n\n[1] 0.01723195\n\n#P(liberal Dem banker | female)\nmean(gss[gss$sex==2 & gss$polviews &lt;=3 & gss$partyid &lt;= 1,]$indus10==6870)\n\n[1] 0.01507289\n\n\n\n\n\n##8. GSS Survey II Compute the following probabilities:\n\n\nWhat is the probability that a respondent is liberal, given that they are a Democrat?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmean(gss[gss$partyid&lt;=1,]$polviews&lt;=3)\n\n[1] 0.389132\n\n\n\n\n\n\nWhat is the probability that a respondent is a Democrat, given that they are liberal?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmean(gss[gss$polviews&lt;=3,]$partyid&lt;=1)\n\n[1] 0.5206403"
  },
  {
    "objectID": "cov_practice.html#gss-survey-iii",
    "href": "cov_practice.html#gss-survey-iii",
    "title": "6  Independence and Conditional Probability Practice",
    "section": "7.7 9. GSS Survey III",
    "text": "7.7 9. GSS Survey III\nThere’s a famous quote about young people, old people, liberals, and conservatives that goes something like:\n\nIf you are not a liberal at 25, you have no heart. If you are not a conservative at 35, you have no brain.\n\nWhether you agree with this proposition or not, it suggests some probabilities we can compute as an exercise. Rather than use the specific ages 25 and 35, let’s define young and old as under 30 or over 65. For these thresholds, I chose round numbers near the 20th and 80th percentiles. Depending on your age, you may or may not agree with these definitions of “young” and “old”.\nI’ll define conservative as someone whose political views are “Conservative”, “Slightly Conservative”, or “Extremely Conservative”.\nCompute the following probabilities. For each statement, think about whether it is expressing a conjunction, a conditional probability, or both. For the conditional probabilities, be careful about the order of the arguments. If your answer to the last question is greater than 30%, you have it backwards!\n\nWhat is the probability that a randomly chosen respondent is a young liberal?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmean(gss$age &lt;30 & gss$polviews &lt;=3)\n\n[1] 0.06579428\n\n\n\n\n\n\nWhat is the probability that a young person is liberal?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmean(gss[gss$age &lt;30,]$polviews &lt;=3)\n\n[1] 0.3385177\n\n\n\n\n\n\nWhat fraction of respondents are old conservatives?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmean(gss$age &gt;65 & gss$polviews &gt;= 5)\n\n[1] 0.06226415\n\n\n\n\n\n\nWhat fraction of conservatives are old?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmean(gss[gss$polviews &gt;=5,]$age &gt;65)\n\n[1] 0.1820933"
  },
  {
    "objectID": "cov_practice.html#two-child-paradox",
    "href": "cov_practice.html#two-child-paradox",
    "title": "6  Independence and Conditional Probability Practice",
    "section": "7.8 10. Two Child Paradox",
    "text": "7.8 10. Two Child Paradox\nSuppose you meet someone and learn that they have two children. You ask if either child is a girl and they say yes. What is the probability that both children are girls? (Hint: Start with four equally likely hypotheses.)\n\n\n\n\n\n\nSolution\n\n\n\n\n\nBefore we know anything about their two kids, the number of girls \\(X\\) they have could be 0, 1 or 2. Simplifying the scenario with the ‘equally likely hypothesis’ means that we assume each kid has a 50% chance of being a girl, independently. Thus the probabilities are 0.25, 0.5 and 0.25 respectively.\nIf we learn that at least one of the kids is a girl, that tells us that the first possibility, that \\(x=0\\) is not possible. Thus \\(P(X=2 | X&gt;0) = .\\dfrac{25}{.5+.25}= \\frac{1}{3}\\)**"
  },
  {
    "objectID": "cov_practice.html#monty-hall",
    "href": "cov_practice.html#monty-hall",
    "title": "6  Independence and Conditional Probability Practice",
    "section": "7.9 11. Monty Hall",
    "text": "7.9 11. Monty Hall\nThere are many variations of the Monty Hall problem. For example, suppose Monty always chooses Door 2 if he can, and only chooses Door 3 if he has to (because the car is behind Door 2).\n\n\nIf you choose Door 1 and Monty opens Door 2, what is the probability the car is behind Door 3?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#3 equally likely possibilities:\n#C1  -&gt; Monty chooses Door 2\n#C2  -&gt; Monty cannot choose Door 2, chooses Door 3\n#C3  -&gt; Monty chooses Door 2\n\n#So if Monty chooses Door 2, either C1 or C3 must be the case, each equally likely. \n#Thus P(C3 | Monty chooses 2) = .50\n\n\n\n\n\nIf you choose Door 1 and Monty opens Door 3, what is the probability the car is behind Door 2?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#If he chose Door 3, that means that it must be the case that the car is behind \n#door 2; he would *ONLY* choose door 3 in that case.\n\n#Thus P(C2 | Monty chooses 3) = 1.0"
  },
  {
    "objectID": "cov_practice.html#mms",
    "href": "cov_practice.html#mms",
    "title": "6  Independence and Conditional Probability Practice",
    "section": "7.10 12. M&Ms",
    "text": "7.10 12. M&Ms\nM&M’s are small candy-coated chocolates that come in a variety of colors. Mars, Inc., which makes M&M’s, changes the mixture of colors from time to time. In 1995, they introduced blue M&M’s.\n\nIn 1994, the color mix in a bag of plain M&M’s was 30% Brown, 20% Yellow, 20% Red, 10% Green, 10% Orange, 10% Tan.\nIn 1996, it was 24% Blue , 20% Green, 16% Orange, 14% Yellow, 13% Red, 13% Brown.\n\nSuppose a friend of mine has two bags of M&M’s, and he tells me that one is from 1994 and one from 1996. He won’t tell me which is which, but he gives me one M&M from each bag. One is yellow and one is green. What is the probability that the yellow one came from the 1994 bag?\n(Hint: The trick to this question is to define the hypotheses and the data carefully.)\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\(P(G|94) = .10, P(G|96) = .20\\) \\(P(Y|94) = .20, P(Y|96) = .14\\) \\(P(94)=P(96)=.50\\) assuming equally likely. It’s important to realize only one of two situations could have occurred:\n\nSituation 1: A G was chosen from the 94 bag and a Y was chosen from the 96 bag\nSituation 2: A Y was chosen from the 94 bag and a G was chosen from the 96 bag.\n\nThe corresponding probabilities are \\((.10)(.14)=.014\\) and \\((.20)(.20)=.04)\\). The question could be stated: What is the probability that Sit.1 occurred given that either Sit1 or Sit2 occured.\nThe likelihood is \\(.014 / (.014+.04) = .2592593\\)"
  },
  {
    "objectID": "cov_practice.html#two-coins",
    "href": "cov_practice.html#two-coins",
    "title": "6  Independence and Conditional Probability Practice",
    "section": "7.11 13. Two Coins",
    "text": "7.11 13. Two Coins\nSuppose you have two coins in a box. One is a normal coin with heads on one side and tails on the other, and one is a trick coin with heads on both sides. You choose a coin at random and see that one of the sides is heads. What is the probability that you chose the trick coin?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis is actually similar to the “family with two girls” problem. The equally likely coins are “HT” and “HH”.\n\\(P(Heads | HH) = 1\\) \\(P(Heads | TH) = .5\\)\nBayes Theorem tells us that \\(P(HH | Heads) = \\dfrac{P(HH)*P(Heads|HH)}{P(HH)P(Heads|HH)+P(TH)P(Heads|TH)}=\\dfrac{.5}{.5+.25}=\\frac23\\)\nSeems counter intuitive! If I pick a random coin from the two, you already know that one of the sides is a head without looking at it. Somehow then, when you look at just one side of the coin, seeing a H makes you 67% sure that it is the trick coin. The reason is that seeing the head side is like flipping it once and getting a H. That is less likely to occur with the fair coin, hence this outcome lends evidence to the “trick coin” hypothesis."
  },
  {
    "objectID": "RV_summary.html#rv-summary",
    "href": "RV_summary.html#rv-summary",
    "title": "Appendix A — Random Variable Summary",
    "section": "A.1 RV summary",
    "text": "A.1 RV summary\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(X\\)\nBinomial\nGeometric\nPoisson\nDiscrete Uniform\nNormal\n(Continuous) Uniform\nExponential\n\n\n\n\nType\nDiscrete\nDiscrete\nDiscrete\nDiscrete\nContinuous\nContinuous\nContinuous\n\n\nParameters\n\\(n\\), \\(p\\)\n\\(p\\)\n\\(\\lambda\\)\n\\(a\\), \\(b\\)\n\\(\\mu\\), \\(\\sigma^2\\)\n\\(a\\), \\(b\\)\n\\(\\lambda\\)\n\n\nDescription\nNumber of successes in \\(n\\) independent trials with \\(p\\) probability of success for each trial  (Note: Bernoulli is just Binomial with \\(n\\!=\\!1\\))\nNumber of failures BEFORE the first success while independently repeating trial with \\(p\\) probability of success\nCount of number of occurrences of an event with constant mean rate \\(\\lambda\\) that’s independent of previous occurrences\n\\(n\\)-sided fair die\nNormal distributions usually arise from CLT (i.e. they’re processes that are the sum of many smaller independent processes)\nGeneralizing \\(n\\)-sided fair die to a continuous interval\nWaiting time between Poisson events\n\n\nOutcomes\n\\(0,1,\\ldots,n\\)\n\\(0,1,\\ldots\\)\n\\(0,1,\\ldots\\)\n\\(a,a\\!+\\!1,\\ldots,b\\)\n\\((-\\infty,\\infty)\\)\n\\([a,b]\\)\n\\([0,\\infty)\\)\n\n\nPDF/PMF at \\(k\\)\n\\({n\\choose k}p^k(n-p)^{n-k}\\)\n\\(p(1-p)^k\\)\n\\(\\frac{\\lambda^ke^{-\\lambda}}{k!}\\)\n\\(\\frac1{b-(a-1)}\\)\n\\(\\frac1{\\sigma\\sqrt{2\\pi}}e^{-\\frac12\\left(\\frac{x-\\mu}\\sigma\\right)^2}\\)\n\\(\\frac1{b-a}\\)\n\\(\\lambda e^{-\\lambda x}\\)\n\n\n\\(P(X\\le k)\\)\n\n\\(1-(1-p)^{\\lfloor k\\rfloor+1}\\)\n\n\\(\\frac{\\lfloor k\\rfloor-(a-1)}{b-(a-1)}\\)\n\n\\(\\frac{x-a}{b-a}\\)\n\\(1-e^{-\\lambda x}\\)\n\n\nMean\n\\(np\\)\n\\(\\frac{1-p}p\\)\n\\(\\lambda\\)\n\\(\\frac{a+b}2\\)\n\\(\\mu\\)\n\\(\\frac{a+b}2\\)\n\\(\\frac1\\lambda\\)\n\n\nVariance\n\\(np(1-p)\\)\n\\(\\frac{1-p}{p^2}\\)\n\\(\\lambda\\)\n\\(\\frac{(b-(a-1))^2-1}{12}\\)\n\\(\\sigma^2\\)\n\\(\\frac{(b-a)^2}{12}\\)\n\\(\\frac1{\\lambda^2}\\)\n\n\nR functions\ndbinom, pbinom, qbinom, rbinom\ndgeom, pgeom, qgeom, rgeom\ndpois, ppois, qpois, rpois\nsample\ndnorm, pnorm, qnorm, rnorm\ndunif, punif, qunif, runif\ndexp, pexp, qexp, rexp"
  },
  {
    "objectID": "R01_RandomVariables.html#bernoulli",
    "href": "R01_RandomVariables.html#bernoulli",
    "title": "4  Random Variables R Examples",
    "section": "4.1 Bernoulli",
    "text": "4.1 Bernoulli\nLike the flip of a fair or unfair coin. X=1 if the coin comes up heads, 0 on tails.\n\n#Parameters\np &lt;- .3 # the probability of a success\n\n#Generating 10 random values\nrbinom(10, size=1, prob=p)\n\n [1] 0 0 1 1 0 0 0 0 0 1\n\n\nExpected value is \\[\\sum_k k\\cdot Pr[X=k]\\]\n\n#All possible values\nk &lt;- 0:1\n#Associated probabilities\nPr &lt;- dbinom(k, size=1, prob=p)\n#expectation\nsum(k*Pr)\n\n[1] 0.3\n\n\nThe expected value is \\(p\\) and the variance is \\(p(1-p)\\)\n\nbernoulli.sim &lt;- rbinom(100, size=1, prob=p)\n\n# Expectation\np\n\n[1] 0.3\n\n# from sample\nmean(bernoulli.sim)\n\n[1] 0.32\n\n# Variance\np*(1-p)\n\n[1] 0.21\n\n#from sample\nvar(bernoulli.sim)\n\n[1] 0.219798"
  },
  {
    "objectID": "R01_RandomVariables.html#binomial",
    "href": "R01_RandomVariables.html#binomial",
    "title": "4  Random Variables R Examples",
    "section": "4.2 Binomial",
    "text": "4.2 Binomial\nLike flipping a fair (or unfair) coin \\(n\\) times, counting the number of heads.\n\n#Parameters\nn &lt;- 8  #the number of flips / attempts\np &lt;- .4 #the probability of success\n\n#Generate 10 random values\nrbinom(10, size=n, prob=p)\n\n [1] 4 1 5 3 3 4 2 4 2 1\n\n#Calculate P(X=3)\ndbinom(x=3, size=n, prob=p)\n\n[1] 0.2786918\n\n#Calculate all probabilities\ndbinom(x=0:8, size=n, prob=p)\n\n[1] 0.01679616 0.08957952 0.20901888 0.27869184 0.23224320 0.12386304 0.04128768\n[8] 0.00786432 0.00065536\n\n#Calculate P(X &lt;= 3)\npbinom(q=3, size=n, prob=p)\n\n[1] 0.5940864\n\n\nExpected value is \\[\\sum_k k\\cdot Pr[X=k]\\]\n\n#All possible values\nk &lt;- 0:n\n#Associated probabilities\nPr &lt;- dbinom(k, size=n, prob=p)\n#expectation\nsum(k*Pr)\n\n[1] 3.2\n\nn*p\n\n[1] 3.2\n\n\nThe probability mass function\n\nbarplot(Pr, names=k, main=\"Probability Mass Function of Binomial(8,.4)\")\n\n\n\n\nThe cumulative distribution function\n\nx &lt;- 0:8\ncdfx &lt;- pbinom(x, size=n,prob=.4)\nplot(x, cdfx, type=\"s\", main=\"Cumulative Distribution Function of Binomial(8,.4)\", ylim=c(0,1))\n\n\n\n\nThe expected value is \\(np\\) and the variance is \\(np(1-p)\\)\n\nbinomial.sim &lt;- rbinom(10000, size=n, prob=p)\n\n# Expectation\nn*p\n\n[1] 3.2\n\n# from sample\nmean(binomial.sim)\n\n[1] 3.2196\n\n# Variance\nn*p*(1-p)\n\n[1] 1.92\n\n#from sample\nvar(binomial.sim)\n\n[1] 1.899366"
  },
  {
    "objectID": "R01_RandomVariables.html#geometric",
    "href": "R01_RandomVariables.html#geometric",
    "title": "4  Random Variables R Examples",
    "section": "4.3 Geometric",
    "text": "4.3 Geometric\nCounting how many tails before the first head; the number of failures before the first success (independent trials, probability of success remains constant)\n\n#Parameters\np &lt;- .4 #The probability of success on each trial\n\n#Generate 10 random values\nrgeom(10, prob=p)\n\n [1] 2 0 0 4 0 4 1 4 2 0\n\n\nThe probability mass function…. only going out to 20, but the support is infinite!\n\nk &lt;- 0:20\nPr &lt;- dgeom(k, prob=p)\nbarplot(Pr, names=k, main=\"Probability Mass Function of Geom(.4)\")\n\n\n\n\nThe cumulative distribution function\n\ncdfx &lt;- cumsum(Pr)\n\n# if you want it to look really proper\nn &lt;- length(k)\nplot(x = NA, y = NA, pch = NA, \n     xlim = c(0, max(k)), \n     ylim = c(0, 1),\n     ylab = \"Cumulative Probability\",\n     main = \"Cumulative Distribution Function of Geom(.4)\")\npoints(x = k[-n], y = cdfx[-n], pch=19)\npoints(x = k[-1], y = cdfx[-n], pch=1)\nfor(i in 1:(n-1)) points(x=k[i+0:1], y=cdfx[c(i,i)], type=\"l\")\n\n\n\n\nBut it’s probably faster to just use a step type plot. The vertical lines are not technically part of the plot though.\n\nplot(k, cdfx, type=\"s\", main=\"Cumulative Distribution Function of Geom(.4)\", ylim=c(0,1))\npoints(k, cdfx, pch = 16, col = \"blue\")\n\n\n\n\nYou can get the cumulative probabilities from the pgeom function\n\nplot(k, pgeom(k, prob=.4), type=\"s\", main=\"Cumulative Distribution Function of Geom(.4)\", ylim=c(0,1))\npoints(k, cdfx, pch = 16, col = \"blue\")\n\n\n\n\nThe expected value is \\(\\dfrac{1-p}{p}\\) and the variance is \\(\\dfrac{1-p}{p^2}\\)\n\ngeom.sim &lt;- rgeom(10000, prob=p)\n\n# Expectation\n(1-p)/p\n\n[1] 1.5\n\n# from sample\nmean(geom.sim)\n\n[1] 1.5128\n\n# Variance\n(1-p)/(p^2)\n\n[1] 3.75\n\n#from sample\nvar(geom.sim)\n\n[1] 3.83542"
  },
  {
    "objectID": "R01_RandomVariables.html#poisson",
    "href": "R01_RandomVariables.html#poisson",
    "title": "4  Random Variables R Examples",
    "section": "4.4 Poisson",
    "text": "4.4 Poisson\nLike the number of times something occurs during a fixed time window\n\n#Parameters\nl &lt;- 10.5 #The rate parameter, average occurrences per unit time\n     #It is lambda, but I'll call it \"l\"\n\n#Generate 10 random values\nrpois(10, lambda=l)\n\n [1]  9 15  8 18  9 12 14 12  8 15\n\n\nPMF and CDF\n\npar(mfrow=c(1,2))\nk &lt;- 0:20\nPr &lt;- dpois(k,l)\n\nbarplot(Pr, names=k, main=\"PMF of Pois(3)\")\nplot(k, ppois(k, l), type=\"s\", main=\"CDF of Pois(3)\", ylim=c(0,1))\npoints(k, ppois(k, l), pch = 16, col = \"blue\")\n\n\n\n\nThe expected value and variance are both is \\(\\lambda\\)\n\npois.sim &lt;- rpois(10000, lambda=l)\n\n# Expectation & Variance\nl\n\n[1] 10.5\n\n# mean from sample\nmean(pois.sim)\n\n[1] 10.5085\n\n#variance from sample\nvar(pois.sim)\n\n[1] 10.52458"
  },
  {
    "objectID": "R01_RandomVariables.html#uniform-discrete",
    "href": "R01_RandomVariables.html#uniform-discrete",
    "title": "4  Random Variables R Examples",
    "section": "4.5 Uniform (Discrete)",
    "text": "4.5 Uniform (Discrete)\nLike rolling a fair die\n\n#Parameters\na &lt;- 1 #lower bound, inclusive\nb &lt;- 6 #upper bound, inclusive\n\n#Generate 10 random values\nsample(a:b, 10, replace=TRUE) #replace=TRUE is important\n\n [1] 6 5 3 5 2 4 6 6 2 1\n\n\nThe PMF and CDF\n\npar(mfrow=c(1,2))\nk &lt;- a:b\nPr &lt;- rep(1/(b-a+1), length(k))\n\nbarplot(Pr, names=k, main=\"PMF of Unif(1,6)\")\nplot(k, cumsum(Pr), type=\"s\", main=\"CDF of Unif(1,6)\", ylim=c(0,1))\npoints(k, cumsum(Pr), pch = 16, col = \"blue\")"
  },
  {
    "objectID": "R01_RandomVariables.html#continuous-uniform",
    "href": "R01_RandomVariables.html#continuous-uniform",
    "title": "4  Random Variables R Examples",
    "section": "4.6 Continuous Uniform",
    "text": "4.6 Continuous Uniform\nThe backbone of random variable generation - for example a random decimal between 0 and 1\n\n# Parameters\na &lt;- 0 #lower bound\nb &lt;- 1 #upper bound\n\n#generate 10 random values\nrunif(10, min=a, max=b)\n\n [1] 0.3491863 0.7421214 0.1316501 0.5038041 0.2094663 0.9037216 0.2234822\n [8] 0.3452239 0.4463721 0.8647587\n\n\nProbability density function and cumulative distribution function\n\npar(mfrow=c(1,2))\nx &lt;- seq(a,b, length.out=100)\n\nplot(x, dunif(x, a, b), type=\"l\", main=\"PDF of Unif(0,1)\", ylab=\"density\", ylim=c(0,1))\nplot(x, punif(x, a, b), type=\"l\", main=\"CDF of Unif(0,1)\", ylab=\"F(x)\")\n\n\n\n\nThe expected value is \\(\\frac{a+b}{2}\\) and the variance is \\(\\frac{(b-a)^2}{12}\\)\n\nunif.sim &lt;- runif(10000, min=a, max=b)\n\n# Expectation\n(a+b)/2\n\n[1] 0.5\n\n# mean from sample\nmean(unif.sim)\n\n[1] 0.4970099\n\n#variance\n(b-a)^2/12\n\n[1] 0.08333333\n\n#variance from sample\nvar(unif.sim)\n\n[1] 0.08397942"
  },
  {
    "objectID": "R01_RandomVariables.html#normal-gaussian",
    "href": "R01_RandomVariables.html#normal-gaussian",
    "title": "4  Random Variables R Examples",
    "section": "4.7 Normal / Gaussian",
    "text": "4.7 Normal / Gaussian\nMany things in the world are normally distributed - useful for modeling when the distribution is symmetric and probability is densest in the middle with decreasing tails.\n\n#Parameters\nmu &lt;- 5 #the mean/location of the distribution\nsigma2 &lt;- 4 #the variance is in squared units!!\nsigma &lt;- sqrt(sigma2) #sigma is the standard deviation, not the variance\n\n#generate 10 random values\nrnorm(10, mean=mu, sd=sigma)\n\n [1] 7.025694 3.265699 6.840293 6.140499 5.576147 7.260201 6.228823 5.524191\n [9] 4.620259 3.816703\n\n\nProbability density function and cumulative distribution function\n\npar(mfrow=c(1,2))\nx &lt;- seq(mu-3*sigma, mu+3*sigma, length.out=100)\n\nplot(x, dnorm(x, mu, sigma), type=\"l\", main=\"PDF of Normal(5, 2^2)\", ylab=\"density\")\nplot(x, pnorm(x, mu, sigma), type=\"l\", main=\"CDF of Normal(5, 2^2)\", ylab=\"F(x)\")\n\n\n\n\nApproximate the expected value numerically\n\\[\\int_{-\\infty}^\\infty t f(t) dt\\]\n\nmu &lt;- 15\nsigma &lt;- 4\nt &lt;- seq(mu-4*sigma, mu+4*sigma, length.out=1000)\nd &lt;- dnorm(t, mean=mu, sd=sigma)\n\nw &lt;- t[2]-t[1]\n\nhead(t)\n\n[1] -1.0000000 -0.9679680 -0.9359359 -0.9039039 -0.8718719 -0.8398398\n\nhead(d)\n\n[1] 3.345756e-05 3.454551e-05 3.566656e-05 3.682162e-05 3.801165e-05\n[6] 3.923763e-05\n\n#Expected value\nsum( t * (d*w))\n\n[1] 14.99907\n\n\nThe expected value is \\(\\mu\\) and the variance is \\(\\sigma^2\\)\n\nnormal.sim &lt;- rnorm(10000, mean=mu, sd=sigma)\n\n# Expectation\nmu\n\n[1] 15\n\n# mean from sample\nmean(normal.sim)\n\n[1] 15.01193\n\n#variance\nsigma2\n\n[1] 4\n\n#variance from sample\nvar(normal.sim)\n\n[1] 16.19469\n\n\n\n4.7.1 Simulate a Normal probability\n\nnormal.sim &lt;- rnorm(1000000)\n\nx &lt;- .25 &lt;= normal.sim & normal.sim &lt;=.75\n\nsum(x)/1000000\n\n[1] 0.175348\n\npnorm(.75)-pnorm(.25)\n\n[1] 0.1746663\n\n\nLet’s consider a geometric that counts the number of days before a electronic component malfunctions Suppose that every day there’s a 25% chance of malfunction.\n\np=.25\nrandom.geom &lt;- rgeom(10000, prob=p)\nhist(random.geom, breaks=25)\n\n\n\n\nWhat if more than one malfunction could happen per day? Like we replace the part immediately when it malfunctions. We could divide the day into \\(N\\) parts and use a geometric for each part of the day. If \\(X\\)=k, then the proportion of the day it took to break is \\(k/N\\) Let’s start with \\(N\\)=2 and go up from there\n\npar (mfrow=c(2,2))\nN &lt;- 2\ngeom.sim &lt;- rgeom(10000, p/N) / N\nhist(geom.sim, breaks=100)\nmean(geom.sim)\n\n[1] 3.5305\n\nN &lt;- 6\ngeom.sim &lt;- rgeom(10000, p/N) / N\nhist(geom.sim, breaks=100)\nmean(geom.sim)\n\n[1] 3.775683\n\nN &lt;- 24\ngeom.sim &lt;- rgeom(10000, p/N) / N\nhist(geom.sim, breaks=100)\nmean(geom.sim)\n\n[1] 3.9357\n\nN &lt;- 100\ngeom.sim &lt;- rgeom(10000, p/N) / N\nhist(geom.sim, breaks=100)\n\n\n\nmean(geom.sim)\n\n[1] 4.048527"
  },
  {
    "objectID": "R01_RandomVariables.html#simulate-a-normal-probability",
    "href": "R01_RandomVariables.html#simulate-a-normal-probability",
    "title": "4  Random Variables R Examples",
    "section": "4.8 Simulate a Normal probability",
    "text": "4.8 Simulate a Normal probability\n\nnormal.sim &lt;- rnorm(1000000)\n\nx &lt;- .25 &lt;= normal.sim & normal.sim &lt;=.75\n\nsum(x)/1000000\n\n[1] 0.17541\n\npnorm(.75)-pnorm(.25)\n\n[1] 0.1746663\n\n\nLet’s consider a geometric that counts the number of days before a electronic component malfunctions Suppose that every day there’s a 25% chance of malfunction.\n\np=.25\nrandom.geom &lt;- rgeom(10000, prob=p)\nhist(random.geom, breaks=25)\n\n\n\n\nWhat if more than one malfunction could happen per day? Like we replace the part immediately when it malfunctions. We could divide the day into \\(N\\) parts and use a geometric for each part of the day. If \\(X\\)=k, then the proportion of the day it took to break is \\(k/N\\) Let’s start with \\(N\\)=2 and go up from there\n\npar (mfrow=c(2,2))\nN &lt;- 2\ngeom.sim &lt;- rgeom(10000, p/N) / N\nhist(geom.sim, breaks=100)\nmean(geom.sim)\n\n[1] 3.5163\n\nN &lt;- 6\ngeom.sim &lt;- rgeom(10000, p/N) / N\nhist(geom.sim, breaks=100)\nmean(geom.sim)\n\n[1] 3.840067\n\nN &lt;- 24\ngeom.sim &lt;- rgeom(10000, p/N) / N\nhist(geom.sim, breaks=100)\nmean(geom.sim)\n\n[1] 3.928362\n\nN &lt;- 100\ngeom.sim &lt;- rgeom(10000, p/N) / N\nhist(geom.sim, breaks=100)\n\n\n\nmean(geom.sim)\n\n[1] 4.014897"
  },
  {
    "objectID": "R01_RandomVariables.html#exponential",
    "href": "R01_RandomVariables.html#exponential",
    "title": "4  Random Variables R Examples",
    "section": "4.8 Exponential",
    "text": "4.8 Exponential\nFor modeling waiting times - the length of time until an event occurs. It’s a continuous version of a geometric, if you start looking at smaller and smaller time units (e.g. days -&gt; hours -&gt; minutes -&gt; seconds)\n\n#Parameters\nl &lt;- 3 #The rate parameter, the average number of occurrences per unit time\n\n#Generate 10 random values\nrexp(10, rate=l)\n\n [1] 0.14532250 0.34245138 0.83001118 0.05330771 0.16092295 0.09114442\n [7] 0.12318770 0.17958063 0.19486000 0.23542797\n\n\nProbability density function and cumulative distribution function\n\npar(mfrow=c(1,2))\nx &lt;- seq(0, 6/l, length.out=100)\n\nplot(x, dexp(x, l), type=\"l\", main=\"PDF of Exp(3)\", ylab=\"density\")\nplot(x, pexp(x, l), type=\"l\", main=\"CDF of Exp(3)\", ylab=\"F(x)\")\n\n\n\n\nThe expected value is \\(\\dfrac{1}{\\lambda}\\) and the variance is \\(\\frac{1}{\\lambda^2}\\)\n\nexp.sim &lt;- rexp(10000, l)\n\n# Expectation\n1/l\n\n[1] 0.3333333\n\n# mean from sample\nmean(exp.sim)\n\n[1] 0.3294719\n\n#variance\n1/l^2\n\n[1] 0.1111111\n\n#variance from sample\nvar(exp.sim)\n\n[1] 0.1065475\n\n\n\n4.8.1 Relationship between an exponential and a Poisson\nlambda = 10\n\nsimulated.exp &lt;- rexp(10000, rate=10)\nhist(simulated.exp)\n\n\n\nhead(simulated.exp)\n\n[1] 0.12408529 0.09626517 0.34601610 0.15449199 0.27343656 0.01666181\n\nconverted.poisson &lt;- as.vector(table(floor(cumsum(simulated.exp))))\npar(mfrow=c(1,2))\n    hist(converted.poisson)\n    hist(rpois(500, lambda=10))"
  },
  {
    "objectID": "R01_RandomVariables.html#relationship-between-an-exponential-and-a-poisson",
    "href": "R01_RandomVariables.html#relationship-between-an-exponential-and-a-poisson",
    "title": "4  Random Variables R Examples",
    "section": "4.10 Relationship between an exponential and a Poisson",
    "text": "4.10 Relationship between an exponential and a Poisson\nlambda = 10\n\nsimulated.exp &lt;- rexp(10000, rate=10)\nhist(simulated.exp)\n\n\n\nhead(simulated.exp)\n\n[1] 0.11366027 0.05467349 0.05377255 0.06814024 0.09737352 0.06935747\n\nconverted.poisson &lt;- as.vector(table(floor(cumsum(simulated.exp))))\npar(mfrow=c(1,2))\n    hist(converted.poisson)\n    hist(rpois(500, lambda=10))"
  },
  {
    "objectID": "R01_RandomVariables.html#simulate-stock-prices",
    "href": "R01_RandomVariables.html#simulate-stock-prices",
    "title": "4  Random Variables R Examples",
    "section": "4.9 Simulate stock prices",
    "text": "4.9 Simulate stock prices\nHere’s an example of how you could combine normally distributed random variables for a model of daily stock prices. This is an example of a random walk.\n\ndeltas &lt;- rnorm(30)\nX &lt;- 50 + c(0,cumsum(deltas))\n\nplot(x=1:31, y=X, type=\"l\")"
  },
  {
    "objectID": "R02_IndepCondBayes.html#example",
    "href": "R02_IndepCondBayes.html#example",
    "title": "7  Independence, Conditional Probability and Bayes Theorem R Examples",
    "section": "7.1 Example",
    "text": "7.1 Example\nTwo random variables that are Not independent, but have a 0 covariance\n\nX = seq(-1,1,.001)\nY = X^2\nplot(X,Y)\nabline(h=mean(Y))\nabline(v=mean(X))\n\n\n\ncov(X,Y)\n\n[1] 1.39546e-17\n\ncor(X,Y)\n\n[1] 8.090705e-17\n\n\n\n#A estimate of the pdf of Y\nplot(density(Y), xlim=c(0,1))\n\n\n\nhist(Y)"
  },
  {
    "objectID": "R02_IndepCondBayes.html#two-normally-distributed-random-variables",
    "href": "R02_IndepCondBayes.html#two-normally-distributed-random-variables",
    "title": "7  Independence, Conditional Probability and Bayes Theorem R Examples",
    "section": "7.2 Two normally distributed random variables",
    "text": "7.2 Two normally distributed random variables\n\n# X1 ~ Normal(1,1^2)\nx1 &lt;- rnorm(10000, mean=1, sd=1)\n\n#X2 ~ Normal(2, 2^2)\nx2 &lt;- rnorm(10000, mean=2, sd=2)\n\npar(mfrow=c(1,2))\nhist(x1)\nhist(x2)\n\n\n\n\nLet’s check the variances individually\n\nvar(x1)\n\n[1] 1.021324\n\nvar(x2)\n\n[1] 3.978341\n\n\nIn theory, Var(X1+X2) = Var(X1) + Var(X2) We check with sample variance\n\nvar(x1+x2)\n\n[1] 5.04692\n\nvar(x1)+var(x2)\n\n[1] 4.999665\n\nvar(x1)+var(x2)+2*cov(x1,x2)\n\n[1] 5.04692\n\n\nLook at the plot of these two variables\n\nmean(x1+x2)\n\n[1] 3.015705\n\nmean(x1)+mean(x2)\n\n[1] 3.015705\n\nplot(x1,x2)\n\n\n\nhist(x1+x2, breaks=50)"
  },
  {
    "objectID": "R02_IndepCondBayes.html#uniform-uniform",
    "href": "R02_IndepCondBayes.html#uniform-uniform",
    "title": "7  Independence, Conditional Probability and Bayes Theorem R Examples",
    "section": "7.3 Uniform + uniform",
    "text": "7.3 Uniform + uniform\n\nX &lt;- runif(100000, 0, 1)\nhist(X)\n\n\n\nY &lt;- runif(100000, 0, 1)\nhist(Y)\n\n\n\nhist(X+Y)\n\n\n\nZ &lt;- runif(100000, 0, 1)\nhist(X+Y+Z, breaks=100)"
  },
  {
    "objectID": "R02_IndepCondBayes.html#conditional-probability",
    "href": "R02_IndepCondBayes.html#conditional-probability",
    "title": "7  Independence, Conditional Probability and Bayes Theorem R Examples",
    "section": "7.4 Conditional Probability",
    "text": "7.4 Conditional Probability\nExample: X: roll a 6 sided die Y: flip a coin x times, count the number of heads\nWe could ask the question: What is the covariance ?!?!?\nSuppose we were to simulate doing this thing many many times. Each outcome from the simulation is representing one equally likely outcome, right?\nThis is the idea of Monte Carlo sampling - which we’ll look at next week\n\nX &lt;- sample(6, size=10000, replace=TRUE)\nY &lt;- rbinom(10000, size=X, prob=.5)\ncor(X,Y)\n\n[1] 0.6769082\n\nplot(jitter(Y)~jitter(X), col=rgb(0,0,0,.01), pch=16)"
  },
  {
    "objectID": "R02_IndepCondBayes.html#disease-screening",
    "href": "R02_IndepCondBayes.html#disease-screening",
    "title": "7  Independence, Conditional Probability and Bayes Theorem R Examples",
    "section": "7.5 Disease Screening",
    "text": "7.5 Disease Screening\nSay that the flu is currently infecting 3% of the population (prevelance). A person can take a flu test that has a sensitivity of 99% (i.e. if they have the virus, there is a 99% chance the test will give a positive result) and a specificity of 95% (i.e. if they don’t have the virus, there’s a 95% chance the test gives them a negative result).\nThe sensitivity is also known as the True positive rate (TPR). The complement of specificity is the False Positive Rate (FPR), and in this case it is 1-.95=.05 or 5%.\nSo a person takes the test and gets a positive test result, what is the probability that they actually have the flu?\n\np.flu &lt;- .03; p.noflu &lt;- 1-p.flu\np.pos.given.flu &lt;- .99; p.neg.given.flu &lt;- 1-p.pos.given.flu\np.neg.given.noflu &lt;- .95; p.pos.given.noflu &lt;- 1-p.neg.given.noflu\n\n# P(flu | pos) = P(flu)*P(pos|flu)/ [P(flu)*P(pos|flu) + P(noflu)*P(pos|noflu) ]\np.flu*p.pos.given.flu / (p.flu*p.pos.given.flu + p.noflu*p.pos.given.noflu)\n\n[1] 0.3797954\n\n\nSurprising? Well, if we didn’t do the test we’d guess a 5% chance of flu. Now that the test results are in that estimation increases by more than 7x to about 38%. Why isn’t it higher? There is a high chance of false positives muddying the waters."
  },
  {
    "objectID": "mc.html#learning-objectives",
    "href": "mc.html#learning-objectives",
    "title": "8  Monte Carlo",
    "section": "8.1 Learning objectives",
    "text": "8.1 Learning objectives\nAfter this lesson, you will be able to\n\nExplain the basic idea behind Monte Carlo methods\nImplement simple Monte Carlo methods in R to estimate probabilities of random events\nImplement simple Monte Carlo methods in R to estimate expectations \\(\\mathbb{E} g(X)\\) for random variables \\(X\\) distributed according to “nice” distributions (i.e., distributions supported by R)\nExplain and implement the “inverse trick” to generate random variables from an arbitrary cumulative distribution function \\(F\\)."
  },
  {
    "objectID": "mc.html#origin-of-monte-carlo-and-a-nice-example",
    "href": "mc.html#origin-of-monte-carlo-and-a-nice-example",
    "title": "8  Monte Carlo",
    "section": "8.2 Origin of Monte Carlo (and a nice example!)",
    "text": "8.2 Origin of Monte Carlo (and a nice example!)\nStanisław Ulam was a famous nuclear physicist (fun fact: after fleeing Europe during WWII, Ulam was a professor at UW-Madison before he was recruited to work on the Manhattan project at Los Alamos).\nSupposedly, while recovering from a surgery, Ulam was playing a lot of solitaire and came to wonder what was the probability \\(p\\) that a randomly-dealt game of solitaire could be played out.\nHe quickly found that calculating this probability precisely (e.g., by doing a bunch of the algebra and combinatorics that you may remember less than fondly from a probability course) was not very easy. The idea occurred to him that even if the probability \\(p\\) could not be calculated directly, it could be estimated by dealing lots of games of solitaire and counting how many of them he won.\nThus, Monte Carlo methods were born.\nThe name “Monte Carlo” is a reference to the Monte Carlo casino, later a frequent setting of James Bond movies. The idea is that like at a casino, Monte Carlo methods involve lots of randomness."
  },
  {
    "objectID": "mc.html#basics-of-monte-carlo",
    "href": "mc.html#basics-of-monte-carlo",
    "title": "8  Monte Carlo",
    "section": "8.3 Basics of Monte Carlo",
    "text": "8.3 Basics of Monte Carlo\nThe basic idea behind Monte Carlo methods, then, is the following: suppose that we have an event \\(E = \\{ X \\in S \\}\\) where \\(S \\subset \\Omega\\) is some set of outcomes and \\(X\\) is a random variable with outcome set \\(\\Omega\\). Suppose that we want to know the probability of event \\(E\\), \\(\\Pr[E]\\).\nOf course, one option would be to draw on the ideas we saw last week. We could do an integral or sum (depending on whether \\(X\\) is continuous or discrete) and just calculate what this probability is.\nUnfortunately, often this integral or sum is very hard to do, either because the integral/sum is very hard to solve (either exactly or numerically). When this happens, we need to take a different approach.\nThat is where Monte Carlo comes in. We give up on doing an integral or sum, and instead just use the fact that we can generate lots of random variables.\nTo (approximately) compute \\(\\Pr[ E ]\\), we\n\ngenerate lots of replicates of \\(X\\), say \\(X_1,X_2,\\dots,X_M\\) for some number \\(M\\) of Monte Carlo replicates.\nCount how many of these replicates correspond to event \\(E\\) occurring. That is, how many \\(i\\) are there such that \\(X_i \\in S\\).\nEstimate \\(\\Pr[ E]\\) as \\(M^{-1} \\sum_{i=1}^M 1_{\\{X_i \\in S\\}}\\).\n\nNote: this \\(1_{ \\{ \\cdots \\} }\\) notation is called an indicator function. For an event \\(E\\), \\[\n1_{E} = \\begin{cases}\n  1 &\\mbox{ if } E~\\text{ occurs } \\\\\n  0 &\\mbox{ otherwise. }\n  \\end{cases}\n\\]\nSo, in other words, to estimate \\(\\Pr[ E ]\\), Monte Carlo says that we just run our experiment of interest a bunch of times and count what proportion of the time the event \\(E\\) happens.\n\n8.3.1 Example: events under the normal\nLet’s start by considering a calculation similar to one that we already did in a previous lecture. Let \\(X\\) be a normal random variable with mean \\(1\\) and variance \\(3\\). What is the probability that \\(0 \\le X \\le 3\\)?\nWell, we already know how to compute this. It’s given by the integral \\[\n\\Pr[ 0 \\le X \\le 3]\n=\n\\int_0^3 \\frac{1}{\\sqrt{2\\pi * 3}} \\exp\\left\\{ \\frac{ -(t-1)^2 }{ 2* 3}  \\right\\} d t\n\\]\nwhere we have taken the normal density and plugged in \\(\\mu = 1, \\sigma^2=3\\).\nNote that this integral actually doesn’t have a closed form– your calculus classes might have tricked you into thinking that most integrals are “nice”. Still, we can use pnorm to compute it numerically (i.e., approximately), and we find that this probability is\n\npnorm(3, mean=1, sd=sqrt(3)) - pnorm(0, mean=1, sd=sqrt(3))\n\n[1] 0.594042\n\n\nNote that we have specified the standard deviation to be \\(\\sqrt{3}\\)– the variance is \\(\\sigma^2 = 3\\), so standard deviation is \\(\\sigma = \\sqrt{3}\\).\nLet’s suppose, however, that we didn’t know this probability and that it wasn’t so easy to compute in R. Note that Monte Carlo is most useful when we don’t have things like pnorm at our disposal, so this is a setting where in real life we wouldn’t ever use Monte Carlo. We’re starting in this nice simple familiar setting as a warm-up.\nOur event of interest is \\(E = \\{ 0 \\le X \\le 3 \\}\\). Monte Carlo says that to estimate \\(\\Pr[ E ]\\), we repeat our experiment lots of times and count what fraction of the time the event \\(E\\) happens.\nSo we should generate lots of copies of \\(X \\sim \\mathcal{N}(\\mu=1,\\sigma^2=3)\\) and count how often \\(0 \\le X \\le 3\\). Let’s do just that.\n\n# Write a function that checks whether or not our event E happens\n# The argument x is the output of our experiment.\n# (i.e., a draw from the normal)\nevent_E_happened &lt;- function( x ) {\n  if( 0 &lt;= x & x &lt;= 3 ) {\n    return( TRUE ) # The event happened\n  } else {\n    return( FALSE ) # The event DIDN'T happen\n  }\n}\n\n# Now MC says that we should generate lots of copies of X...\nNMC &lt;- 1000; # 1000 seems like \"a lot\".\nresults &lt;- rep( 0, NMC ); # We're going to record outcomes here.\nfor( i in 1:NMC) {\n  # Generate a draw from the normal, and then...\n  X &lt;- rnorm( 1, mean=1, sd=sqrt(3) );\n  # ...record whether or not our event of interest happened.\n  results[i] &lt;- event_E_happened(X);\n}\n# Now, compute what fraction of our trials were \"successes\" (i.e., E happened)\nsum( results )/NMC\n\n[1] 0.602\n\n\nJust as a reminder, the true number, which we just happen to know in this case, is\n\npnorm( 3, mean=1, sd=sqrt(3) ) - pnorm( 0, mean=1, sd=sqrt(3) )\n\n[1] 0.594042\n\n\nNow, our estimate is random, so every time we recompile this document it will be a bit different, but the estimate should be between 0.56 and 0.63.\nWe can make the estimate still more accurate by increasing the number of MC replicates \\(M\\)– larger \\(M\\) will make the estimation error smaller, on average. We’ll be able to make that description more precise later.\n\n\n8.3.2 Example: the birthday problem\nHere’s a classic probability question: In a group of \\(n\\) people, what is the probability that two or more of them have the same birthday? For simplicity, we’ll assume that there are no leap days (i.e., the year has 365 days) and that all 365 days are equally likely birthdays. You’ll implement a solution to a more general version of this problem in your homework, but let’s get an intuition here.\nWe need to simulate assigning \\(n\\) people to birthdays. We will represent the days of the year by the numbers 1 through 365, so assigning a birthday just amounts to choosing one of these 365 numbers at random. Then we need to check whether or not there are any repeated birthdays.\n\ngen_birthdays &lt;- function( n ) {\n  # Generate n random birthdays.\n  \n  # Generating a random birthday just corresponds to choosing a random number\n  # between 1 and 365 inclusive.\n  \n  # Pick uniformly at random from {1,2,3,...,365}.\n  # We sample WITH replacement,\n  # because it is possible for a birthday to be repeated.\n  # See ?sample for details\n  return( sample( 365, size=n, replace=TRUE ) );\n}\n\n# One run of our experiment will consist of generating n birthdays,\n# and then checking whether or not the birthdays contain a repeat.\n# Return TRUE if more than one person shares a birthday,\n# FALSE otherwise.\nrun_bday_expt &lt;- function( n ) {\n  # Generate n birthdays\n  bdays &lt;- gen_birthdays( n );\n  \n  # Now, check if there is a repeat.\n  # There are lots of ways to do this in R.\n  # Let's use the table function, which takes a vector and returns a\n  # vector of counts.   # See ?table for details\n  \n  # The important thing for us is that:\n  # If every entry of bdays appears exactly once,\n  # then table(bdays) will just be a vector of ones.\n  # If one or more entries in the vector bdays is repeated,\n  # then table(bdays) will have one or more entries that are larger than 1.\n  \n  # So we can examine max( table(bdays) ).\n  # max( table(bdays)) &gt; 1 if and only if there is a repeated entry in bdays.\n  return( max(table(bdays)) &gt; 1 );\n}\n\nNow let’s pick a value for the number of people \\(n\\) and repeat our experiment a bunch of times, keeping track of how often it returns TRUE (i.e., there is a repeated birthday).\n\nn &lt;- 22;\nNMC &lt;- 1000;\nNTRUE &lt;- 0;\nfor( i in 1:NMC) {\n  if( run_bday_expt(n) ) {\n    NTRUE &lt;- NTRUE + 1;\n  }\n}\npbday_estimated &lt;- NTRUE/NMC\npbday_estimated\n\n[1] 0.496\n\n\nOnce again, this is a situation where we can actually compute an answer exactly– we are using this to build intuition, not because it is a problem that strictly speaking requires Monte Carlo methods.\nThe probability that one or more birthdays is repeated is one minus the probability that all \\(n\\) birthdays are distinct. \\[\np_{\\text{repeated}} = 1 - p_{\\text{distinct}}.\n\\]\nThe probability that all \\(n\\) birthdays are distinct is\n\\[\np_{\\text{distinct}}\n= \\frac{365}{365}*\\frac{364}{365} * \\frac{ 363 }{ 365 } * \\cdots * \\frac{ 365-n+1}{365}\n= \\frac{ 365! }{ (365-n)! 365^n }.\n\\]\n\n\n8.3.3 Aside: wait, what?\nIf you’ve taken a probability class before, this computation will be simple and familiar. If you haven’t taken a probability class before, this warrants some unpacking.\nI’ll do that unpacking here in these notes, but we won’t go into detail about this in lecture, owing to time constraints.\nWe want to compute the probability that all \\(n\\) birthdays are distinct. Let’s label these people \\(1,2,3,\\dots,n\\), and consider generating their birthdays in order.\nThe way we usually compute probabilities in problems like this is to count how many different outcomes there are, and then look at how many of those outcomes match our event of interest. That is, we compute a probability as \\[\nN_{\\text{event is true}} / N_{\\text{outcomes}} ,\n\\]\nwhere \\(N_{\\text{outcomes}}\\) is the total number of possible outcomes and \\(N_{\\text{event is true}}\\) is the number of possible outcomes where our event of interest is true.\nIn this case, the outcomes are assignments of \\(n\\) people to 365 birthdays. Each of those \\(n\\) people can be assigned to one of 365 birthdays, so \\[\nN_{\\text{outcomes}} = 365^n.\n\\]\nNow, to compute the numerator in our probability, let’s count how many ways we can assign \\(n\\) people to \\(n\\) unique birthdays out of 365 available birthdays.\nThe first birthday is unique no matter what: for any of the 365 birthdays we pick, there are no other birthdays for it to “duplicate”.\nNow, let’s consider the 2nd birthday. The first person’s birthday is off limits, so that leaves 364 remaining birthdays to choose from, so there are \\(365*364\\) ways to choose distinct birthdays for the first two people.\nNow, consider the third person. If the first and second person have distinct birthdays, there are \\(365-2 = 363\\) birthdays left to choose from. There are \\(365*364\\) ways to pick distinct birthdays for the first two people, and so there are \\(365*364*363\\) ways to choose distinct birthdays for the first three people.\nContinuing this argument up to the \\(n\\)-th person, if the first \\(n-1\\) people all have distinct birthdays, then there are \\(365-(n-1) = 365 - n + 1\\) birthdays remaining for the \\(n\\)-th person to choose from that would maintain the distinct birthdays property. So there are \\(365*364*363*\\cdots*(365-n+1)\\) ways to choose distinct birthdays for all \\(n\\) people.\nOf course, this argument only makes sense if \\(1 \\le n \\le 365\\), an assumption we were making implicitly, but worth making explicit here.\nSo, plugging this back into our numerator, we have determined that the probability that our \\(n\\) people are assigned distinct birthdays is\n\\[\n\\frac{365*364*363*\\cdots*(365-n+1) }{ 365^n}\n=\n\\frac{ 365! }{ (365-n)! } \\frac{1}{365^n },\n\\]\nwhere we have used the fact that \\(m*(m-1)*\\cdots*(m-k+1) = m!/(m-k)!\\) for non-negative integers \\(k\\) and \\(m\\) with \\(k \\le m\\).\n\n\n8.3.4 End of aside. what’s the punchline?\nThus, the probability of a repeated birthday is\n\\[\np_{\\text{repeated}} = 1 - p_{\\text{distinct}}\n= \\frac{ (365-n)! 365^n - 365! }{ (365-n)! 365^n }.\n\\] Let’s implement that as a function and get the true values to verify our MC estimates.\n\np_repeated &lt;- function( n ) {\n  # Compute p_distinct, first, then subtract it from 1.\n  numer &lt;- prod( seq(365,365-n+1) );\n  denom &lt;- 365**n;\n  p_distinct &lt;- numer/denom;\n  return( 1 - p_distinct);\n}\n\np_repeated( 23 )\n\n[1] 0.5072972\n\n\n\np_repeated( 22 )\n\n[1] 0.4756953\n\n\nJust as a reminder, our estimate for p_repeated( 22 ) was\n\npbday_estimated\n\n[1] 0.496\n\n\nNot bad!\n\n\n8.3.5 Why does Monte Carlo work?\nOkay, before we start looking at more complicated or more interesting examples of Monte Carlo, we have to ask… why does this work, anyway? We’re estimating a number \\(\\Pr[E]\\) by just repeating an experiment a bunch of times and recording the fraction of the time that our event \\(E\\) happened…\nWell, in one sense, the fact that this gets us a good estimate of \\(\\Pr[E]\\) should be “obvious”. Our “definition” of a probability is as a long-run average– the probability of an event is the proportion of the time we would expect that event to happen if we repeated the experiment many times. So it comes as no surprise that when we run our experiment a bunch of times and average out how often our event happens, well… we get our probability!\nOkay, but that explanation feels a bit circular… To answer the question more carefully, we need to use just a bit of math. I promise it’s just a bit, and we’ll go through it step by step. We won’t even have to compute any integrals– just look at them!\nTo start with, let’s imagine that our variable of interest \\(X\\) is continuous with density function \\(f_X(t)\\). The same argument will apply for discrete RVs; just change integrals to sums. Then with \\(E = \\{ X \\in S \\}\\) for any set \\(S \\subseteq \\Omega\\), \\[\n\\Pr[ E ] = \\int_S f_X(t) dt = \\int_\\Omega 1_{t \\in S} ~f_X(t) dt\n\\]\nThe first equality there is just our definition of probability– to get the probability of an event, we integrate a density over the event set.\nThe second equality is just rewriting the integral. Instead of only integrating over \\(S\\), we integrate over the whole set \\(\\Omega\\) and add in an indicator \\(1_{t \\in S}\\). Remember, this function is \\(1\\) when \\(t \\in S\\) and \\(0\\) otherwise.\nBut now, let’s recall the definition of expectation. For a function \\(g(X)\\), \\[\n\\mathbb{E} g(X) = \\int_\\Omega g(t) f_X(t) dt\n\\]\nWe say that we have “integrated \\(g\\) against the density \\(f_X\\)”. Plugging in \\(g(t) = 1_{t \\in S}\\), \\[\n\\mathbb{E} 1_{X \\in S} = \\int_\\Omega 1_{t \\in S} ~f_X(t) dt.\n\\]\nBut we showed a few equations ago that this integral on the right-hand side is \\(\\Pr[ E ]\\).\nSo we have shown that \\(\\Pr[E] = \\mathbb{E} 1_{X \\in S}\\).\nOkay, we’re almost there. We have shown that the probability we want to estimate, \\(\\Pr[ E ]\\), is really just equal to an expectation, \\(\\mathbb{E} 1_{X \\in S}\\).\nNow, let’s think back to the law of large numbers. If we generate lots of independent copies of a random variable \\(X\\), say \\(X_1,X_2,\\dots,X_M\\), and look at the average \\(M^{-1} \\sum_{i=1}^M g(X_i)\\), then for large \\(M\\), this average is close to the expectation \\(\\mathbb{E} g(X)\\): \\[\n\\frac{1}{M} \\sum_{i=1}^M g(X_i) \\approx \\mathbb{E} g(X)\n\\] Let’s again take \\(g(t) = 1_{t \\in S}\\). Then \\[\n\\frac{1}{M} \\sum_{i=1}^M 1_{X_i \\in S} \\approx  \\mathbb{E} 1_{X \\in S} = \\Pr[ E ].\n\\]\nMonte Carlo works for estimating probabilities because probabilities are just expectations (that’s from the calculus we did above), and sample averages are close to their expectations (by the law of large numbers)!\n\n\n8.3.6 Example: Buffon’s needle\nLet’s look at a slightly more interesting example, based on a question first asked by Georges-Louis Leclerc, Comte de Buffon in the 1700s:\n\nSuppose we have a floor made of parallel strips of wood, each of width 1, and we drop a needle of length 1 onto the floor. What is the probability that the needle will lie across a line between two strips?\n\nNow, even beginning to answer this question requires that we specify what we have in mind when we say that we drop a needle onto the floor. That is, we need to specify our probabilistic/statistical model of the experiment of dropping a needle on the floor.\nPresumably we mean that the needle lands at a random point on the floor and that its orientation (i.e., angle that the needle makes with the cracks between the floor boards) is uniformly random.\nThese are the kinds of assumptions that we always want to be aware of when we build a model of the world, and these kinds of specifications can make a big difference in terms of the answers that we get. A nice example of this is Bertrand’s paradox, presented beautifully in this YouTube video by the always wonderful Numberphile and 3blue1brown.\nSo let’s specify what we mean, here.\nLet’s consider a 2-by-2 square with corners at \\((\\pm1,\\pm1)\\) and divide it into 2 halves: the top half is one strip of wood, and the bottom half is another strip of wood.\n\nrequire(ggplot2)\npp &lt;- ggplot() + geom_rect(aes(xmin=-1,xmax=1,ymin=0,ymax=1),\n                           fill=\"grey30\", color=NA);\npp &lt;- pp + geom_rect(aes(xmin=-1,xmax=1,ymin=-1,ymax=0),\n                     fill=\"grey80\",color=NA);\npp &lt;- pp + scale_x_continuous(expand=c(0,0)) + scale_y_continuous(expand=c(0,0))\npp\n\n\n\n\nTo model our randomly dropped pin, we first sample a point in this square uniformly at random. We will imagine that the pin is just a line, and this sampled point will be the location that the middle of the pin lands on. Then we randomly pick an angle uniformly over \\([0,\\pi)\\) and extend the ends of the needle each 0.5 units of length, for a needle of length \\(1\\). Finally, we check if the needle crosses any of the lines \\(y=0,\\pm1\\).\nLet’s write that function and plot a few random needles to make sure it’s doing what we want.\n\n# define needle dropping function\nneedle = function(){\n  \n  # Randomly pick the location of the center of the needle.\n  # We need an x and y coordinate, hence n=2 in runif\n  # This means that xy is a length-two vector,\n  # kind of like we wrote c( xcoord, ycoord ).\n  # This will come up below when we compute the endpoints of our\n  # needle, p1 and p2, below.\n  xy = runif(n=2, min=-1, max=1)\n  \n  # randomly pick an angle uniformly between 0 and pi.\n  angle = runif(n=1, min=0, max=pi)\n  \n  # calculate delta x and delta y, the distance of the ends of\n  # the needle from center in the horizontal and vertical directions.\n  # We are defining the angle using the standard definition\n  # (going counterclockwise from positive x axis).\n  # We will use these numbers to compute the coordinates of the needle's\n  # endpoints below, \n  dx = 0.5*cos(angle);\n  dy = 0.5*sin(angle);\n  \n  # Calculate coordinates of the needle's end points\n  # Our dy is always positive, so p1 is always higher than p2.\n  # This will be useful later for checking if our needle crosses a line\n  p1 = setNames(xy + c(dx,dy), c(\"p1x\",\"p1y\"))\n  p2 = setNames(xy - c(dx,dy), c(\"p2x\",\"p2y\"))\n  # Note: setNames is explained where we use it below\n  # in the function `crosses()` in the next code block.\n  \n  # return endpoints\n  return(c(p1,p2))\n}\n\n# plot a few needle drops\nlibrary(plyr)\n\nWarning: package 'plyr' was built under R version 4.2.3\n\nndl = function(i) needle()\n# needle() takes no arguments, but we want to call it 10 times,\n# so ldply needs a dummy variable,\n# which we've called (totally arbitrarily) i.\nneedles = ldply(1:10,ndl);\n\n# First plot out board again.\npp &lt;-ggplot() + geom_rect(aes(xmin=-1,xmax=1,ymin=0,ymax=1),\n                          fill=\"grey30\",color=NA);\npp &lt;- pp + geom_rect(aes(xmin=-1,xmax=1,ymin=-1,ymax=0),\n                     fill=\"grey80\",color=NA);\n# Now, add in the needles, in red.\npp &lt;- pp + geom_segment(data=needles,\n                        mapping=aes(x=p1x,y=p1y,xend=p2x,yend=p2y),\n                        color=\"red\",size=1.5);\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\npp\n\n\n\n\nNow, Monte Carlo says that we need to repeat this experiment many times (i.e., many more than 10 needles) and count how many of our dropped needles cross a line. So first and foremost we need a function to check if a needle crosses a line.\n\ncrosses &lt;- function( pts ) {\n  # Remember that needle() returns a pair of (x,y) points, p1,p2.\n  # We only need the y-coordinates to check if they cross a line.\n  p1y = pts['p1y'] # Note: this indexing trick is why we used setNames above\n  p2y = pts['p2y']\n  \n  # check if p1 and p2 are on opposite sides of a line\n  # We do this by simply checking if the y-coordinates are on different sides\n  # of one of the three lines y=-1, y=0 or y=1.\n  if( (p1y &gt; -1 & p2y &lt; -1) || (p1y &gt; 0 & p2y &lt; 0) || (p1y &gt; 1 & p2y &lt; 1) ){\n    return( TRUE );\n  } else {\n    return( FALSE );\n  }\n}\n\nGreat. So let’s generate lots of random needles, and use our new function crosses to check which ones cross a crack in the floorboards.\n\n# set size\nNMC = 1e5; # 10K MC replicates. Crank this number up for better accuracy.\n\n# create vector to count crossings\ncrossings = 0\n\n# run function\nfor(i in 1:NMC){\n  # drop a needle\n  points = needle()\n  # Check if it crosses and update counts accordingly.\n  if( crosses( points ) ) {\n    crossings &lt;- crossings + 1;\n  }\n}\n\nNow, our estimate of the probability of a crossing is just the fraction of our dropped needles (i.e., Monte Carlo replicates) that crossed.\n\ncrossings/NMC\n\n[1] 0.63686\n\n\nWe can compare with the correct answer and see how close we are. The actual probability, \\(2/\\pi\\) can be obtained using calculus (see the Wikipedia page for a derivation).\n\ntrue.cross = 2/pi\nMC.cross &lt;- crossings/NMC\ncat( sprintf(\" true value: %.5f \\n  our value: %.5f \\n Percent relative error: %.3f%%\",  true.cross, MC.cross, 100*abs(true.cross-MC.cross)/true.cross ) )\n\n true value: 0.63662 \n  our value: 0.63686 \n Percent relative error: 0.038%\n\n\nExercise: Write a function that takes 3 arguments: L for the length of the needle, T for the width of the floor boards, and M for the number of Monte Carlo replicates; performs the above Monte Carlo simulation; and returns the (estimated) probability of a crossing. Refer to the Wikipedia page on Buffon’s needle for the probability of crossing for a needle length \\(L\\) and board width \\(T\\)."
  },
  {
    "objectID": "mc.html#more-uses-for-monte-carlo-integration-by-darts",
    "href": "mc.html#more-uses-for-monte-carlo-integration-by-darts",
    "title": "8  Monte Carlo",
    "section": "8.4 More uses for Monte Carlo: integration by darts",
    "text": "8.4 More uses for Monte Carlo: integration by darts\nThe power of Monte Carlo methods goes way beyond estimating the probabilities of events. Monte Carlo refers to a much broader class of methods– using simulation to answer questions that would otherwise be hard or impossible to answer just using math (i.e., problems that do not have closed-form solutions).\nWe just saw above that we can use Monte Carlo to estimate probabilities of the form \\(\\Pr[ E ]\\) by approximating expectations of the form \\(\\mathbb{E} 1_E\\).\nWell, what is to stop us from replacing that indicator with a more interesting function \\(g(X)\\)? For example, suppose that \\(X\\) is normal with mean \\(\\mu\\) and variance \\(\\sigma^2\\) and we want to compute \\(\\mathbb{E} \\log |X|\\). We could set up and solve the integral \\[\n\\mathbb{E} \\log |X|\n= \\int_{-\\infty}^\\infty \\left( \\log |t| \\right) f( t; \\mu, \\sigma) dt\n= \\int_{-\\infty}^\\infty \\frac{ \\log |t| }{ \\sqrt{2\\pi \\sigma^2} }\n                  \\exp\\left\\{ \\frac{ -(t-\\mu)^2 }{ 2\\sigma^2 } \\right\\} dt.\n\\]\nAlternatively, we could just draw lots of Monte Carlo replicates \\(X_1,X_2,\\dots,X_M\\) from a normal with mean \\(\\mu\\) and variance \\(\\sigma^2\\), and look at the sample mean \\(M^{-1} \\sum_{i=1}^M \\log |X_i|\\), once again appealing to the law of large numbers to ensure that this sample mean is close to its expectation.\nExercise: Do that! Write code to obtain a Monte Carlo estimate of \\(\\mathbb{E} \\log |X|\\) for \\(X \\sim \\mathcal{N}(\\mu, \\sigma^2 )\\) (choose values for \\(\\mu\\) and \\(\\sigma^2\\) as you like).\nIndeed, this idea can be pushed still further. Suppose that we want to compute an integral \\[\n\\int_D g(x) dx,\n\\]\nwhere \\(D\\) is some domain of integration and \\(g\\) is a function. Let \\(f(x)\\) be the density of some random variable with \\(f(x) &gt; 0\\) for all \\(x \\in D\\) and \\(f(x) = 0\\) for \\(x \\not \\in D\\). In other words, \\(f\\) is the density of a random variable supported on \\(D\\). Then we can rewrite the integral as \\[\n\\int_D g(x) dx = \\int_D \\frac{ g(x) }{ f(x) } f(x) dx.\n\\]\nDefining \\(h(x) = g(x)/f(x)\\), what we have really shown is that \\[\n\\int_D g(x) dx = \\mathbb{E} h(X),\n\\]\nwhere \\(X\\) is a random variable with density \\(f\\).\nSo if we want to (approximately) compute \\(\\int_D g(x) dx\\), we can just generate lots of copies of \\(X\\) with density \\(f\\), and compute \\(M^{-1} \\sum_{i=1}^M h(X_i)\\). This is why you’ll sometimes see Monte Carlo methods referred to as “integration by darts”!\n\n\n8.4.1 Example: integrate \\((x+1)^{-3}\\) from 0 to \\(\\infty\\)\n\nlibrary(ggplot2)\nf = function(x) (x+1)^-3\nggplot() + geom_function(fun=f)\n\n\n\n\n\n\n\n\nWe know from calculus \\(\\int_0^\\infty (x+1)^{-3}\\text{dx}=\\left.-\\frac1{2(x+1)^2}\\right\\vert_0^\\infty=\\frac12\\).\nSuppose we want to find this approximately using an MC approach. Let \\(g(x)=(x+1)^{-3}\\). We need a random variable defined from 0 to \\(\\infty\\). Let’s choose \\(X=\\text{Exponential}(\\lambda=1)\\) with density \\(f(x)=e^{-x}\\).\nThen we can find \\(h(x)=g(x)/f(x)=(x+1)^{-3}\\,\\cdot\\,e^x\\). Now, we just need to find \\(E(h(X))\\), which we can do by drawing a sample \\(X_i\\) using rexp(...) and finding \\(\\frac1n\\sum_{i=1}^n h(X_i)\\).\n\nn = 1e6\n\n# draw a sampe of Xi\nx = rexp(n, rate = 1)\n\n# find the sample mean of h(Xi)\nmean((x+1)^-3 / exp(-x))\n\n[1] 0.4985974\n\n\nNote that we can pick any \\(X\\) that is only defined over \\([0,\\infty)\\), as long as we know its PDF \\(f(x)\\).\nSuppose instead we had picked \\(X\\) as \\(|Z|\\), i.e. as the absolute value of a standard normal. It’s easy to see by symmetry \\(f(x) = 2\\,\\cdot\\texttt{dnorm(x,mean=0,sd=1)}\\). We can then also compute it as this:\n\nn = 1e6\n\n# draw a sample of Xi\nx = abs(rnorm(n, mean=0, sd=1))\n\n# find the sample mean of h(Xi)\nmean((x+1)^-3 / (2*dnorm(x, mean=0, sd=1)))\n\n[1] 0.4964237\n\n\nAnd we again get approximately the right answer 0.5 as expected."
  },
  {
    "objectID": "mc.html#mc-estimator-example-compute-pi",
    "href": "mc.html#mc-estimator-example-compute-pi",
    "title": "8  Monte Carlo",
    "section": "8.5 MC estimator example: compute \\(\\pi\\)",
    "text": "8.5 MC estimator example: compute \\(\\pi\\)\nHere’s a fun example. Of course, we all know the value of \\(\\pi\\) (at least to a few decimal points). But let’s suppose we didn’t know \\(\\pi\\), for the sake of argument. We do know that \\(\\pi\\) is the ratio of the area of a circle to radius².\nHow can we use this fact, in conjunction with Monte Carlo methods, to estimate \\(\\pi\\)?\nWell, let’s have a look at the diagram below, which shows a square of side length 2, with an inscribed circle of radius 1 (hence area \\(\\pi\\)). Some random points have been chosen in the square, and colored according to whether or not they lie inside the circle.\n\n\n\nEstimating Pi\n\n\nSuppose that we pick a point uniformly at random in this two-by-two square. What is the probability that the point lies inside of the circle? Well, the circle has area \\(\\pi\\) and the square has area \\(4\\), so the probability is \\(p_{\\text{in}} = \\pi/4\\).\nThis means we can estimate \\(\\pi\\) as \\(4 * p_{\\text{in}}\\). So one way to estimate \\(\\pi\\) would be to estimate \\(p_{\\text{in}}\\) using Monte Carlo methods and then multiply by \\(4\\).\nWe can formalize this using the following setup:\nDrop \\(N\\) points uniformly and independently in the square. We know each point has probability \\(\\frac\\pi4\\) of being in the circle. Let \\(X_i\\) be \\(1\\) if the \\(i\\)-th point is in the circle and \\(0\\) if it is not. Note that \\(X_i\\sim\\text{Bernoulli}(p=\\frac\\pi4)\\)\nWe know then that \\(p_{\\text{in}}=E[X_i]\\approx\\bar X=\\frac1N\\sum_{i=1}^NX_i\\). Thus, our estimator can be represented as\n\\[\\hat\\pi:=4*p_\\text{in}\\approx4*\\frac1N\\sum_{i=1}^NX_i\\]\nLet’s try this.\n\nNMC &lt;- 1000; # Number of Monte Carlo replicates\nin_circ &lt;- 0; # Count how many points landed in the circle\n\n# For-loop over the MC replicates\nfor(i in 1:NMC){\n    # for each point, generate 2 coordinates (x,y) randomly between -1 and 1\n    point &lt;- runif(n=2, min=-1, max=1);\n    \n    # to be inside circle, our point must satisfy x^2 + y^2 &lt;= 1\n    if(point[1]^2 + point[2]^2 &lt;= 1){\n        # if inside, add to count\n        in_circ &lt;- in_circ+1\n    }\n}\n\n# To get proportion of square covered, take in_circ/N\nprop &lt;- in_circ/NMC\n# to get our estimate of pi, multiply by 4.\npi.mc &lt;- 4*prop\n\nNow, let’s assess how good our estimate is by computing its relative error, i.e., the size of the error compared to the size of the thing we are trying to estimate. Note that this is a number we can compute only because we are in a situation where we know the correct answer. Of course, in more realistic settings, we don’t know the true value of the quantity we are trying to approximate.\n\n# what are our estimate and percentage error?\n# See ?sprintf for more information on creating formatted strings in R.\ncat(sprintf(\"estimate: %.4f\\n %% error: %.2f%%\",pi.mc,100*abs(pi.mc-pi)/pi))\n\nestimate: 3.1240\n % error: 0.56%\n\n\nBonus: try changing NMC in the code above. How does the relative error change? What happens if you increase NMC up to 10000? What if you decrease NMC down to 100?\n\n8.5.1 Expectation and Variance of \\(\\hat\\pi\\)\nWe can easily derive the expectation and variance of this estimator: \\[\\begin{align}\nE(\\hat\\pi)&=E\\left(\\frac4N\\sum_{i=1}^NX_i\\right)\\\\\n&=\\frac4NE\\left(\\sum_{i=1}^NX_i\\right)\\\\\n&=\\frac4N\\sum_{i=1}^NE(X_i)\\\\\n&=\\frac4N\\sum_{i=1}^N\\left[(1)(\\tfrac\\pi4)+(0)(1-\\tfrac\\pi4)\\right]\\\\\n&=\\frac4N\\sum_{i=1}^N\\frac\\pi4\\\\\n&=\\frac4N\\left(N*\\frac\\pi4\\right)\\\\\n&=\\pi\n\\end{align}\\]\n\\[\\begin{align}\nVar(\\hat\\pi)&=Var\\left(\\frac4N\\sum_{i=1}^NX_i\\right)\\\\\n&=\\left(\\frac4N\\right)^2Var\\left(\\sum_{i=1}^NX_i\\right)\\\\\n&=\\frac{16}{N^2}\\sum_{i=1}^NVar(X_i)\\\\\n&=\\frac{16}{N^2}\\sum_{i=1}^N\\left[(1-\\tfrac\\pi4)^2(\\tfrac\\pi4)+(0-\\tfrac\\pi4)^2(1-\\tfrac\\pi4)\\right]\\\\\n&=\\frac{16}{N^2}\\sum_{i=1}^N\\frac\\pi4\\left(1-\\frac\\pi4\\right)\\\\\n&=\\frac{16}{N^2}\\left(N*\\frac\\pi4\\left(1-\\frac\\pi4\\right)\\right)\\\\\n&=\\frac{\\pi(4-\\pi)}N\n\\end{align}\\]\nbonus exercise: derive same equations for \\(E\\) and \\(Var\\) by treating \\(\\sum X_i\\) as a binomial variable and applying the binomial RV equations for \\(E\\) and \\(Var\\).\nWe can easily verify the truth of these formulae by simulating multiple “runs” of this experiment and looking at the distribution of estimates we obtain.\n\n# choose M (number of times to repeat MC experiment)\nM = 1000\n\n# create vector to save results in\nmc.est = rep(NA,M)\n\n# for each experiment, do all the steps done before, get an estimate, and save it\nfor(j in 1:M){\n    \n    # these lines are copied exactly from above\n    N = 1000\n    in.circ = 0\n    for(i in 1:N){\n        point = runif(n=2, min=-1, max=1)\n        if(point[1]^2 + point[2]^2 &lt; 1){\n            in.circ = in.circ+1\n        }\n    }\n    prop = in.circ/N\n    pi.mc = prop * 4\n    \n    # save result in vector\n    mc.est[j] = pi.mc\n}\n\n\n# what do the estimates look like? print the first 100 values\noptions(max.print=100)\nmc.est\n\n  [1] 3.156 3.112 3.216 3.228 3.228 3.212 3.224 3.084 3.088 3.140 3.136 3.264\n [13] 3.112 3.156 3.020 3.184 3.100 3.204 3.080 3.104 3.120 3.072 3.076 3.084\n [25] 3.160 3.168 3.088 3.116 3.276 3.148 3.092 3.140 3.228 3.168 3.112 3.136\n [37] 3.072 3.168 3.160 3.160 3.096 3.148 3.136 3.212 3.040 3.068 3.176 3.212\n [49] 3.096 3.144 3.124 3.196 3.164 3.188 3.120 3.088 3.116 3.168 3.152 3.028\n [61] 3.088 3.064 3.132 3.196 3.172 3.188 3.160 3.144 3.116 3.168 3.196 3.224\n [73] 3.136 3.220 3.124 3.096 3.160 3.136 3.192 3.224 3.220 3.176 3.104 3.152\n [85] 3.172 3.060 3.212 3.184 3.240 3.196 3.140 3.100 3.076 3.196 3.080 3.120\n [97] 3.164 3.192 3.148 3.060\n [ reached getOption(\"max.print\") -- omitted 900 entries ]\n\n\n\nmean(mc.est)\n\n[1] 3.14024\n\n\n\nvar(mc.est)\n\n[1] 0.002513464\n\n\n\nvar.theory = pi*(4-pi)/N\nvar.theory\n\n[1] 0.002696766\n\n\n\n# deviation of our mean and variance from theory:\ncat(sprintf(\"%% deviation from E  : %.3f%% \\n%% deviation from Var: %.3f%%\",\n            abs(mean(mc.est)-pi)/pi*100,abs(var(mc.est)-var.theory)/var.theory*100))\n\n% deviation from E  : 0.043% \n% deviation from Var: 6.797%"
  },
  {
    "objectID": "mc.html#important-notes",
    "href": "mc.html#important-notes",
    "title": "8  Monte Carlo",
    "section": "8.6 Important notes:",
    "text": "8.6 Important notes:\n\nthe estimator is unbiased, since \\(E(\\hat\\pi)-\\pi=0\\), which means there’s no systematic error\nthe estimator variance \\(\\propto1/N\\), so we can increase our precision by simulating more points\n\nnote the standard deviation \\(\\propto1/\\sqrt N\\), so if you want to lower error by factor of \\(\\frac12\\) you need to increase simulation size by factor of \\(4\\)\n\n\n\n\n\nBonus: (click to show) alternate setup: find \\(E[1_\\bigcirc(X,Y)]\\) for indep. uniform \\(X,Y\\)\n\n\nWe can also represent this in the following alternate setup.\nConsider a sample \\(X_i,Y_i\\) where all \\(X_i\\) and \\(Y_i\\) are i.i.d. drawn from \\(\\text{Uniform}(-1,1)\\). Then, \\((X_i,Y_i)\\) can represent picking the \\(i\\)_th point uniformly in the square. Then, define the indicator function \\(1_\\bigcirc(x,y)\\) which gives \\(1\\) if \\((x,y)\\) is in the circle and \\(0\\) otherwise, i.e.\n\\[1_\\bigcirc(x,y)=\\begin{cases}1 & x^2+y^2\\le1^2 \\\\ 0 & \\text{otherwise}\\end{cases}\\]\nNow, from calculus we know the area of a region \\(D\\) can be represented as the integral \\(\\iint_D\\text{dxdy}\\), thus we have\n\\[\\pi=\\text{circle area} = \\iint_\\bigcirc\\text{dxdy}=\\iint_\\square1_\\bigcirc(x,y)\\text{ dxdy}=\\iint_\\square\\frac{1_\\bigcirc(x,y)}{f(x,y)}\\cdot f(x,y)\\text{ dxdy}=E[h(X,Y)]\\]\nwhere \\(h(x,y)=\\frac{1_\\bigcirc(x,y)}{f(x,y)}\\), and \\(f(x,y)\\) is the “joint density” of \\(X,Y\\) over the square, which is basically the 2D version of a PDF for a coordinate \\((X,Y)\\). It’s easy to show for this example \\(f(x,y) = \\frac14\\). Then,\n\\[E[h(X,Y)]=E\\left[\\frac{1_\\bigcirc(X,Y)}{1/4}\\right]=4\\,\\cdot E[1_\\bigcirc(x,y)]\\approx4\\,\\cdot\\,\\frac1N\\sum_{i=1}^N1_\\bigcirc(X_i,Y_i)\\]"
  },
  {
    "objectID": "mc.html#generating-random-variables-and-the-importance-of-randomness",
    "href": "mc.html#generating-random-variables-and-the-importance-of-randomness",
    "title": "8  Monte Carlo",
    "section": "8.7 Generating random variables and the importance of randomness",
    "text": "8.7 Generating random variables and the importance of randomness\nCrucial to Monte Carlo methods is that we be able to generate random variables. For example, if we want to estimate \\(\\mathbb{E} g(X)\\) for some random variable \\(X\\), then we need to be able to generate copies of the random variable \\(X\\) (and we need to be able to compute \\(g( \\cdot )\\), of course…).\nR has built-in functions that we’ve seen already for generating from the normal, Poisson, geometric, etc., but how does R generate those random numbers? And suppose that we had a particular random variable that we want to generate and R doesn’t have a built-in function for it? What do we do then?\nWell, let’s take it as a given that we know how to generate uniform random variables. Suppose that someone gives us an arbitrary density or an arbitrary CDF. How can we draw samples from it?\nWell, here’s an interesting property. For any random variable \\(X\\) with CDF \\(F\\), \\(F(X)\\) is distributed as a uniform random variable on \\([0,1]\\).\nHave a look. The code below generates a bunch of random variables from each of four different distributions, and plots the resulting histograms in the top row of an array of plots. Then, in the second row, we have histograms of \\(F(X)\\). That is, we generate the random variables and pass them into their cumulative distribution function. In all four cases, the second row look an awful lot like uniform 0-1 random variables!\n\nN &lt;- 1e5;\noptions(repr.plot.width=16)\npar(mfrow=c(2,4))\n# Generate random variables.\nXnorm &lt;- rnorm(N);\nXchisq &lt;- rchisq(N,10);\nXexp &lt;- rexp(N,1);\nXbeta &lt;- rbeta(N,.5,.5);\n# Plot plain old histograms.\nhist(Xnorm); hist(Xchisq); hist(Xexp); hist(Xbeta);\n# Plot histograms of putting the variables into their own CDFs.\nhist(pnorm(Xnorm)); hist(pchisq(Xchisq,10));\nhist(pexp(Xexp,1)); hist(pbeta(Xbeta,.5,.5));\n\n\n\n\nWe can use this fact to generate observations from any arbitrary distribution!\nLet \\(X\\) be a random variable with CDF \\(F_X\\), and suppose that \\(F_X\\) is invertible so that we can sensibly write \\(F_X^{-1}(t)\\). In later probability courses you’ll see that this trick works even if the CDF doesn’t have an inverse like you’re used to, because we can define a special kind of inverse for CDFs, but that’s for another time.\nRemember that by definition, \\[\nF_X(t) = \\Pr[ X \\le t ].\n\\]\nIf \\(U\\) is uniform \\(0\\)-\\(1\\), \\(U \\sim \\operatorname{Unif}(0,1)\\), consider \\(Y = F_X^{-1}(U)\\). We claim that this number has the same distribution as \\(X\\) (i.e., it has CDF \\(F_X\\)). If you’re interested, the next subsection will give a proof of this fact. If you don’t care about seeing why this is true, you can skip it.\n\n8.7.1 \\(F_X(X)\\) is uniform 0-1.\nLet’s check this fact. Remember, \\(Y = F_X^{-1}(U)\\), where \\(U \\sim \\operatorname{Unif}(0,1)\\) and \\(F_X\\) is the CDF of a random variable \\(X\\), and has an inverse \\(F_X^{-1}\\).\nWe need to verify that the CDF of \\(Y\\) is equal to \\(F_X\\). That is, \\(Y\\) and \\(X\\) have the same distribution.\nSo let’s look at the CDF of \\(Y\\). By definition, \\[\nF_Y(t) = \\Pr[ Y \\le t] = \\Pr[ F_X^{-1}(U) \\le t ],\n\\]\nwhere the second equality is plugging in the definition of \\(Y = F_X^{-1}(U)\\). Now, \\(F_X^{-1}(U) \\le t\\) if and only if \\(U \\le F_X(t)\\) (applying \\(F_X\\) to both sides of the inequality), so \\[\n\\Pr[ F_X^{-1}(U) \\le t ]\n=\n\\Pr[ U \\le F_X(t) ].\n\\] That is, \\[\nF_Y(t)\n=\n\\Pr[ U \\le F_X(t) ].\n\\]\nThat right-hand side is just the CDF of a uniform, evaluated at \\(F_X(t)\\). But the CDF of a uniform is just \\(\\Pr[U \\le p] = p\\) for all \\(0 \\le p \\le 1\\). So we have shown that \\(F_Y(t) = F_X(t)\\), which is to say, \\(Y = F_X^{-1}(U)\\) has the same distribution as our original random variable \\(X\\).\nIn other words, randomly sampling from the uniform distribution and then applying the inverse of the given CDF function gives the desired target distribution!\n\n\n8.7.2 Okay, proof over.\nLet’s have another look at that by sampling from a normal. In the process, we’re going to see the last of R’s built-in functions for working with random variables: qnorm.\nqnorm takes a number p between zero and one and returns the corresponding quantile of the normal distribution. That is, the number \\(t\\) such that the probability that a normal \\(X\\) is less then or equal to \\(t\\) is equal to \\(p\\). That’s a clumsy thing to say in English– put more simply, the quantile is just the inverse CDF!\n\n# reset Rmarkdown print width for readability.\noptions(repr.plot.width=7)\n\n# generate a bunch of Unif(0,1) RVs.\nunifs &lt;- runif(1e5)\n\n# Apply the built-in inverse CDF function using qnorm\n# that is, this is computing F_X^{-1}(U).\nx.normal.mc = qnorm(unifs,mean=1,sd=1)\n\n# plot results\nhist(x.normal.mc)\n\n\n\n\nAnd let’s compare those with RVs generated directly from a normal in R.\n\nhist(rnorm(1e5,mean=1,sd=1))\n\n\n\n\nAnother way of looking at this is via a Q-Q plot (no relation to QQ Express on University Ave, sadly), which might be familiar to you from previous classes.\nIf you’ve never seen this before, that’s okay– a Q-Q plot (short for quantile-quantile plot) plots points \\((x,y)\\) where the \\(x\\) values are the ordered observations from one sample and the \\(y\\) values are the ordered observations of the other sample. Q-Q plots are a good way to compare two distributions of points. We’ll have more to say about them over the course of the semester and you’ll see them plenty more during your later courses.\nFor now, it’s enough to know that if two distributions are similar, then their Q-Q plot will look like a straight line.\n\n# plot our sample quantiles against theoretical quantiles for comparison\nplot(sort(x.normal.mc),qnorm(ppoints(1e5,1),mean=1,sd=1))\n\n\n\n\nThe straight line in the Q-Q plot indicates that our two samples are very similar– as they should be!"
  },
  {
    "objectID": "mc.html#example",
    "href": "mc.html#example",
    "title": "8  Monte Carlo",
    "section": "8.8 Example:",
    "text": "8.8 Example:\nDefine a random variable \\(X\\) with density \\[\nf_X(x) = \\begin{cases}\n      2x &\\mbox{ if } 0 \\le x \\le 1 \\\\\n      0 &\\mbox{ otherwise. }\n      \\end{cases}\n\\]\n\n# here we define a *vectorized* function to evaluate the density of X\npdf_x = function(x) {\n  # ifelse is like a function version of an if else control statement\n  # We use it here to ensure that pdf_x can operate directly on vectors\n  return(ifelse(0&lt;=x & x&lt;=1 , 2*x , 0 ))\n}\n\n# showing the PDF in a plot\nplot(pdf_x,from = -.5,to = 1.5,n=1001)\n\n\n\n\nThis means that the cumulative distribution function is \\[F_X(x)=\\int_0^xf_X(x)dx=\\int_0^x2xdx=x^2\\] for \\(0 \\le x \\le 1\\) (if \\(x&lt;0\\), \\(F_X(x)=0\\), and if \\(x&gt;1\\), \\(F_X(x)=1\\)). Here’s a plot of the CDF\n\ncdf_x = function(x) {\n  return(ifelse(0&lt;=x & x&lt;=1 , x^2 , ifelse(x&lt;0,0,1) ))\n}\n\n# showing the CDF in a plot\nplot(cdf_x,from = -.2,to = 1.2,n=1001)\n\n\n\n\nHow can we write a function rx(n) (like rbinom) to sample from this random variable, where n is the size of the sample to be drawn?\nFirst, we find the inverse CDF, which here is the opposite of \\(x^2\\), i.e. \\(\\sqrt x\\). Next, we simply need to apply this to a sample from from Uniform(0,1) and this should give us the desired result.\n\nrx = function(n) sqrt(runif(n))\n\nWe can check our work by drawing a sample and plotting it.\n\nhist(rx(1e5))\n\n\n\n\n\nplot(ecdf(rx(1e5)),main=\"Plot of sample CDF\")\n\n\n\n\n\n8.8.1 Okay, but do I actually need this inverse trick?\nOkay, full disclosure: lucky for us, it’s pretty rare that we actually need to use this inverse trick, especially in a course at this level. Almost any random variable you will ever need in your life has already been implemented in R (and most other programming languages, for that matter). Still, if you understand this trick, then you understand enough about CDFs and how they work to be dangerous. Also, it’s useful on exam questions…"
  },
  {
    "objectID": "mc.html#random-v.-pseudorandom",
    "href": "mc.html#random-v.-pseudorandom",
    "title": "8  Monte Carlo",
    "section": "8.9 Random v. pseudorandom",
    "text": "8.9 Random v. pseudorandom\nOne last parting remark, included here because it’s interesting and important to know about, not because it will be on any exams.\nFor Monte Carlo, it’s important to have a good source of random numbers whose distribution is precisely known. This is a surprisingly difficult problem. There are ways of generating (as far as modern science can tell), almost perfectly uniformly random numbers, such as measuring atmospheric noise, radioactive decay, or even lava lamps (used by Cloudflare). These sources are generally considered capable of producing the most truly random numbers.\nYour computer (unless it’s attached to a Geiger counter or a wall of lava lamps) is only capable of producing pseudorandom numbers. These are made by running a pseudorandom number generator algorithm which is deterministic, meaning it always produces the same output given the same input. For example, R produces pseudorandom numbers using the Mersenne-Twister algorithm. Even though these are deterministic, they are statistically random– for all practical computational purposes, there are no discernible patterns in the output.\nYou can see this in action in R by setting the seed of the random number generator:\n\nset.seed(340)\n\nrnorm(n=10)\n\n [1] -0.1573733 -1.1988575 -0.8892049  1.0090607  0.6130407  1.0071506\n [7]  0.4144321 -1.8579099 -1.3487292  0.5188585\n\n\nNow, if we kept generating normals, we’d continue to see a bunch of normal RVs. But if set the random number generator’s seed back to 340…\n\nset.seed(340)\n\nrnorm(n=10)\n\n [1] -0.1573733 -1.1988575 -0.8892049  1.0090607  0.6130407  1.0071506\n [7]  0.4144321 -1.8579099 -1.3487292  0.5188585\n\n\nYou’re not imagining it– those are the same ten “random” normals as we saw above.\nOnce the RNG seed is set, the “random” numbers that R generates for us aren’t random at all. But someone looking at these random numbers would have a very hard time distinguishing these numbers from truly random numbers. That is what “statistical randomness” means!\nNone of this is of tremendous importance for you in the short term. It’s just important to keep in mind that the “random” numbers that we generate on our computers aren’t truly random. There are situations where these patterns actually matter, most notably in security applications. Still, for our purposes, pseudorandom numbers are good enough, and way cheaper than truly random numbers from Geiger counters or atmospheric noise or lava lamps or…\nYou can spend a whole career studying random numbers and how to generate them. Unfortunately, this deeply interesting subject is mostly outside the scope of our course. If you’re interested in learning more, though, here are a couple of videos you might enjoy:\n\n\n\n\n\nThe comprehensive textbook on the topic of generating random variables is Non-Uniform Random Variate Generation by Luc Devroye. Unfortunately, it’s a bit advanced, unless you’ve taken a bunch of calculus already, but something to strive for!\n\n8.9.1 Review:\nIn these notes we covered:\n\nThe basic steps of a Monte Carlo simulation\nEstimating the expected value of a random variable using MC\nEstimating a probability using MC\nEstimating a definite integral using MC\nWhy \\(F_x(X)\\sim Uniform(0,1)\\) for any r.v. \\(X\\)\nSimulating an aribitrary random variable using MC\nPsuedorandom number generation & the use of set.seed() in R"
  },
  {
    "objectID": "R03_MonteCarloExamples.html#a-few-structures-for-monte-carlo",
    "href": "R03_MonteCarloExamples.html#a-few-structures-for-monte-carlo",
    "title": "9  Monte Carlo Examples",
    "section": "9.1 A few structures for Monte Carlo",
    "text": "9.1 A few structures for Monte Carlo\n\n9.1.1 For Loop\nConsider two random variables: \\(X\\sim N(5, 3^2)\\) is normally distributed with a mean of \\(\\mu=5\\) and a variance of \\(\\sigma^2=3^2\\). \\(Y\\sim exp(.2)\\), independent of X, is exponentially distributed with a rate parameter of \\(\\lambda=.2\\). The Questions is what is the \\(Pr[X &gt; Y]\\)?\nUse Monte Carlo to estimate this probability.\n\nset.seed(2)\nNMC &lt;- 100000 #Many Monte Carlo replicates\nresults &lt;- rep(FALSE, NMC) # a vector for storing results\nfor(i in 1:NMC){\n  X &lt;- rnorm(1,5,3)\n  Y &lt;- rexp(1, .2)\n  results[i] &lt;- (X &gt; Y) #TRUE or FALSE\n}\nmean(results)  ### the proportion of TRUES out of all replicates\n\n[1] 0.57455\n\n\n\n\n9.1.2 Generate Many RVs at once\nYou can also avoid the loop entirely by just generating many random variables at once\n\nset.seed(2)\nNMC &lt;- 100000 #Many Monte Carlo replicates\nX &lt;- rnorm(NMC,5,3)\nY &lt;- rexp(NMC, .2)\nmean(X &gt; Y)  ### the proportion of TRUES out of all replicates\n\n[1] 0.57829\n\n\n\n\n9.1.3 The replicate() function\nYou can also use the replicate function. It can avoid the need for a loop\n\nset.seed(2)\nNMC &lt;- 100000 #Many Monte Carlo replicates\nresults &lt;- replicate(NMC, rnorm(1,5,3)&gt;rexp(1,.2))\n#replicate( how many times, expression)\n#this creates a vector of replicates! So easy!\nmean(results)  ### the proportion of TRUES out of all replicates\n\n[1] 0.57455"
  },
  {
    "objectID": "R03_MonteCarloExamples.html#expected-value-estimation-using-monte-carlo",
    "href": "R03_MonteCarloExamples.html#expected-value-estimation-using-monte-carlo",
    "title": "9  Monte Carlo Examples",
    "section": "9.2 Expected Value Estimation using Monte Carlo",
    "text": "9.2 Expected Value Estimation using Monte Carlo\n\n9.2.1 Weak Law of Large Numbers Example\nDemonstration of how larger samples leads the sample mean to approach expected value\nLet’s consider the following random variable:\n\nx&lt;- 1:10\npx &lt;- runif(10)\npx &lt;- px / sum(px)\nbarplot(height=px, names=x)\n\n\n\n#Let's peek behind the curtain\n(EX &lt;- sum( x * px))\n\n[1] 4.923099\n\n(VarX &lt;- sum(x^2*px) - EX^2)\n\n[1] 7.508671\n\nsum((x-EX)^2*px)\n\n[1] 7.508671\n\n\nLet’s demonstrate how our estimate of EX gets better with M growing\n\nmyMeans &lt;- vector(\"numeric\")\nMs &lt;- seq(100, 10000, 100)\nfor(M in Ms){\n  mySample &lt;- sample(x, prob=px, size=M, replace=TRUE)\n  myMeans[M/100] &lt;- mean(mySample)\n}\nplot(x= Ms, y=myMeans)\nabline(h=EX, col=\"red\")\n\n\n\n\n\n\n9.2.2 Demonstration of the law of large numbers in Monte Carlo expected value estimation\nFor example, say you want to estimate the mean of an exponential distribution. In principal, we can simulate many values \\(X_1, X_2, \\ldots, X_M\\) from this distribution, average them and that’s going to be our estimate of the \\(EX\\)\n\nNMC &lt;- 10000\nrandomExp &lt;- rexp(NMC, .4)\nnumerator &lt;- cumsum(randomExp)\naverage &lt;- numerator / (1:NMC)\nplot(x=1:NMC, y=average, type=\"l\")\nabline(h=1/.4, col=\"red\")\n\n\n\n\n\n\n9.2.3 Estimate the expected value of some weird random variable\nGamma distribution takes 2 parameters - shape and scale\nSay X ~ Gamma(shape = 5, scale = 0.5)\nLet’s estimate it’s expected value using Monte carlo - with just 100 runs. We’ll do it 5 times to compare the estimates.\n\nset.seed(1)\n\nMCN &lt;- 100   #stands for Monte Carlo N\n\nfor(i in 1:5){\n  #generate a bunch of values from the random variable\n  myData &lt;- rgamma(MCN, shape=5, scale=.5)\n#  hist(myData)\n  \n  #Law of Large Numbers says that the sample average should be close to EX\n  print(mean(myData))\n  \n}\n\n[1] 2.46491\n[1] 2.381638\n[1] 2.44396\n[1] 2.536307\n[1] 2.514453\n\n\nWhat’s your guess as to the true expected value? Hint: the parameters are 5 and .5. Do you have a guess?\nLet’s generate 10 million random values and see what we get for the mean.\n\nMCN &lt;- 10000000   #stands for Monte Carlo N\n\n#generate a bunch of values from the random variable\nmyData &lt;- rgamma(MCN, shape=5, scale=.5)\n\n#Law of Large Numbers says that the sample average should be close to EX\nmean(myData)\n\n[1] 2.500108\n\n\nLet’s consider a random variable Y which is the square root of a exponential random variable X with rate parameter 3\n\\(E(X) = 1/3 = .333333\\)\nGuess what might be \\(E(Y)=E(\\sqrt{X})\\)? maybe \\(\\sqrt{1/3} = 0.5773503\\)?\nLet’s check using MC method.\n\nX &lt;- rexp(1000000, rate=3)\nY &lt;- sqrt(X)\nmean(Y)\n\n[1] 0.5116081\n\n\nNo ! it turns out that EY = .511 or so.\nIn general \\(E(g(X))\\) is not \\(g(E(X))\\)\n\n\n9.2.4 A time when Monte Carlo fails - when the expected value does not exist.\nThe Cauchy Distribution is a weird one. It has no defined expected value. It is actually just a T distribution with 1 degree of freedom! Same thing.\nHere’s a picture of its density function from -10 to 10.\n\nplot(x=seq(-10,10,.01), y=dcauchy(seq(-10,10,.01)), type=\"l\", main=\"density of Cauchy Distribution\", xlab=\"x\", ylab=\"density\")\n\n\n\n\nHere’s an example of a sample from the Cauchy:\n\nhist(rcauchy(1000))\n\n\n\n\nChances are you get at least one extreme extreme value. That’s the effect of having FAT tails.\nLet’s just look at what the long term average would be\n\nNMC &lt;- 10000\nrandomCauchy &lt;- rcauchy(NMC)\nnumerator &lt;- cumsum(randomCauchy)\naverage &lt;- numerator / (1:NMC)\nplot(x=1:NMC, y=average, type=\"l\")\nabline(h=0, col=\"red\")\n\n\n\n\nThe cumulative average approaches 0 until one extreme value is sampled and then it throws off the average. Then the average slowly approaches 0 again until another extreme value throws everything off. This is what happens when expected value is not defined - law of large numbers cannot take effect.\nBut when the t distribution has 2 degrees of freedome we see a very different pattern emerge:\n\nNMC &lt;- 10000\nrandomT2 &lt;- rt(NMC,2)\nnumerator &lt;- cumsum(randomT2)\naverage &lt;- numerator / (1:NMC)\nplot(x=1:NMC, y=average, type=\"l\")\nabline(h=0, col=\"red\")\n\n\n\n\nProblem is the variance is still undefined. The variance is infinity for \\(df \\leq 2\\). When the mean is defined and the variance is finite we start to see the Law of Large Numbers get involved\n\nNMC &lt;- 10000\nrandomT3 &lt;- rt(NMC,3)\nnumerator &lt;- cumsum(randomT3)\naverage &lt;- numerator / (1:NMC)\nplot(x=1:NMC, y=average, type=\"l\")\nabline(h=0, col=\"red\")\n\n\n\n\n\n\n9.2.5 Estimate the expected value of log(X) where X~Normal\n\nmu &lt;- 4\nsigma &lt;- 5\n\nNMC &lt;- 10000\n\nX &lt;- rnorm(NMC, mean=mu, sd=sigma)\n\n#Look a the histogram\nhist(X)\n\n\n\nY &lt;- log(abs(X))\n#histogram of log|X|\nhist(Y)\n\n\n\nmean(Y)\n\n[1] 1.272277\n\n\n\n\n9.2.6 St Petersburg Game\nThe game goes like this:\nI (the Casino) put one dollar in the pot I flip a coin. If it’s a tails, I double the pot If it is heads, you win the pot.\nIT costs money to play the game!!! First question: what is a fair price to play the game?\nA random variable without a defined expected value; Monte Carlo will fail us!\n\n#we can simulate M plays of the game with simply M geometric random values from geom(.5)\nM &lt;- 1000000\n\nt &lt;- rgeom(M, .5)  #t is number tails per game\nwinnings &lt;- 2^t\nmean(winnings)\n\n[1] 11.19202"
  },
  {
    "objectID": "R03_MonteCarloExamples.html#probability-calculation-by-monte-carlo",
    "href": "R03_MonteCarloExamples.html#probability-calculation-by-monte-carlo",
    "title": "9  Monte Carlo Examples",
    "section": "9.3 Probability Calculation by Monte Carlo",
    "text": "9.3 Probability Calculation by Monte Carlo\n\n9.3.1 A Normal Example\nSuppose we want to calculate a normal RV probability. Say X follows a normal distribution with mean 8 and standard deviation 2.\nWhat is the probability that X is between 8.4 and 9.9? And let’s also imagine we don’t know how to use pnorm.\n\nM &lt;- 1000000 #this is the number of Monte Carlo replicates to make\nX &lt;- rnorm(M, mean=8, sd=2)\nmean(X &gt; 8.4 & X &lt; 9.9)\n\n[1] 0.248712\n\n\n\npnorm(9.9, 8,2)- pnorm(8.4, 8,2)\n\n[1] 0.2496842\n\n\n\n\n9.3.2 The Birthday Problem.\nIf you have n people together, what is the probability that at least 2 of them share a birthday?\n\nsimulateBirthdays &lt;- function(n){\n  #birthdays will be numbers from 1 to 365\n  #we'll assume that each day of the year is equally likely (this is probably not true in real life)\n  return (sample(x = 1:365, size=n, replace=TRUE))\n}\n\ncheckSharedBirthdays &lt;- function(birthdays){\n  #We'll use the unique function\n  #given a vector X of values, unique(X) gives the unique values\n  return (length(unique(birthdays)) &lt; length(birthdays))\n}\n\nWe’ll do a Monte Carlo simulation to estimate the probability of a shared birthday when we have 19 people\n\nNMC &lt;- 10000\nresults &lt;- vector(\"logical\")\nfor(i in 1:NMC){\n  simBirthdays &lt;- simulateBirthdays(19)\n  results[i] &lt;- checkSharedBirthdays(simBirthdays)\n}\n#estimate the probability\nmean(results)\n\n[1] 0.376\n\n\nRepeat with other values of n\n\nNMC &lt;- 100000\nresults &lt;- vector(\"logical\")\nfor(i in 1:NMC){\n  simBirthdays &lt;- simulateBirthdays(23)\n  results[i] &lt;- checkSharedBirthdays(simBirthdays)\n}\n#estimate the probability\nmean(results)\n\n[1] 0.51082\n\n\n\n\n9.3.3 Buffon’s Needles\nWe want to modify the example from class to take 3 parameters: L: length of the needles W: the width of the floorbords M: the number of Monte Carlo replicates\nThis will simulate the Buffon Needle experiment with M needles of length L on a floor with line width W. The needle.crosses function returns a single needle’s result - did it cross a floor line (TRUE or FALSE).\n\n#I will dispense with the x coordinates entirely. \nneedle.crosses &lt;- function(L, W){\n  y &lt;- runif(1, -W, W)\n  angle &lt;- runif(1, 0, pi)\n  dy &lt;- L/2 * sin(angle)\n  y1 &lt;- y-dy\n  y2 &lt;- y+dy\n  return( floor(y1/W)!= floor(y2/W)) #divide by W tells us which board number the endpoint is on, \n}\n\nbuffon.prob &lt;- function(L, W, M){\n  results &lt;- rep(0, M)\n  for(i in 1:M){\n    results[i] &lt;- needle.crosses(L,W)\n  }\n  return(mean(results))\n}\n\n#test\nbuffon.prob(1, 1, 10000)\n\n[1] 0.6381\n\n#What if the floor boards are 2 units wide??\nbuffon.prob(1, 2, 10000)\n\n[1] 0.3128\n\n\n\n\n9.3.4 Example: the Monty Hall Problem\nOkay, it’s time for a probability and statistics rite of passage: the Monty Hall problem.\nThe problem is named after Monty Hall, the original host of the game show Let’s Make a Deal.\nThe setup is as follows: you, the contestant, are faced with three doors. Behind one of the doors is the grand prize (a million dollars, a new car, a MacGuffin; use your imagination). Behind the other two doors are goats (in this hypothetical universe, a goat is not a prize you want; I disagree with this sentiment, but that’s beside the point). You get to choose a door, and you win the prize behind that door.\nHere’s a helpful illustration from Wikipedia:\n\n\n\nImage credit Wikipedia; https://en.wikipedia.org/wiki/Monty_Hall_problem\n\n\nSuppose that you choose a door at random. Having chosen that door, the host Monty Hall opens one of the other doors to reveal a goat (i.e., not the Grand Prize), and Monty Hall offers you a choice: you can stick with the door you chose and win whatever prize is behind that door, or you can switch your choice to the other door, which Monty Hall has not yet opened.\nShould you switch your choice of door?\nOn first glance, most people agree that it should make no difference– your original choice of door was random, so whether you switch your guess or not, you’re still equally likely to have chosen the door with the Grand Prize.\nBut this intuition is incorrect! Let’s check with a simulation, first.\n\ngenerate_game_state &lt;- function() {\n  # Generate a random instance of the Monty Hall game.\n  # That is, a random assignment of prizes to doors\n  # and an initial guess for our contestant.\n  # Generate an assignment of prizes/goats to doors.\n  # We'll encode the Grand Prize as a 1 and the goats as 0s.\n  # Reminder: sample(v) just returns a random permutation\n  # of the entries of v.\n  prizes &lt;- sample( c(1,0,0) );\n  # Now, let's randomly pick a door to guess.\n  # We pick door number 1, 2 or 3.\n  # Use sample() to choose from {1,2,3} uniformly at random\n  doors &lt;- c(1,2,3)\n  guess &lt;- sample( doors, size=1);\n  # Record the other two doors.\n  # x[-c] returns the entries of x NOT in vector c.\n  otherdoors &lt;- doors[-guess];\n  \n  # Return a list object, which will be easier to work with\n  # when we want to access the different pieces of game\n  # information\n  game &lt;- list(prizes=prizes, guess=guess,\n               otherdoors=otherdoors );\n  return( game )\n}\n\nrun_game_noswitch &lt;- function() {\n  # Run one iteration of Let's Make a Deal,\n  # in which we do NOT switch our guess.\n  \n  # Generate a game.\n  game &lt;- generate_game_state()\n  # Now, Monty Hall has to reveal a door to us.\n  # If we were switching our guess, we would need to do some\n  # extra work to check some conditions (see below for that),\n  # but since we're not switching, let's just cut to the\n  # chase and see if we won the prize or not.\n  # Remember, game$prizes is a vector of 0s and 1s, encoding\n  #     the prizes behind the three doors.\n  # game$guess is 1, 2 or 3, encoding which door we guessed\n  return( game$prizes[game$guess] )\n}\n\nrun_game_yesswitch &lt;- function() {\n  # Run one iteration of Let's Make a Deal,\n  # in which we DO switch our guess.\n  \n  # Generate a game.\n  game &lt;- generate_game_state()\n  guess &lt;- game$guess; # We're going to switch this guess.\n  # Now, Monty Hall has to reveal a door to us.\n  # To do that, we need to look at the other doors,\n  # and reveal that one of them has a goat behind it.\n  # game$otherdoors is a vector of length 2, encoding the\n  # two doors that we didn't look at.\n  # So let's look at them one at a time.\n  # Note: there are other, more clever ways to write\n  # this code, but this is the simplest implementation\n  # to think about, in my opinion.\n  if( game$prizes[game$otherdoors[1]]==0 ){\n    # The first non-guessed door doesn't have a goat\n    # behind it, so Monty Hall shows us the goat behind\n    # that door, and we need to switch our guess to the\n    # *other* door that we didn't choose.\n    guess &lt;- game$otherdoors[2];\n  } else {\n    # If the Grand Prize is behind otherdoors[1],\n    # so that game$otherdoors[1]]==1,\n    # then Monty Hall is going to show us a goat behind\n    # otherdoors[2], and we have the option to switch our\n    # guess to otherdoors[1],\n    # and we will exercise that option\n    guess &lt;- game$otherdoors[1];\n  }\n  # Now check if we won the prize!\n  return( game$prizes[guess] )\n}\n\nOkay, we’ve got simulations implemented for both of our two different game strategies. Let’s simulate both of these a bunch of times and compare the long-run average success.\n\nM &lt;- 1e4;\nnoswitch_wins &lt;- 0;\nfor(i in 1:M) {\n  noswitch_wins &lt;- noswitch_wins + run_game_noswitch()\n}\n\nnoswitch_wins/M\n\n[1] 0.3357\n\n\nNow, let’s see how we do if we switch our guesses.\n\nM &lt;- 1e4;\nyesswitch_wins &lt;- 0;\nfor(i in 1:M) {\n  yesswitch_wins &lt;- yesswitch_wins + run_game_yesswitch()\n}\n\nyesswitch_wins/M\n\n[1] 0.665\n\n\nWow! That’s a lot better than the strategy where we don’t switch our guess!\nThis discrepancy can be explained using Bayes’ rule, but it gets a bit involved (see the wikipedia page if you’re really curious).\nInstead, let’s just think about the following: suppose that the Grand Prize is behind door number 1. There are three possibilities, all equally likely (because we chose uniformly at random among the three doors):\n\nWe pick door 1. We have chosen the door with the Grand Prize behind it. In this situation, the other two doors both have goats behind them, and Monty Hall reveals one of those two goats to us. In this situation, we (mistakenly, so sad!) switch our Grand Prize door for a goat door and we lose.\nWe pick door 2. We have chosen a door with a goat behind it. Of the other two doors, only one has a goat, door 3. Monty Hall shows us the goat behind that door, and we switch our guess to the other door, door 1, which has the Grand Prize behind it. Hooray!\nWe pick door 3. We have chosen a door with a goat behind it. Of the other two doors, only one has a goat, door 2. Monty Hall shows us the goat behind that door, and we switch our guess to the other door, door 1, which has the Grand Prize behind it. Hooray!\n\nSo, of the three equally likely situations, we win the Grand Prize in two of them, and our probability of winning is thus \\(2/3\\). Compare that with our \\(1/3\\) probability of winning in the situation where we don’t switch doors. Not bad!\nThe important point here is that our decision to switch doors is made conditional upon the information from Monty Hall that eliminates one of the three doors for us.\n\n\n9.3.5 A Combination of Random Variables\nLet X be the product of 3 normal random variables Y1, Y2 and Y3, with means 3, 6, and -2 and standard deviations 5, 6 and 9\nWhat is Pr[X &lt; 13]?\n\nNMC&lt;- 100000\nresults &lt;- rep(0, NMC)\nfor(i in 1:NMC){\n  Y1 &lt;- rnorm(1, 3, 5)\n  Y2 &lt;- rnorm(1, 6, 6)\n  Y3 &lt;- rnorm(1, -2, 9)\n  X &lt;- Y1*Y2*Y3\n  results[i] &lt;- (X &lt; 13)\n}\nmean(results)\n\n[1] 0.60955\n\n\n\n\n9.3.6 Example A complicated random variable\nRoll 3 6-sided dice and multiply their values. Let’s find the expected product\n\nNMC &lt;- 100000\n\nresults &lt;- FALSE\nfor(i in 1:NMC){\n  results[i] &lt;- prod(sample(6, size=3, replace=TRUE)) #multiples the values in the vector\n  \n}\nmean(results)\n\n[1] 42.76313\n\nhist(results)\n\n\n\n\n\n\n9.3.7 Example: non-transitive dice\nsee here\n\ndieY &lt;- c(3,3,3,3,3,3)\ndieB &lt;- c(0,0,4,4,4,4)\ndieG &lt;- c(1,1,1,5,5,5)\ndieR &lt;- c(2,2,2,2,6,6)\n\nnotTdice &lt;- data.frame(dieY,dieB,dieG,dieR)\n\nrollDice &lt;- function(die1,die2,N){\n  #true if player 1 wins\n  return(sample(notTdice[,die1],N,replace=TRUE) &gt; sample(notTdice[,die2],N,replace=TRUE))\n}\n\nMCN &lt;- 10000\n\ndieColors &lt;- c(\"yellow\",\"blue\",\"green\",\"red\")\n\nfor(i in 1:3){\n  for(j in ((i+1):4)){\n    results =rollDice(i,j,MCN)\n    print(paste(dieColors[i],\n                \"vs\",\n                dieColors[j],\n                \":\",\n                dieColors[i],\n                \"win proportion is \",\n                mean(results)))\n  }\n}\n\n[1] \"yellow vs blue : yellow win proportion is  0.3343\"\n[1] \"yellow vs green : yellow win proportion is  0.492\"\n[1] \"yellow vs red : yellow win proportion is  0.6617\"\n[1] \"blue vs green : blue win proportion is  0.3283\"\n[1] \"blue vs red : blue win proportion is  0.4541\"\n[1] \"green vs red : green win proportion is  0.3378\"\n\n\n\n\n9.3.8 Miwin’s Dice\nMiwin’s Dice were invented in 1975 by the physicist Michael Winkelmann.\nConsider a set of three dice such that\ndie A has sides 1, 2, 5, 6, 7, 9 die B has sides 1, 3, 4, 5, 8, 9 die C has sides 2, 3, 4, 6, 7, 8\nWhat are the winning probabilities for these dice in the game?\n\ndieA &lt;- c(1, 2, 5, 6, 7, 9)\ndieB &lt;- c(1, 3, 4, 5, 8, 9)\ndieC &lt;- c(2, 3, 4, 6, 7, 8)\n\nnotTdice &lt;- data.frame(dieA,dieB,dieC)\n\nrollDice &lt;- function(die1,die2,N){\n  #true if player 1 wins\n  results &lt;- rep(0,N)\n  P1Rolls &lt;- sample(notTdice[,die1],N,replace=TRUE)\n  P2Rolls &lt;- sample(notTdice[,die2],N,replace=TRUE)\n  results[ P1Rolls &gt; P2Rolls] &lt;- 1\n  results[P1Rolls &lt; P2Rolls] &lt;- -1\n  return(results)\n}\nMCN &lt;- 1000000\ndieNames &lt;- c(\"A\",\"B\",\"C\")\nresultsTable &lt;- data.frame(P1&lt;-vector(\"character\"),\n                           P2&lt;-vector(\"character\"),\n                           Win&lt;-vector(\"numeric\"),\n                           Tie&lt;-vector(\"numeric\"),\n                           Lose&lt;-vector(\"numeric\"))\nfor(i in 1:2){\n  for(j in ((i+1\n             ):3)){\n    results =rollDice(i,j,MCN)\n    resultsTable &lt;- rbind(resultsTable,\n                          c(dieNames[i],\n                            dieNames[j],\n                            mean(results == 1),\n                            mean(results == 0),\n                            mean(results == -1)))\n  }\n}\nresultsTable\n\n  X.A. X.B. X.0.472807. X.0.08342. X.0.443773.\n1    A    B    0.472807    0.08342    0.443773\n2    A    C      0.4437   0.083683    0.472617\n3    B    C    0.472341   0.083206    0.444453\n\nnames(resultsTable) &lt;- c(\"P1 Die\",\"P2 Die\",\"P1 win\",\"Tie\",\"P2 Win\")"
  },
  {
    "objectID": "R03_MonteCarloExamples.html#integration-by-monte-carlo-simulation",
    "href": "R03_MonteCarloExamples.html#integration-by-monte-carlo-simulation",
    "title": "9  Monte Carlo Examples",
    "section": "9.4 Integration by monte carlo simulation",
    "text": "9.4 Integration by monte carlo simulation\n\n9.4.1 Example 1\n\\[\\int_{7}^{14} (3x-2\\ln x-x^2) dx\\]\n\ng &lt;- function(x){\n  return(3*x - 2*log(x)-x^2)\n}\n\nM &lt;- 10000\nresults &lt;- vector(\"numeric\") #empty numerical vector\n\n#I am going to sample from X~unif(7,14) and I want to evalute h(x) = g(x)/f(x), where f(x) is the density of X\n\nfor(i in 1:M){\n  x &lt;- runif(1, 7, 14)\n  results[i] &lt;- g(x)/dunif(x, 7, 14) #this is h(x)\n}\nmean(results)\n\n[1] -615.2348\n\n\n\n-2*log(13492928512)-3395/6\n\n[1] -612.4842\n\n\n\n\n9.4.2 Example 2\n\\[\\int_1^7\\ln(3x^2-2)\\sin x dx\\]\n\nM &lt;- 10000\n\n#step 1, sample from unif(1,7) \nx &lt;- runif(M, 1,7)\ng &lt;- function(x){\n  log(3*x^2-2)*sin(x)\n}\nf &lt;- function(x){\n  dunif(x, 1, 7)\n}\nh &lt;- g(x)/f(x)\n\nmean(h)\n\n[1] -4.191919"
  },
  {
    "objectID": "R03_MonteCarloExamples.html#other-examples",
    "href": "R03_MonteCarloExamples.html#other-examples",
    "title": "9  Monte Carlo Examples",
    "section": "9.5 Other Examples",
    "text": "9.5 Other Examples\n\n9.5.1 Estimating Euler’s constant\nA fact - if you sample \\(X_1, X_2, \\ldots\\) from Unif(0,1), and let \\(Y\\) be the index for which the sum exceeds 1, the expected value of \\(Y\\) is \\(e\\).\n\nNMC &lt;- 100000\nNs &lt;- 0\nfor(i in 1:NMC){\n  Ns[i] = min(which(cumsum(runif(100))&gt;1))\n}\nmean(Ns)\n\n[1] 2.72073\n\n\n\n#Check the value\nexp(1)\n\n[1] 2.718282\n\n\n\n\n9.5.2 Estimating the value of pi\n\nNMC &lt;- 10000; # Number of Monte Carlo replicates\nplot(NA,NA, xlim=c(-1,1), ylim=c(-1,1))\n\nin_circ &lt;- 0; # Count how many points landed in the circle\n# For-loop over the MC replicates\nfor(i in 1:NMC){\n  \n  # for each point, generate (x,y) randomly between -1 and 1\n  point &lt;- runif(n=2, min=-1, max=1);\n  # to be inside circle, our point must satisfy xˆ2 + yˆ2 &lt;= 1\n  if(point[1]^2 + point[2]^2 &lt;= 1){\n  # if inside, add to count\n    in_circ &lt;- in_circ+1\n    points(point[1],point[2])\n  }\n}\n\n\n\n#To get proportion of square covered, take in_circ/N\nprop &lt;- in_circ/NMC\n# to get our estimate of pi, multiply by 4.\npi.mc &lt;- 4*prop\npi.mc\n\n[1] 3.1344"
  },
  {
    "objectID": "R03_MonteCarloExamples.html#random-variable-generation",
    "href": "R03_MonteCarloExamples.html#random-variable-generation",
    "title": "9  Monte Carlo Examples",
    "section": "9.6 Random Variable Generation",
    "text": "9.6 Random Variable Generation\n\n9.6.1 Distribution of F(X) is uniform(0,1)\n\n#Sample from the normal distribution, let's get 1000 values from N(mean=5, var=8^2)\nX &lt;- rnorm(10000, 5, sd=8)\n\nhist(X)\n\n\n\n#What are the first 5 sampled values?\nX[1:5]\n\n[1] 12.6667085  9.0566258  0.2460861 19.1794222 -8.5156276\n\n#SO far we haven't looked at F(X). Remember, the CDF, F(x) is defined as Pr(X &lt;= x)\n#To find these we can look at pnorm\npnorm(X[1:5], 5, sd=8)\n\n[1] 0.83105397 0.69395003 0.27617605 0.96183821 0.04556628\n\n#what if we looked at pnorm for ALL values\n#How would the pnorms be distributed?\n\nhist(pnorm(X, 5, sd=8))\n\n\n\n\n\n\n9.6.2 Simulating Random Values\nLet’s look at a random sample of values from a normal distribution - \\(N(6,2^2)\\)\n\nn.values &lt;- rnorm(10000, mean=6, sd=2)\n\nWe can look a histogram of these values\n\nhist(n.values)\n\n\n\n\nYup. It’s a normal distribution. For any value, let p=P(X&lt;x) What about the left-tailed probabilities associated? Use pnorm.\n\nn.values[1:5]\n\n[1] 7.194574 3.433902 6.290671 5.266036 5.734321\n\npnorm(n.values[1:5], mean=6, sd=2)\n\n[1] 0.72484206 0.09973744 0.55777702 0.35681628 0.44716018\n\n\nWhat does the distribution of left-tail probabilities look like?\n\nhist(pnorm(n.values, mean=6, sd=2), breaks=10)\n\n\n\n\nWhat about some other random variable distribution? Let’s look at an exponential random variable.\n\nexp.values &lt;- rexp(10000, rate=3)\nhist(exp.values)\n\n\n\n\nAgain- that’s the shape of the distribution. What about the distribution of left-tail probabilities?\n\nhist(pexp(exp.values, rate=3))\n\n\n\n\nWhy is this the case? Think about the theory. X ~ Normal Distribution with mean=6, sd=2 What is the probability that P(X&lt;x) &lt; .1?\nWell, .1 of course! There’s a 10% probability that .2 &lt; P(X&lt;x) &lt; .3, and for each interval in this histogram.\n\nprobs &lt;- seq(.01,.99,.005)\npercentiles &lt;- qnorm(probs)\n\nplot(x=seq(-2,2,.1), pnorm(seq(-2,2,.1)), type=\"l\")\nsegments(percentiles,0,percentiles, probs, lwd=3, col=rgb(0,0,0,.5))\nsegments(-2,probs,percentiles, probs)\n\n\n\n\nWe can use this idea to generate random values from any distribution we want as long as we can specify the inverse CDF.\nWe’re going to use the inverse CDF trick to simulate a bunch of values from a normal distribution with mean 6 and standard deviation 2.\n\nu &lt;- runif(10000)  #These are my values sampled uniformly\n                   # at random from 0 to 1. These represent\n                   # Left tail probabilities\nx &lt;- qnorm(u, mean=6, sd=2)\n\nmean(x)\n\n[1] 6.021647\n\nsd(x)\n\n[1] 2.004111\n\nhist(x, probability=TRUE)\nlines(seq(0,12,.1), dnorm(seq(0,12,.1),6,2), col=\"blue\")\n\n\n\n\n\n\n9.6.3 CDF plot for some other distribution\nThe PDF of an exponential\n\nx&lt;- seq(0, 6, .1)\nplot(x, dexp(x,.4), type=\"l\", main=\"Exp(.4) density curve\")\n\n\n\n\n\nprobs &lt;- seq(.01,.99,.01)\npercentiles &lt;- qexp(probs, .4)\n\nplot(x=percentiles, pexp(percentiles,.4), type=\"l\")\nsegments(percentiles,0,percentiles, probs, lwd=3, col=rgb(0,0,0,.5))\nsegments(-2,probs,percentiles, probs)\n\n\n\n\n\n\n9.6.4 Generating random values\nSay I want to get 1000 values from an exponential distribution\n\nx&lt;- seq(0, 20,.1)\ny&lt;- dexp(x, rate=1)\nplot(x,y, type=\"l\", main=\"the density function of X ~ exp(1)\")\n\n\n\n\n\n#Here is what R would do\nU &lt;- runif(1000)\nX &lt;- qexp(U, rate=1) #This is the inverse CDF of X\n#in theory, X data should be distributed by exp(1)\nhist(X, probability=TRUE)\nlines(x,y, col=\"red\")\n\n\n\n\n\\(f(X)=\\frac38x^2\\) over \\([0,2]\\)\n\nU &lt;- runif(10000)\nX &lt;- (8*U)^(1/3)\nhist(X, probability=TRUE)\nlines(x=seq(0, 2, .1), y=3/8*seq(0, 2, .1)^2, col=\"red\")\n\n\n\n\n\n\n9.6.5 Inverse CDF Trick\nHere is a density function that doesn’t have a name The support is from 0 to 2\n\\(f(x) = \\frac38 x^2\\)\n\\(F(x) = \\frac18 x^3\\)\n\\(F^{-1}(x) = \\sqrt[3]{8x}\\)\n\nU &lt;- runif(10000, min=0, max=1)\nX &lt;- (8*U)^(1/3)\n\nhist(X, probability=TRUE)\nlines(x =seq(0,2,.1), y=3/8*(seq(0,2,.1)^2), col=\"red\")"
  },
  {
    "objectID": "R_MonteCarlo_Battleship.html",
    "href": "R_MonteCarlo_Battleship.html",
    "title": "12  Monte Carlo Battleship",
    "section": "",
    "text": "This code will demonstrate how you can use Monte Carlo Simulation to create an AI opponent in Battleship.\nFirst a few function that will be used throughout.\n\n# constants representing hits and misses.\nHIT &lt;- 9; MISS &lt;- -9\n\nplaceShip &lt;- function(board, shipIndex){\n  isLegal &lt;- FALSE\n  giveUp &lt;- 0\n  while(!isLegal & giveUp &lt; 100){\n    giveUp &lt;- giveUp+1\n    orientation = sample(2,1) #upright or across\n    if(orientation==2) {board &lt;- t(board)}\n    shipLength = shipSizes[shipIndex]\n    shipX = sample(1:(dim(board)[1]-shipLength+1),1)\n    shipY = sample(1:(dim(board)[2]),1)\n    isLegal = prod(board[shipX:(shipX+shipLength-1), shipY] %in% c(0,HIT))\n    if(isLegal){\n      board[shipX:(shipX+shipLength-1), shipY] &lt;- shipIndex\n    }\n    if(orientation==2) {board &lt;- t(board)}\n  }\n  if(isLegal){\n    return(board)\n  } else{\n    return(FALSE)\n  }\n}\n\nplaceAllShips &lt;- function(board){\n  for(i in which(shipAlive)){\n    board &lt;- placeShip(board,i)\n    if(!is.matrix(board)) return(FALSE)\n  }\n  if(sum(board==HIT)==0){\n    return(board)\n  } else {\n    return(FALSE)\n  }\n}\n\nbuildHeatMap &lt;- function(boardKnowledge, NMC=10000){\n  boardMap &lt;- matrix(data=0, nrow=boardDim[1], ncol=boardDim[2])\n  for(i in 1:NMC){\n    placeAll &lt;- placeAllShips(boardKnowledge) \n    if(is.matrix(placeAll)){\n      boardMap &lt;- boardMap + (placeAll %in% (1:length(shipAlive))[shipAlive])\n    }\n  }\n  return(boardMap)\n}\n\nguessACoord &lt;- function(boardKnowledge, NMC=10000){\n  hmap &lt;- buildHeatMap(boardKnowledge, NMC)\n  #remove known hits\n  hmap[which(boardKnowledge==HIT)] &lt;- 0\n  \n  guessIndex &lt;- which(hmap == max(hmap))[1]\n  guessX &lt;- guessIndex %% boardDim[1]\n  if(guessX == 0) {guessX &lt;- 10}\n  guessY &lt;- floor((guessIndex-1) / boardDim[2])+1\n  return(list(c(guessX,guessY), hmap))\n}\n\nresultOfGuess &lt;- function(guess){\n  x &lt;- guess[1]; y&lt;- guess[2]; returnstr &lt;- \"\"\n  if(trueBoard[x,y] == 0){\n    boardKnowledge[x,y] &lt;&lt;- MISS\n    returnstr &lt;- \"Miss\"\n  } else{\n    #Hit\n    returnstr &lt;-\"Hit!\"\n    boatIndex &lt;- abs(trueBoard[x,y])\n    trueBoard[x,y] &lt;&lt;- trueBoard[x,y] * -1\n    boardKnowledge[x,y] &lt;&lt;- HIT\n    if(sum(trueBoard == boatIndex)==0){\n      #sunk it\n      boardKnowledge[which(trueBoard==(-boatIndex))] &lt;&lt;- -boatIndex\n      returnstr &lt;- paste(returnstr,\" Sunk Boat \",boatIndex,\".\",sep=\"\")\n      shipAlive[boatIndex] &lt;&lt;- FALSE\n    } \n    if(sum(trueBoard&gt;0)==0){\n      #All Boats Sunk\n      returnstr &lt;- paste(returnstr, \"You Lose\")\n    }\n  }\n  return(returnstr)\n}\n\nTest it out. First the setup.\n\nlibrary(fields)\n#Define board\nboardDim=c(10,10)\n#Define ship sizes\nshipSizes=c(5,4,3,3,2)\n#Initialize ship states\nshipAlive = rep(TRUE, length(shipSizes))\n\n#initializeKnowledge\n# 0 unknown\n# 1,2,3, etc hit boat\nboardKnowledge=matrix(data=0, nrow=boardDim[1], ncol=boardDim[2])\ntrueBoard &lt;- placeAllShips(boardKnowledge)\n\npar(mfrow=c(1,2), mar=c(.5, 3, 4, 0))\nimage(trueBoard, main=\"Ship Locations\", col=tim.colors(),yaxt=\"n\",xaxt=\"n\"); \n  axis(3, at=seq(0,1, length.out=10), labels=LETTERS[1:10], lwd=0, pos=1, cex.axis=.75)\n  axis(2, at=seq(0,1, length.out=10), labels=10:1, lwd=0, pos=0, cex.axis=.75); \nimage(boardKnowledge, main=\"Comp Knowledge\", col=tim.colors(),yaxt=\"n\",xaxt=\"n\"); \n  axis(3, at=seq(0,1, length.out=10), labels=LETTERS[1:10], lwd=0, pos=1, cex.axis=.75)\n  axis(2, at=seq(0,1, length.out=10), labels=10:1, lwd=0, pos=0, cex.axis=.75)\n\n\n\n\nPlay the Game!!!\n\nturn &lt;- 0\nwhile(sum(shipAlive)&gt;0 | turn &lt; 9){\n  turn &lt;- turn +1\n  guessList &lt;- guessACoord(boardKnowledge,1000)\n  guess &lt;- guessList[[1]]\n  guessResult &lt;- resultOfGuess(guess)\n  print(paste(\"Turn \",turn,\": Computer Guesses \",LETTERS[guess[1]],11-guess[2],\": \",guessResult, sep=\"\"))\n  \n  flush.console()\n  par(mfrow=c(1,3), mar=c(.5, 3, 3, 0))\n  image(guessList[[2]], main=\"Heatmap\", col=tim.colors(),yaxt=\"n\",xaxt=\"n\"); \n  axis(3, at=seq(0,1, length.out=10), labels=LETTERS[1:10], lwd=0, pos=1)\n  axis(2, at=seq(0,1, length.out=10), labels=10:1, lwd=0, pos=0)\n  image(trueBoard, main=\"My Board\", col=tim.colors(),yaxt=\"n\",xaxt=\"n\");   \n  axis(3, at=seq(0,1, length.out=10), labels=LETTERS[1:10], lwd=0, pos=1)\n  axis(2, at=seq(0,1, length.out=10), labels=10:1, lwd=0, pos=0)\n  image(boardKnowledge, main=\"Comp Knowledge\", col=tim.colors(),yaxt=\"n\",xaxt=\"n\")\n  axis(3, at=seq(0,1, length.out=10), labels=LETTERS[1:10], lwd=0, pos=1)\n  axis(2, at=seq(0,1, length.out=10), labels=10:1, lwd=0, pos=0)\n}\n\n[1] \"Turn 1: Computer Guesses E5: Miss\"\n\n\n\n\n\n[1] \"Turn 2: Computer Guesses D6: Miss\"\n\n\n\n\n\n[1] \"Turn 3: Computer Guesses F4: Miss\"\n\n\n\n\n\n[1] \"Turn 4: Computer Guesses F8: Hit!\"\n\n\n\n\n\n[1] \"Turn 5: Computer Guesses E8: Hit!\"\n\n\n\n\n\n[1] \"Turn 6: Computer Guesses D8: Hit!\"\n\n\n\n\n\n[1] \"Turn 7: Computer Guesses C8: Miss\"\n\n\n\n\n\n[1] \"Turn 8: Computer Guesses G8: Hit! Sunk Boat 2.\"\n\n\n\n\n\n[1] \"Turn 9: Computer Guesses G3: Hit!\"\n\n\n\n\n\n[1] \"Turn 10: Computer Guesses F3: Miss\"\n\n\n\n\n\n[1] \"Turn 11: Computer Guesses G4: Hit!\"\n\n\n\n\n\n[1] \"Turn 12: Computer Guesses G5: Hit!\"\n\n\n\n\n\n[1] \"Turn 13: Computer Guesses G2: Hit!\"\n\n\n\n\n\n[1] \"Turn 14: Computer Guesses G1: Hit! Sunk Boat 1.\"\n\n\n\n\n\n[1] \"Turn 15: Computer Guesses H7: Miss\"\n\n\n\n\n\n[1] \"Turn 16: Computer Guesses C4: Miss\"\n\n\n\n\n\n[1] \"Turn 17: Computer Guesses I6: Miss\"\n\n\n\n\n\n[1] \"Turn 18: Computer Guesses B3: Miss\"\n\n\n\n\n\n[1] \"Turn 19: Computer Guesses D2: Miss\"\n\n\n\n\n\n[1] \"Turn 20: Computer Guesses B7: Hit!\"\n\n\n\n\n\n[1] \"Turn 21: Computer Guesses B6: Hit!\"\n\n\n\n\n\n[1] \"Turn 22: Computer Guesses B5: Miss\"\n\n\n\n\n\n[1] \"Turn 23: Computer Guesses B8: Hit! Sunk Boat 4.\"\n\n\n\n\n\n[1] \"Turn 24: Computer Guesses H10: Miss\"\n\n\n\n\n\n[1] \"Turn 25: Computer Guesses I9: Hit!\"\n\n\n\n\n\n[1] \"Turn 26: Computer Guesses I8: Hit!\"\n\n\n\n\n\n[1] \"Turn 27: Computer Guesses I10: Miss\"\n\n\n\n\n\n[1] \"Turn 28: Computer Guesses I7: Hit! Sunk Boat 3.\"\n\n\n\n\n\n[1] \"Turn 29: Computer Guesses I2: Miss\"\n\n\n\n\n\n[1] \"Turn 30: Computer Guesses F6: Miss\"\n\n\n\n\n\n[1] \"Turn 31: Computer Guesses A4: Miss\"\n\n\n\n\n\n[1] \"Turn 32: Computer Guesses B1: Miss\"\n\n\n\n\n\n[1] \"Turn 33: Computer Guesses I4: Miss\"\n\n\n\n\n\n[1] \"Turn 34: Computer Guesses E2: Miss\"\n\n\n\n\n\n[1] \"Turn 35: Computer Guesses D9: Miss\"\n\n\n\n\n\n[1] \"Turn 36: Computer Guesses D3: Miss\"\n\n\n\n\n\n[1] \"Turn 37: Computer Guesses C2: Miss\"\n\n\n\n\n\n[1] \"Turn 38: Computer Guesses J3: Miss\"\n\n\n\n\n\n[1] \"Turn 39: Computer Guesses E10: Miss\"\n\n\n\n\n\n[1] \"Turn 40: Computer Guesses B10: Miss\"\n\n\n\n\n\n[1] \"Turn 41: Computer Guesses E7: Miss\"\n\n\n\n\n\n[1] \"Turn 42: Computer Guesses H3: Miss\"\n\n\n\n\n\n[1] \"Turn 43: Computer Guesses A9: Hit!\"\n\n\n\n\n\n[1] \"Turn 44: Computer Guesses B9: Hit! Sunk Boat 5. You Lose\""
  },
  {
    "objectID": "mc_practice.html",
    "href": "mc_practice.html",
    "title": "11  Monte Carlo Practice",
    "section": "",
    "text": "12 Practice Problems\nThese problems are excellent practice but they are beyond the material we cover in STAT 340."
  },
  {
    "objectID": "mc_practice.html#integration-by-darts",
    "href": "mc_practice.html#integration-by-darts",
    "title": "11  Monte Carlo Practice",
    "section": "12.1 Integration by darts",
    "text": "12.1 Integration by darts\nEstimate \\(\\int_0^3 (x^3-3x^2+x+3)\\,dx\\). To do so, use the fact that \\[\\int_a^b g(x)dx = \\int_a^b \\frac{g(x)}{f(x)}f(x)dx\\]. Let \\(f(x)\\) be the density function for a uniform random variable over \\([0,3]\\).\n\nf&lt;-function(x){return(x^3-3*x^2+x+3)}\nplot(x=seq(0,3,.1), f(seq(0,3,.1)), type=\"l\", ylim=c(0,7), xlab=\"x\", ylab=\"y\")\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#Solution\n\n#We can define a uniform density function between 0 and 3\n#call this g(x)=dunif(x,0,3)\n#The integral trick says that int_0^7 f(x)dx = E(f(x)/g(x)).\nNMC &lt;- 1000\nx &lt;- runif(NMC, 0,3)\nmean(f(x)/dunif(x,0,3))\n\n[1] 6.752893"
  },
  {
    "objectID": "mc_practice.html#eulers-constant",
    "href": "mc_practice.html#eulers-constant",
    "title": "11  Monte Carlo Practice",
    "section": "12.2 Euler’s Constant",
    "text": "12.2 Euler’s Constant\nSuppose \\(X_1, X_2,\\ldots, X_n \\sim Unif(0,1)\\). Let \\(N\\) be the lowest index such that \\(X_1+X_2+\\cdots+X_N &gt; 1\\). \\(\\mathbb{E}(N)=e\\). Use this fact to estimate Euler’s constant \\(e\\) using Monte Carlo simulation.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nNMC &lt;- 1000\nNs &lt;- 0\nfor(i in 1:NMC){\n  sum &lt;- 0;   N &lt;- 0\n  while(sum &lt; 1){\n    sum &lt;- sum + runif(1)\n    N &lt;- N+1\n  }\n  Ns[i] = N\n}\nmean(Ns)\n\n[1] 2.687\n\nexp(1)\n\n[1] 2.718282"
  },
  {
    "objectID": "mc_practice.html#dice-probability",
    "href": "mc_practice.html#dice-probability",
    "title": "11  Monte Carlo Practice",
    "section": "12.3 Dice Probability",
    "text": "12.3 Dice Probability\nI roll 3 six sided dice. What is the probability that the sum of the dice is at least 12? Estimate the answer with Monte Carlo simulation.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nNMC &lt;- 100\nresults &lt;- 0\nfor(i in 1:NMC){\n  results[i] &lt;- sum(sample(6, 3, replace=TRUE))&gt;=12\n}\nmean(results)\n\n[1] 0.35"
  },
  {
    "objectID": "mc_practice.html#sales-and-price",
    "href": "mc_practice.html#sales-and-price",
    "title": "11  Monte Carlo Practice",
    "section": "12.4 Sales and Price",
    "text": "12.4 Sales and Price\nBased on your market research, you believe that there are equal chances that the market will be Slow, OK, or Hot.\n\nIn the “Slow market” scenario, you expect to sell 50,000 units at an average selling price of $11.00 per unit.\nIn the “OK market” scenario, you expect to sell 75,000 units, but you’ll likely realize a lower average selling price of $10.00 per unit.\nIn the “Hot market” scenario, you expect to sell 100,000 units, but this will bring in competitors who will drive down the average selling price to $8.00 per unit.\n\nAnother uncertain variable is Unit Cost.B Your firm’s production manager advises you that unit costs may be anywhere from $5.50 to $7.50. Use a Monte Carlo simulation to estimate the expected net profit (revenue - cost).\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nNMC &lt;- 100\nprofit &lt;- 0\nprices &lt;- c(11, 10, 8)\nquantity &lt;- c(50000, 75000, 100000)\nfor(i in 1:NMC){\n  market &lt;- sample(1:3, 1)\n  unitCost &lt;- runif(1, 5.5, 7.5)\n  profit[i] &lt;- quantity[market]*(prices[market]-unitCost)\n}\nmean(profit)\n\n[1] 205536.9"
  },
  {
    "objectID": "mc_practice.html#black-scholes-option-pricing",
    "href": "mc_practice.html#black-scholes-option-pricing",
    "title": "11  Monte Carlo Practice",
    "section": "12.5 Black-Scholes Option Pricing",
    "text": "12.5 Black-Scholes Option Pricing\nWe start with the Black-Scholes-Merton formula (\\(1973\\)) for the pricing of European call options on an underlying (e.g. stocks and indexes) without dividends:\n\\(\\begin{eqnarray*} C(S_t, K, t, T, r, \\sigma) &=& S_t\\cdot N(d_1) - e^{-r(T-t)}\\cdot K \\cdot N(d_2)\\newline\\newline N(d) &=& \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^d e^{-\\frac{1}{2}x^2}dx \\newline\\newline d_1 &=& \\frac{\\log\\frac{S_t}{K} + (T-t)\\left(r + \\frac{\\sigma^2}{2}\\right)}{\\sigma\\sqrt{T-t}}\\newline\\newline d_2 &=& \\frac{\\log\\frac{S_t}{K} + (T-t)\\left(r - \\frac{\\sigma^2}{2}\\right)}{\\sigma\\sqrt{T-t}}. \\end{eqnarray*}\\)\nIn the equations above \\(S_t\\) is the price of the underlying at time \\(t\\), \\(\\sigma\\) is the constant volatility (standard deviation of returns) of the underlying, \\(K\\) is the strike price of the option, \\(T\\) is the maturity date of the option, \\(r\\) is the risk-free short rate.\nThe Black-Scholes-Merton (\\(1973\\)) stochastic differential equation is given by \\(dS_t = rS_t dt + \\sigma S_t dZ_t,\\) where $Z(t)$ is the random component of the model (a Brownian motion). In this model, the risky underlying follows, under risk neutrality, a geometric Brownian motion with a stochastic differential equation (SDE).\nWe will look at the discretized version of the BSM model (Euler discretization), given by \\(S_t = S_{t-\\Delta t} \\exp\\left(\\left(r - \\frac{\\sigma^2}{2}\\right)\\Delta t + \\sigma\\sqrt{\\Delta t}z_t \\right).\\)\nThe variable \\(z\\) is a standard normally distributed random variable, \\(0 &lt; \\Delta t &lt; T\\), a (small enough) time interval. It also holds \\(0 &lt; t \\leq T\\) with \\(T\\) the final time horizon.\nIn this simulation we use the values \\(S_0 = 100\\), \\(K = 105\\), \\(T = 1.0\\), \\(r = 0.05\\), \\(\\sigma = 0.2\\). Let’s see what is the expected option price using these parameters and assuming \\(t=0\\), then we will run a Monte Carlo simulation to find the option price under the same conditions.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nS_0 &lt;- 100; K &lt;- 105; endT &lt;- 1.0; r &lt;- 0.05; sigma &lt;- 0.2;\ndt &lt;- 0.01\n\nST &lt;- 0 #vector to hold values\nNMC &lt;- 1000\nfor(i in 1:NMC){\n  St &lt;- S_0\n  t &lt;- 0\n  while(t &lt; endT){\n    St &lt;- St*exp((r-sigma^2/2)*dt + sigma*sqrt(dt)*rnorm(1))\n    t &lt;- t+dt\n  }\n  ST[i] &lt;- St\n}\nhist(ST)\n\n\n\nmean(ST)\n\n[1] 105.277"
  },
  {
    "objectID": "mc_practice.html#average-distance-in-a-sphere",
    "href": "mc_practice.html#average-distance-in-a-sphere",
    "title": "11  Monte Carlo Practice",
    "section": "12.6 Average Distance in a sphere",
    "text": "12.6 Average Distance in a sphere\nEstimate the average distance between two points in a sphere of radius 1 using Monte Carlo simulation.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nNMC &lt;- 100\ndist &lt;- 0\nfor(i in 1:NMC){\n  #get a random point\n  repeat{\ncoord1 &lt;- runif(2, -1,1)\nif(sqrt(sum(coord1^2))&lt;=1){\n  break\n}\n  }\n  #get another random point\n  repeat{\ncoord2 &lt;- runif(2, -1,1)\nif(sqrt(sum(coord2^2))&lt;=1){\n  break\n}\n  }\n  dist[i] = sqrt(sum((coord2-coord1)^2))\n}\nmean(dist)\n\n[1] 0.9242228"
  },
  {
    "objectID": "mc_practice.html#average-distance-in-a-square",
    "href": "mc_practice.html#average-distance-in-a-square",
    "title": "11  Monte Carlo Practice",
    "section": "12.7 Average distance in a square",
    "text": "12.7 Average distance in a square\nEstimate the average distance between two points in a square with side lengths 1 using Monte Carlo simulation.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nNMC &lt;- 100\ndist &lt;- 0\nfor(i in 1:NMC){\n  coord1 &lt;- runif(2, 0, 1)\n  coord2 &lt;- runif(2, 0, 1)\n  dist[i] = sqrt(sum((coord2-coord1)^2))\n}\nmean(dist)\n\n[1] 0.5010534"
  },
  {
    "objectID": "mc_practice.html#average-distance-in-a-simplex",
    "href": "mc_practice.html#average-distance-in-a-simplex",
    "title": "11  Monte Carlo Practice",
    "section": "12.8 Average distance in a simplex",
    "text": "12.8 Average distance in a simplex\nEstimate the average distance between two points on the 3-simplex (points \\((x,y,z)\\) such that \\(0\\leq x,y,z \\leq 1\\) and \\(x+y+z=1\\).\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nNMC &lt;- 100\ndist &lt;- 0\n\nfor(i in 1:NMC){\n  \n#A good way to think of the sampling is to pick two random dividing points between 0 and 1. Add 0 and 1 to the list and then sort them, then find the differences\n  pt1 &lt;- diff(sort(c(0,1,runif(2))))\n  pt2 &lt;- diff(sort(c(0,1,runif(2))))\n\n  dist[i] &lt;- sqrt(sum((pt1-pt2)^2))\n}\nmean(dist)\n\n[1] 0.5190203"
  },
  {
    "objectID": "mc_practice.html#other-examples",
    "href": "mc_practice.html#other-examples",
    "title": "11  Monte Carlo Practice",
    "section": "12.18 Other examples",
    "text": "12.18 Other examples\nCheck out some examples here"
  },
  {
    "objectID": "mc_practice.html#completion-time",
    "href": "mc_practice.html#completion-time",
    "title": "11  Monte Carlo Practice",
    "section": "12.9 Completion Time",
    "text": "12.9 Completion Time\nLet’s assume we have a process constructed from 3 stages (X1, X2, X3). Each one has an average duration (5, 10 and 15 minutes) which vary following the normal distribution and we know their standard deviation (all 1 minute). We want to know what is the probability that the process will exceed 34 minutes?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nNMC&lt;-10000\nduration &lt;- rnorm(NMC, 5, 1)+rnorm(NMC, 10, 1) + rnorm(NMC, 15, 1)\nmean(duration &gt; 34)\n\n[1] 0.0129"
  },
  {
    "objectID": "mc_practice.html#fitting-blocks",
    "href": "mc_practice.html#fitting-blocks",
    "title": "11  Monte Carlo Practice",
    "section": "12.10 Fitting Blocks",
    "text": "12.10 Fitting Blocks\nIn this example let’s assume we want to assemble three blocks inside a container of a given width. The box has a nominal width of 16.5mm, the three blocks have nominal widths of 4, 6 and 6 mm. By design there is a nominal gap of 0.5mm. However there are variations in the production of the blocks.\n\nThe box has variation in width between -0.1mm to +0.1mm uniformly at random\nThe other boxes have margins of error of 0.2, 0.3 and 0.25 respectively (+ or - uniformly at random)\n\nEstimate the probability that the 3 blocks will fit in the box.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nNMC &lt;- 100\n\nbox.w &lt;- runif(NMC, 16.5-.1, 16.5+.1)\nblock1.w &lt;- runif(NMC, 4-.2, 4+.2)\nblock2.w &lt;- runif(NMC, 6-.3, 6+.3)\nblock3.w &lt;- runif(NMC, 6-.25, 6+.25)\n\nfits &lt;- box.w &gt; block1.w+block2.w+block3.w\nmean(fits)\n\n[1] 0.99"
  },
  {
    "objectID": "mc_practice.html#roomba-zoomba",
    "href": "mc_practice.html#roomba-zoomba",
    "title": "11  Monte Carlo Practice",
    "section": "12.11 Roomba Zoomba",
    "text": "12.11 Roomba Zoomba\nA circular vacuum robot that has a radius of 20cm will roll around a room that is 10m x 10m square. It begins in the exact center of the room. The way it moves is:\n\nIt picks a direction uniformly at random from 0 to 360 degrees (\\(0\\) to \\(2\\pi\\))\nIt travels for anywhere between 0m and 1m, uniformly at random.\nIf it hits a wall it bounces off at the angle of incidence.\nIt repeats\n\n\nIf there is a speck of dirt located at coordinates (1,1), what is the average amount of time it will take for the robot to collect this dirt?\nIf the robot travels at 1m/sec, what is the expected length of time for the robot to clean 50% of the floor?\n\nSolution in-progress!\n\nx &lt;- 5; y&lt;- 5\n\nmaxN &lt;- 1000\n\nfor(step in 1:maxN){\n  theta &lt;- runif(1, 0, 2*pi)\n  dist &lt;- runif(1,0,1)\n  xy_new &lt;- c(x[step],y[step]) + dist*c(cos(theta), sin(theta))\n  if(xy_new[1]&lt;.2){xy_new[1]=2*.2-xy_new[1]}\n  if(xy_new[2]&lt;.2){xy_new[2]=2*.2-xy_new[2]}\n  if(xy_new[1]&gt;9.8){xy_new[1]=2*9.8-xy_new[1]}\n  if(xy_new[2]&gt;9.8){xy_new[2]=2*9.8-xy_new[2]}\n  x[step+1] &lt;- xy_new[1]\n  y[step+1] &lt;- xy_new[2]\n}\nplot(x,y, type=\"l\", xlim=c(0,10), ylim=c(0,10))\nabline(h=c(0,10), col=\"red\")\nabline(v=c(0,10), col=\"red\")"
  },
  {
    "objectID": "mc_practice.html#chutes-and-ladders",
    "href": "mc_practice.html#chutes-and-ladders",
    "title": "11  Monte Carlo Practice",
    "section": "12.12 Chutes and Ladders",
    "text": "12.12 Chutes and Ladders\nConsider the game Chutes and Ladders. On each turn you roll a 6 sided die and move that many spaces. If you land on a ladder you move up to a new spot, and if you land on a slide you move down. Perform a monte Carlo simulation to answer the following questions:\n\n\nWhat’s the average number of rolls to win?\nHow many chutes and ladders will a user typically hit?\nAre the chutes and ladders balanced?\nAre some squares hit more often than others?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#We need to create a vector of the board\nboard &lt;- 1:100\n#ladders\nboard[1]&lt;- 38\nboard[4] &lt;- 14\nboard[9] &lt;- 31\nboard[21] &lt;- 42\nboard[36] &lt;- 44\nboard[28] &lt;- 84\nboard[51] &lt;- 67\nboard[80] &lt;- 100\nboard[71] &lt;- 91\n#chutes\nboard[16] &lt;- 6\nboard[49] &lt;- 11\nboard[48] &lt;- 26\nboard[62] &lt;- 19\nboard[87] &lt;- 24\nboard[56] &lt;- 53\nboard[64] &lt;- 60\nboard[93] &lt;- 73\nboard[95] &lt;- 75\nboard[98] &lt;- 78\n\nNMC &lt;- 100\nset.seed(1)\n\nrolls &lt;- rep(0, NMC)\nnChutes &lt;- rep(0, NMC)\nnLadders &lt;- rep(0,NMC)\nlandOn &lt;- matrix(rep(0, NMC*100),nrow=NMC)\n\nfor(i in 1:NMC){\n  position &lt;- 1\n  repeat{\nlandOn[i,position] &lt;- landOn[i,position] + 1\nif(position==100){break;}\nroll &lt;- sample(6,1)\nrolls[i] &lt;- rolls[i] + 1\nposition.new &lt;- min(100,position+roll)\nif(board[position.new] &lt; position.new){\n  nChutes[i] &lt;- nChutes[i] + 1\n}\nif(board[position.new] &gt; position.new){\n  nLadders[i] &lt;- nLadders[i] +1\n}\nposition &lt;- board[position.new]\n  }\n}\n\nmean(rolls)\n\n[1] 34.66\n\nmean(nChutes)\n\n[1] 3.93\n\nmean(nLadders)\n\n[1] 3.08\n\nplot(colMeans(landOn))\n\n\n\nlandOnDF &lt;- data.frame(space=1:100, proportion &lt;- colMeans(landOn))\ntail(landOnDF[order(landOnDF[,2]),],10)\n\n    space proportion....colMeans.landOn.\n42     42                           0.68\n31     31                           0.83\n24     24                           0.84\n6       6                           0.86\n11     11                           0.86\n26     26                           0.86\n44     44                           0.93\n1       1                           1.00\n100   100                           1.00\n84     84                           1.02\n\n\nIt takes an average of 36.78 turns to finish the game The average number of chutes slid down is 4 per game. The average number of ladders climbed is 3.22 per game. Chutes are more likely than ladders apparently; even though there are 10 chutes compared to 9 ladders, the expected number of chutes is much higher than ladders.\nThe most common spots (besides 1 and 100) are 44 and 26.\n44 is the result of landing on one of the ladders. 26 is the result of landing on one of the chutes."
  },
  {
    "objectID": "mc_practice.html#battleship",
    "href": "mc_practice.html#battleship",
    "title": "11  Monte Carlo Practice",
    "section": "12.13 Battleship",
    "text": "12.13 Battleship\nBuild a Battleship AI (https://github.com/mitchelljy/battleships_ai)\n(Rules of the game: https://www.hasbro.com/common/instruct/battleship.pdf)\nBattleship is a game played on 10x10 grid. There are 5 boats of lengths 2, 3, 3, 4, and 5. The Monte Carlo AI is built like this:\n\nTake current board state\nSimulate \\(N\\) samples, each is a random placement of a remaining ships (knowing where hits and misses have been observed.) . Be sure to not put boats in a space that has been guessed, and if a hit has been found, be sure that boats cover those spots.\nStack all of the simulations and sum the total number of ships in each square (emphasise ships that overlap existing hits)\nTake the mean for each sqaure, giving us a frequency matrix or heatmap\nPick the largest value corresponding to a legal move in the matrix\n\nThis is how the AI decides which square to guess at every state of the game. As an added challenge, you can create additional logic to have the computer make the guess - taking the spot that has the highest likelihood - and determine if it is a hit, or if it sinks a boat. You will need to initialize the board with a random arrangement of the boats.\n\nYou will need a function generate_board &lt;- function(width=10, height=10, boats=c(TRUE,TRUE,TRUE,TRUE,TRUE)). This function should randomly place boats on the board, each either vertically or horizontally, and return The layout. Number the boats 1,2,3,4,5. Be sure that numbers do not overlap each other when placed randomly. This function should return a matrix with values 0 if there is nothing placed in a spot, or the boat number. For example, when you place boat 5, it is 5 units long, so there should be 5 spots with the number 5 in them (And they should be in a straight line).\nYou will also need a function validate_board &lt;- function(board, state) which will check to see if the simulated board is legal given the state. The state should have 0s in locations that have not been tested, -1 in locations where misses have been numbers 1 through 5 where hits have been observed. If the number of \\(i\\)’s on the board equals the number of pegs in boat \\(i\\), then the AI will now that boat \\(i\\) has been sunk - you can convert all of these \\(i\\)’s into -1 so they will be ignored, and in the future we can dispance with randomly placing boat \\(i\\). A board is valid if there are no boats in a -1 spot, and any spot in an \\(i\\) spot contains boat \\(i\\).\nTo determine the next move you will need to generate boards until you have had at least 1 valid board (10 is better) to make a choice. If many spots have the same frequency, then you can just pick one at random, or pick the one with the lowest row and column.\n\nSee an implementation here"
  },
  {
    "objectID": "mc_practice.html#stock-price",
    "href": "mc_practice.html#stock-price",
    "title": "11  Monte Carlo Practice",
    "section": "12.15 Stock Price",
    "text": "12.15 Stock Price\nSuppose a stock price varies from day to day through a scaled process. If the stock price is \\(X_i\\) on day \\(i\\), \\(X_{i+1} = (1.01+Z/25) X_i\\) where \\(Z\\) is a standard normal random variable. Today the stock price is $50 per share. Use a Monte Carlo simulation to estimate the distribution of stock prices 30 days from now.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nNMC &lt;- 1000\n  plot(NA, xlim=c(1,31), ylim=c(0,100))\n  finalPrice &lt;- 0\nfor(i in 1:NMC){\n  price &lt;- 50\n  for(day in 1:30){\nprice[day+1] &lt;- price[day] * (1.01 + rnorm(1, 0, 1)/25)\n  }\n  finalPrice[i] &lt;- price[31]\n  lines(x=1:31, price, col=rgb(0,0,0,.15))\n}\n\n\n\nmean(finalPrice)\n\n[1] 67.90084\n\nhist(finalPrice, prob=TRUE)\nlines(density(finalPrice))\n\n\n\n\n\n\n\nYou can buy a 30 day put option for $10 with a strike price of $65 from Sleazy Jim, the stock broker. This terms of this contract are these:\n\nYou pay $10 to Sleazy Jim today.\nIf after 30 days the stock price is below $65, you will buy a share of stock at the market price and Sleazy Jim will buy it from you for $65. You pocket the difference.\nIf after 30 days the stock price is above $65, you will do nothing.\n\n(In essence, Sleazy Jim is betting that the stock price will be higher than $65 after 30 days.)\nEven though interest rates are high now, let’s ignore the affect of interest rate. Using Monte Carlo simulation, estimate the expected value of this put option (the net profit) to determine whether it is a good idea to buy the put option.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ngain &lt;- 65 - pmin(finalPrice, 65)\ncost &lt;- 10\n\nmean(gain - 10)\n\n[1] -5.383399\n\n\nIf you enter into this trade with Sleazy Jim, you have an expected loss of $5.53. Don’t make the trade!"
  },
  {
    "objectID": "mc_practice.html#patent-pending",
    "href": "mc_practice.html#patent-pending",
    "title": "11  Monte Carlo Practice",
    "section": "12.16 Patent Pending",
    "text": "12.16 Patent Pending\nYou have decided to apply for a patent to protect your IP, but you also did that in order to increase sales as you are aware that businesses deem a patented product more worthy.\nLet’s make the following assumptions:\n\nThere is a 50% chance that your product gets patented\nIf it does get patented, your sales go up by 25% — 75%, with 50% being the most likely case. (uniform distribution)\nWithout a patent you expect to sell between $1 — $9 million next year, with $3 million being the most likely case. Let the probabilities be given in the following table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSales ($M)\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nprobability\n1/33\n4/33\n7/33\n6/33\n5/33\n4/33\n3/33\n2/33\n1/33\n\n\n\n\nWe do not have to consider any costs or expenses\n\nProblem: Suppose a wholesaler offers to buy your entire production and inventory for the year for $6 million (you won’t be able to sell anything else), would you accept the offer?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsales.p &lt;- c(1,4,7,6,5,4,3,2,1)/33\nsales.v &lt;- 1:9\n\nrevenue &lt;- 0\nNMC &lt;- 1000\nfor(i in 1:NMC){\n  getPatent &lt;- sample(0:1, size=1, prob=c(.5,.5))\n  sales.scalar &lt;- 1\n  if(getPatent){\nsales.scalar &lt;- 1 + runif(1, .25, .75)\n  }\n  revenue[i] &lt;- sample(sales.v, size=1, prob=sales.p) * sales.scalar\n}\nhist(revenue)\n\n\n\nmean(revenue)\n\n[1] 5.401985\n\n\nThe expected revenue is 5.75 million. The offer of 6 million is an attractive offer. I would go for that."
  },
  {
    "objectID": "mc_practice.html#social-network",
    "href": "mc_practice.html#social-network",
    "title": "11  Monte Carlo Practice",
    "section": "12.17 Social Network",
    "text": "12.17 Social Network\nConsider a social network with people \\(1,2,\\ldots, n\\). Suppose we have a symmetric social structure, in that if person \\(i\\) is friends with person \\(j\\), then person \\(j\\) is friends with person \\(i\\). Thus we can define a symmetric friendship matrix with entries \\(p_{ij}=p_{ji}\\).\nSuppose that each pair of people can be friends independently with probability \\(\\theta\\). The question we want to answer here is this: How big must \\(\\theta\\) be in order to be more than 95\\% certain that the entire social network will be connected - this means that every two people will be connected either directly or through one or more intermediate friends.\nYour goal is to write a function estimateProportionConnected(n,theta, NMC), which takes three parameters:\n\nn, the number of people in the network,\ntheta, the probability of a connection,\nNMC, the number of Monte Carlo simulations to run.\n\nThe function should\n\nCreate an empty vector to store the results (whether or not each simulation resulted in a connected network)\nIn a loop,\n\n\ngenerate a random symmetric social network of size n (a function generateNetwork(n, theta) will be useful)\nDetermine whether the network is connected or not\nSave the result in your results vector\n\n\nReturn the proportion of simulations that resulted in a connected network.\n\nHint: You can use the function concomFromMatAdj in the concom package. It takes a symmetric adjacency matrix and returns the connected components. In particular, you want to look at the number of connected components, in the ncomponents variable.\nGiven a matrix M, you just call concomFromMatAdj(M)$ncomponents\nIf the number of components is more than 1 then the social network is not connected.\nBonus: For a social network of size \\(50\\), come up with an estimate of the lowest value of \\(\\theta\\) that produces connected social networks 95% of the time.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n#install.packages(\"concom\")\nlibrary(concom)\n\nWarning: package 'concom' was built under R version 4.2.3\n\ngenerateMatrix &lt;- function(n, theta){\n  M &lt;- matrix(data=rep(0, n*n), nrow=n)\n  for(i in 1:(n-1)){\nfor(j in 2:n){\n  if(runif(1) &lt; theta){\nM[i,j]=1\nM[j,i]=1\n  }\n}\n  }\n  return(M)\n}\n\nestimateProportionConnected &lt;- function(n,theta, NMC){\n  results &lt;- 0\n  for(i in 1:NMC){\nM &lt;- generateMatrix(n, theta)\nresults[i] &lt;- concomFromMatAdj(M)$ncomponents==1\n  }\n  return(mean(results))\n}\n\nfor(theta in seq(.08,.07,by=-.001)){\n  p &lt;- estimateProportionConnected(50, theta, 500)\n  print(paste(\"When theta =\",theta,\"connected with prob\",p))\n}\n\n[1] \"When theta = 0.08 connected with prob 0.956\"\n[1] \"When theta = 0.079 connected with prob 0.966\"\n[1] \"When theta = 0.078 connected with prob 0.958\"\n[1] \"When theta = 0.077 connected with prob 0.968\"\n[1] \"When theta = 0.076 connected with prob 0.964\"\n[1] \"When theta = 0.075 connected with prob 0.956\"\n[1] \"When theta = 0.074 connected with prob 0.948\"\n[1] \"When theta = 0.073 connected with prob 0.934\"\n[1] \"When theta = 0.072 connected with prob 0.946\"\n[1] \"When theta = 0.071 connected with prob 0.924\"\n[1] \"When theta = 0.07 connected with prob 0.93\""
  },
  {
    "objectID": "mc_practice.html#infection-spread-simulation-source",
    "href": "mc_practice.html#infection-spread-simulation-source",
    "title": "11  Monte Carlo Practice",
    "section": "12.14 Infection spread simulation source",
    "text": "12.14 Infection spread simulation source\nModel a city as a 1x1 square; The population is 2.5k, randomly located throughout the city. Pick one single individual to be infected.\nOn each time step, each individual walks in a random direction and moves .005 units (if it hits a wall, just place it at the edge of the city). After each time step, if an unaffected person is near an infected person (within .002) then the infection spreads to them, and they become infected.\n\nEstimate how many time steps it takes for 99% of the population to become infected.\nWhat if each person will become resistant after \\(X_i\\) time steps, where \\(X_i \\sim Geom(p)\\). Suppose \\(p=.5\\). This gives us the standard SIR model - individuals are susceptible, infected or resistant (either cured or dead). resistant individuals cannot become infected, and they cannot infect others. How does the esimate change?\nWhat if we change the population to 1000 individuals?\nWhat if we change the infection distance to be 0.004?\n\nSolution in progress"
  }
]